<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>多模态</title>
      <link href="/posts/29165/"/>
      <url>/posts/29165/</url>
      
        <content type="html"><![CDATA[<h2 id="Decisive-features-is-subset-of-features-which-determine-label-y"><a href="#Decisive-features-is-subset-of-features-which-determine-label-y" class="headerlink" title="Decisive features is subset of features which determine label y"></a>Decisive features is subset of features which determine label y</h2><h2 id="Modality-specific-decisive-features"><a href="#Modality-specific-decisive-features" class="headerlink" title="Modality specific decisive features"></a>Modality specific decisive features</h2><h2 id="Modality-general-decisive-features"><a href="#Modality-general-decisive-features" class="headerlink" title="Modality general decisive features"></a>Modality general decisive features</h2><h1 id="多模态表示"><a href="#多模态表示" class="headerlink" title="多模态表示"></a>多模态表示</h1><p>单模态的表示学习负责将信息表示为计算机可以处理的数值向量或者进一步抽象为更高层的特征向量，而多模态表示学习是指通过利用多模态之间的互补性，剔除模态间的冗余性，从而学习到更好的特征表示。主要包括两大研究方向：<strong>联合表示（Joint Representations）</strong>和<strong>协同表示（Coordinated Representations）</strong>。</p><p>联合表示将多个模态的信息一起映射到一个统一的多模态向量空间；</p><p>协同表示负责将多模态中的每个模态分别映射到各自的表示空间，但映射后的向量之间满足一定的相关性约束（例如线性相关）。</p><h1 id="多模态特征融合"><a href="#多模态特征融合" class="headerlink" title="多模态特征融合"></a>多模态特征融合</h1><p>在特征提取之后，多模态特征融合的方法分为四种：特征级融合、决策级融合、混合级融合和模型级融合。</p><p>特征级融合：也成为早期融合，最常用的策略，是多模态识别系统最常用的策略。它表示在<strong>提取后立即从不同模态提取的特征连接成单个高维特征向量的方法</strong>。多模态早期融合方法常常与特征提取方法相结合以剔除冗余信息，如主成分分析（PCA）、最大相关最小冗余算法（mRMR）、自动解码器（Autoencoders）等。</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202311091748134.webp" alt="image-20231109174848949" style="zoom:50%;" /><p>决策级融合：也称为后期融合，是在获得基于每个模态的决策之后，通过应用多个预测类标签的代数组合规则（例如，最大值、最小值、总和、平均值等）对这些决策执行集成步骤。</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202311091749815.webp" alt="image-20231109174941622" style="zoom: 50%;" /><hr><p>“元分类器”（Meta-Classifier）是指在机器学习中用于组合多个基本分类器的高层次模型。元分类器的任务是利用基本分类器的预测结果来做出最终的决策。通常，这种组合的目的是提高整体模型的性能，尤其是在解决复杂问题或处理高维数据时。</p><p>元分类器可以采用不同的策略来组合基本分类器的输出。以下是一些常见的元分类器策略：</p><ol><li><strong>投票法（Voting）：</strong> 元分类器可以通过对多个基本分类器的预测进行投票来做出最终的决策。投票可以是硬投票（基于多数票）或软投票（考虑预测的概率）。</li><li><strong>堆叠法（Stacking）：</strong> 在堆叠中，多个基本分类器的预测结果被用作输入，然后通过另一个模型（元分类器）来组合这些结果。这个元分类器能够学习如何最好地结合基本分类器的输出。</li><li><strong>混合法（Blending）：</strong> 类似于堆叠，但在混合中，数据集被分成两部分，一部分用于训练基本分类器，另一部分用于训练元分类器。</li><li><strong>Boosting：</strong> 元分类器可以使用Boosting方法，其中每个基本分类器根据前一个分类器的性能进行加权，以纠正先前的错误。</li></ol><p>元分类器的选择和设计通常取决于特定问题的性质以及基本分类器的性能。使用元分类器的目标是整合不同分类器的优势，从而提高整体性能，减少过拟合，并提高模型的鲁棒性.</p><hr><p>混合级融合。它是早期融合和后期融合两个方法的结合，通过早期融合和单个模态预测的输出相结合。然而，混合级融合虽然改善了特征级融合和决策级的局限性，但是问题没有得到解决，只是这两种方案的折中。</p><p>模型级融合。该方法旨在获得三种模态的联合特征表示，它的实现主要取决于使用的融合模型。模型级融合是更深层次的融合方法，为分类和回归任务产生更优化的联合判别特征表示。以ML-LSTM为例，多层次LSTM（Multi-layers LSTM，ML-LSTM）作为模型级融合方法之一，该方法是将多层网络与传统的LSTM模型相结合，通过充分考虑话语之间的关系，来使得在学习过程中处理话语层面的多模态融合问题。</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202311091751744.webp" alt="image-20231109175108558" style="zoom:50%;" /><h1 id="多模态对齐"><a href="#多模态对齐" class="headerlink" title="多模态对齐"></a>多模态对齐</h1><h1 id="多模态的应用："><a href="#多模态的应用：" class="headerlink" title="多模态的应用："></a>多模态的应用：</h1><p><strong>Language-Audio</strong></p><ol><li>Text-to-Speech Synthesis: 给定文本，生成一段对应的声音。</li><li>Audio Captioning：给定一段语音，生成一句话总结并描述主要内容。(不是语音识别)</li></ol><p><strong>Vision-Audio</strong></p><ul><li>Audio-Visual Speech Recognition(视听语音识别)：给定某人的视频及语音进行语音识别。</li><li>Video Sound Separation(视频声源分离)：给定视频和声音信号(包含多个声源)，进行声源定位与分离。</li><li>Image Generation from Audio**:** 给定声音，生成与其相关的图像。</li><li>Speech-conditioned Face generation：给定一段话，生成说话人的视频。</li><li>Audio-Driven 3D Facial Animation：给定一段话与3D人脸模版，生成说话的人脸3D动画。</li></ul><p><strong>Vision-Language</strong></p><ul><li>Image&#x2F;Video-Text Retrieval (图(视频)文检索): 图像&#x2F;视频&lt;–&gt;文本的相互检索。</li><li>Image&#x2F;Video Captioning(图像&#x2F;视频描述)：给定一个图像&#x2F;视频，生成文本描述其主要内容。</li><li>Visual Question Answering(视觉问答)：给定一个图像&#x2F;视频与一个问题，预测答案。</li><li>Image&#x2F;Video Generation from Text：给定文本，生成相应的图像或视频。</li><li>Multimodal Machine Translation：给定一种语言的文本与该文本对应的图像，翻译为另外一种语言。</li><li>Vision-and-Language Navigation(视觉-语言导航)： 给定自然语言进行指导，使得智能体根据视觉传感器导航到特定的目标。</li><li>Multimodal Dialog(多模态对话)： 给定图像，历史对话，以及与图像相关的问题，预测该问题的回答。</li></ul><p><strong>定位相关的任务</strong></p><ul><li>Visual Grounding：给定一个图像与一段文本，定位到文本所描述的物体。</li><li>Temporal Language Localization: 给定一个视频即一段文本，定位到文本所描述的动作(预测起止时间)。</li><li>Video Summarization from text query：给定一段话(query)与一个视频，根据这段话的内容进行视频摘要，预测视频关键帧(或关键片段)组合为一个短的摘要视频。</li><li>Video Segmentation from Natural Language Query: 给定一段话(query)与一个视频，分割得到query所指示的物体。</li><li>Video-Language Inference: 给定视频(包括视频的一些字幕信息)，还有一段文本假设(hypothesis)，判断二者是否存在语义蕴含(二分类)，即判断视频内容是否包含这段文本的语义。</li><li>Object Tracking from Natural Language Query: 给定一段视频和一些文本，进行</li><li>Language-guided Image&#x2F;Video Editing: 一句话自动修图。给定一段指令(文本)，自动进行图像&#x2F;视频的编辑。</li></ul><p><strong>更多模态</strong></p><ul><li>Affect Computing (情感计算)：使用语音、视觉(人脸表情)、文本信息、心电、脑电等模态进行情感识别。</li><li>Medical Image：不同医疗图像模态如CT、MRI、PET</li><li>RGB-D模态：RGB图与深度图</li></ul>]]></content>
      
      
      <categories>
          
          <category> 多模态 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Multimodal </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>知识蒸馏</title>
      <link href="/posts/29167/"/>
      <url>/posts/29167/</url>
      
        <content type="html"><![CDATA[<p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202311252058596.webp" alt="image-20231125205827161"></p><p>Hard Targets 训练结果，得到 Soft Targets 去训练 Student 可能会更好。</p><p><strong>Soft Targets 含有更多得信息和知识。特别是非正确类别概率的相对大小。</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202311281650110.webp" alt="Knowledge-distillation-example"></p><h2 id="蒸馏温度T"><a href="#蒸馏温度T" class="headerlink" title="蒸馏温度T"></a>蒸馏温度T</h2><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202311252119768.webp" alt="image-20231125211905593" style="zoom:25%;" /><p>T 越高，target 越 soft ， T &#x3D; 1 时，就是普通的 softmax。</p><h2 id="知识蒸馏的过程"><a href="#知识蒸馏的过程" class="headerlink" title="知识蒸馏的过程"></a>知识蒸馏的过程</h2><p><strong>KL 散度</strong>、distallation loss：Student soft targets 与 Teacher 的 soft targets 的 loss；</p><p>Student loss ：Student hard prediction ：cross entropy</p><p>Total loss &#x3D; α Student loss + β Distallation loss</p><p>单个网络集成10倍构建教师网络</p><p>防止过拟合</p><h1 id="Distillation-loss"><a href="#Distillation-loss" class="headerlink" title="Distillation loss"></a>Distillation loss</h1><p>“Distillation loss”（蒸馏损失）通常是指在深度学习中的模型蒸馏（knowledge distillation）过程中用于衡量模型性能的损失函数。模型蒸馏是一种训练过程，旨在通过将一个较大且计算代价较高的模型的知识传递给一个较小且计算代价较低的模型来提高模型的效能。</p><p>在模型蒸馏中，通常涉及到两个模型：</p><ol><li><strong>教师模型（Teacher Model）：</strong> 通常是一个复杂而准确的模型，拥有较大的模型容量，能够捕捉复杂的模式和关系。</li><li><strong>学生模型（Student Model）：</strong> 通常是一个简化的模型，拥有较小的模型容量，计算代价较低。</li></ol><p>Distillation loss即为学生模型在训练中与教师模型之间的损失。该损失旨在确保学生模型能够捕捉到教师模型的知识，从而在拥有更小的体积和计算代价的同时，仍能保持较高的性能。</p><p>常见的蒸馏损失函数可以使用交叉熵（Cross Entropy）或均方误差（Mean Squared Error）等，具体的选择通常取决于任务和模型的特性。训练过程中，通过最小化蒸馏损失，学生模型被引导去模仿教师模型的输出。</p><p>总体来说，蒸馏损失是模型蒸馏过程中的关键组成部分，有助于在学生模型中保留教师模型的知识。这种技术通常用于在计算资源受限的环境中，通过减小模型体积和计算需求，仍然保持模型性能。</p><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><ul><li>模型压缩</li><li>优化训练，防止过拟合、潜在的正则化</li><li>无线大、无监督数据集的数据挖掘</li><li>少样本、零样本学习</li></ul><p>迁移学习（领域）和知识蒸馏（模型）的关系：正交</p><p>label smoothing : 把其他低概率的标签全部变成一个常数</p><h2 id="发展方向"><a href="#发展方向" class="headerlink" title="发展方向"></a>发展方向</h2><p>互相学习，Student 帮助 Teacher</p><p>助教，多个 Teacher ，多个 Student</p><p>知识的表示（网络的中间层是否也可以做知识蒸馏，如卷积 feature map）、数据集蒸馏、对比学习</p><p>多模态、知识图谱、预训练大模型</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202311281447192.webp" alt="image-20231128144656914" style="zoom: 67%;" />]]></content>
      
      
      <categories>
          
          <category> 知识蒸馏 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> KD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>随心</title>
      <link href="/posts/29166/"/>
      <url>/posts/29166/</url>
      
        <content type="html"><![CDATA[<h1 id="小波变换"><a href="#小波变换" class="headerlink" title="小波变换"></a>小波变换</h1><p>小波变换是一种数学工具，它将一个信号（通常是一维信号，例如时间序列）分解成不同尺度和频率成分的系数。我将通过一个简单的例子来解释小波变换的过程。</p><p>考虑一个包含了不同频率成分的信号，例如一个包含低频和高频成分的时间序列。我们将使用离散小波变换（Discrete Wavelet Transform，DWT）来分析这个信号。DWT的过程可以概括为以下几个步骤：</p><ol><li>选择小波函数：首先，选择一个合适的小波函数。不同的小波函数适用于不同类型的信号和分析任务。常见的小波函数包括哈尔小波、Daubechies小波、小波包等。每个小波函数都有不同的性质，如频率响应和时间局部性。</li><li>分解信号：将信号进行多层分解。在每个分解层，信号被分为两部分：近似部分（approximation）和细节部分（detail）。近似部分包含低频信息，而细节部分包含高频信息。</li><li>下采样：在每个分解层中，对近似部分和细节部分分别进行下采样，以减少数据量。</li><li>重复分解：重复上述步骤，直到达到所需的分解层数或直到近似系数不再包含有用信息为止。</li><li>获取小波系数：在每个分解层的结束，我们获得了一组近似系数和一组细节系数。这些系数表示信号在不同尺度和频率上的成分。</li></ol><h1 id="Fisher-准则"><a href="#Fisher-准则" class="headerlink" title="Fisher 准则"></a>Fisher 准则</h1><p>Fisher’s criterion（费舍尔准则），也称为Fisher’s Linear Discriminant（费舍尔线性判别），是一种用于特征选择和数据降维的技术。它是由英国统计学家罗纳德·费舍尔（Ronald A. Fisher）于1936年提出的，主要用于线性判别分析（Linear Discriminant Analysis，LDA）中。</p><p>Fisher’s criterion的主要目标是找到一个投影方向，使得不同类别的样本在这个方向上的均值之差尽可能大，同时类内方差之和尽可能小。具体来说，Fisher’s criterion通过以下公式来定义一个判别分数：</p><p>Fisher’s criterion &#x3D; (类间方差) &#x2F; (类内方差)</p><p>其中，类间方差表示不同类别的均值之差，类内方差表示每个类别内部的方差之和。</p><p>Fisher’s criterion的最优投影方向是使这个判别分数最大化的方向。这个方向对于分类问题非常有用，因为它可以帮助在低维空间中找到一个能够最好地区分不同类别的线性投影。</p><p>在实践中，Fisher’s criterion通常用于以下两种应用：</p><ol><li>特征选择：在高维数据中，Fisher’s criterion可以帮助选择最能够区分不同类别的特征（变量），从而降低数据维度，提高分类性能。</li><li>线性判别分析（LDA）：Fisher’s criterion是LDA的核心思想，用于将多维数据映射到低维空间，以便进行分类或模式识别。</li></ol><p>总之，Fisher’s criterion是一种有助于数据降维和特征选择的统计工具，它在模式识别、机器学习和数据分析中具有广泛的应用。</p><h1 id="CSP（Common-Spatial-Patterns）"><a href="#CSP（Common-Spatial-Patterns）" class="headerlink" title="CSP（Common Spatial Patterns）"></a>CSP（Common Spatial Patterns）</h1><p>CSP（Common Spatial Patterns）是一种常用于脑机接口（Brain-Computer Interface，BCI）和信号处理领域的特征提取算法，主要用于区分不同的脑电信号或脑成像数据（如EEG或fNIRS）中的类别。CSP算法的主要目标是找到一组空间滤波器，将输入信号转化为新的空间域，以最大化不同类别信号的差异，从而方便后续的分类任务。<strong>公共空间模式算法的基本原理是利用矩阵的对角化，找到一组最优空间滤波器进行投影，使得两类信号的方差值差异最大化，从而得到具有较高区分度的特征向量。</strong></p><p>以下是CSP算法的基本步骤：</p><ol><li>数据收集：首先，采集包含不同类别的脑信号数据，例如，一个BCI应用中可以包括不同类型的脑电图（EEG）数据。</li><li>数据预处理：对采集的数据进行预处理，包括滤波、降采样、去噪和滤波等步骤，以准备用于CSP算法的数据。</li><li>构建类别协方差矩阵：对每个类别的数据计算协方差矩阵，反映了每个类别的信号特点。通常，这是通过计算每个类别的数据样本的协方差矩阵来完成的。</li><li>特征提取：CSP算法的核心是通过计算空间滤波器，将数据映射到一个新的空间中，使得在这个新的空间中不同类别的方差最大化或差异最大化。这通常涉及到求解广义特征值问题，得到CSP投影矩阵。</li><li>数据投影：使用求解得到的CSP投影矩阵，将原始数据投影到新的CSP空间中。这将导致数据在新的空间中的特征向量之间更容易区分。</li><li>分类：最后，使用机器学习分类器（如支持向量机、k近邻等）来对CSP空间中的数据进行分类。由于CSP投影已经增强了不同类别的差异，分类任务通常更容易实现。</li></ol><p>CSP算法的主要优点是它可以帮助提取最具判别性的特征，从而改善信号分类性能。它在脑机接口、神经科学研究和脑信号分析中有广泛的应用，因为它能够帮助解决多类别脑信号分类问题。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202311072154219.webp" alt="image-20231107215411300"></p><h1 id="动态神经网络（Dynamic-Neural-Networks）："><a href="#动态神经网络（Dynamic-Neural-Networks）：" class="headerlink" title="动态神经网络（Dynamic Neural Networks）："></a>动态神经网络（Dynamic Neural Networks）：</h1><ol><li><strong>概念：</strong> 动态神经网络是指在模型的训练或推理过程中，动态地改变网络结构的一类神经网络。这与传统的静态神经网络不同，静态网络在训练过程中保持不变的结构。</li><li><strong>优点：</strong> 允许网络在处理不同输入时动态地调整自身结构，以适应不同的任务和数据分布。这样的网络更灵活，能够更好地适应复杂的场景和数据变化。</li><li><strong>应用：</strong> 动态神经网络常用于处理序列数据，如自然语言处理（NLP）任务中的文本处理或语音识别等。这种网络结构的动态性有助于处理变长序列和不同长度的输入。</li></ol><h1 id="神经架构搜索（Neural-Architecture-Search，NAS）："><a href="#神经架构搜索（Neural-Architecture-Search，NAS）：" class="headerlink" title="神经架构搜索（Neural Architecture Search，NAS）："></a>神经架构搜索（Neural Architecture Search，NAS）：</h1><ol><li><strong>概念：</strong> 神经架构搜索是一种自动化的方法，通过搜索神经网络的结构空间来找到最优的网络结构，以解决特定的任务。这个结构空间可以包括不同层数、宽度、连接方式等网络结构的变化。</li><li><strong>优点：</strong> 自动化搜索网络结构的过程，有望发现在人工设计中可能被忽略的有效结构，从而提高模型性能。NAS有助于解决手工设计网络结构的繁琐和耗时的问题。</li><li><strong>应用：</strong> NAS广泛应用于图像分类、目标检测、语音识别等各种深度学习任务。通过自动搜索网络结构，可以在不同的任务上获得更好的性能。</li></ol><h2 id="联系与区别："><a href="#联系与区别：" class="headerlink" title="联系与区别："></a>联系与区别：</h2><ul><li><strong>联系：</strong> 动态神经网络和神经架构搜索都关注于提高神经网络的灵活性和性能。</li><li><strong>区别：</strong> 动态神经网络强调在运行时动态地改变网络结构，而神经架构搜索关注于通过搜索算法找到最优的网络结构。</li></ul><h1 id="分类重新参数化"><a href="#分类重新参数化" class="headerlink" title="分类重新参数化"></a>分类重新参数化</h1><p>分类重新参数化是指在训练深度学习模型的过程中，通过重新参数化模型的输出层，改变模型的输出表示，从而提高模型的性能或增强其泛化能力。这种技术通常用于解决一些特定的问题或改进模型的训练过程。</p><p>以下是一些分类重新参数化的常见技术：</p><ol><li><strong>温度调节（Temperature Scaling）：</strong> 在Softmax函数中引入一个温度参数，通过调整这个参数，可以控制模型对概率分布的敏感性。温度调节在模型的不确定性估计和校准性能上有一定作用。</li><li><strong>标签平滑（Label Smoothing）：</strong> 在训练数据的标签中引入一些噪声，即将正确标签的概率从1降低到一个较小的值，将错误标签的概率从0增加到一个较小的值。这有助于使模型对训练数据更具有鲁棒性，减少过拟合的风险。</li><li><strong>Focal Loss：</strong> 由于在分类问题中，负类别样本通常占据绝大多数，而正类别样本相对较少，Focal Loss通过调整损失函数的权重，使得模型更加关注难以分类的正样本，从而改进了在不平衡类别问题上的性能。</li><li><strong>Mixup：</strong> Mixup是一种数据增强的方法，它通过线性插值的方式将两个不同样本的特征和标签进行混合，生成新的训练样本。这有助于模型更好地泛化到未见过的样本。</li><li><strong>CutMix：</strong> 类似于Mixup，但是CutMix在图像上进行操作，通过将一个图像的一部分覆盖到另一个图像上来生成新的训练样本。</li><li><strong>类别平衡的损失函数（Class-Balanced Loss）：</strong> 针对类别不平衡的问题，设计一些损失函数，使得在计算损失时考虑到每个类别的重要性，以达到更好的平衡。</li></ol><p>这些技术的目标通常是提高模型的泛化性能，使其在未见过的数据上表现更好，同时在训练过程中更加稳定。选择合适的重新参数化技术取决于具体的问题和数据分布。</p><h2 id="什么时候需要分类重新参数化？"><a href="#什么时候需要分类重新参数化？" class="headerlink" title="什么时候需要分类重新参数化？"></a>什么时候需要分类重新参数化？</h2><p>分类重新参数化的需要取决于具体的问题和数据情境。以下是一些通常情况下可能需要考虑分类重新参数化的情形：</p><ol><li><strong>类别不平衡：</strong> 当训练数据中的各个类别的样本数量差异很大时，可能导致模型在学习中更关注样本数较多的类别，而对样本数较少的类别学习不足。这时可以考虑使用类别平衡的损失函数或其他类别平衡的技术。</li><li><strong>模型过拟合：</strong> 如果模型在训练数据上表现很好，但在测试数据上表现较差，可能是由于过拟合造成的。这时可以考虑一些正则化方法或数据增强技术，如标签平滑、Mixup等。</li><li><strong>不确定性估计：</strong> 在一些应用中，对模型的不确定性估计很关键，例如在医学图像识别中。温度调节等技术可以帮助模型更准确地估计其预测的不确定性。</li><li><strong>数据分布变化：</strong> 如果模型在训练和测试阶段面临不同的数据分布，例如在实际应用中遇到的环境变化，可以考虑使用领域自适应或迁移学习技术，其中分类重新参数化可能是其中的一种手段。</li><li><strong>模型对噪声敏感：</strong> 如果训练数据中存在噪声或标签错误，可以考虑一些技术，如标签平滑、深度监督等，以提高模型对噪声的鲁棒性。</li><li><strong>解决梯度消失问题：</strong> 在深层网络中，梯度消失问题可能导致训练过程变得困难。一些重新参数化的技术，如残差连接，可以帮助缓解这个问题。</li></ol><p>总体来说，分类重新参数化通常在面临一些特定问题或者需要提升模型性能、稳定性时才被考虑使用。在选择具体的重新参数化技术时，需要根据具体问题和数据的特征进行权衡和选择。</p><h1 id="Gumbel-softmax"><a href="#Gumbel-softmax" class="headerlink" title="Gumbel-softmax"></a>Gumbel-softmax</h1><p>Gumbel-Softmax是一种用于处理离散概率分布的技术，特别是在深度学习中用于实现近似采样过程。这种技术通常应用于具有离散输出空间的神经网络，例如文本生成或分类问题。</p><h3 id="1-背景："><a href="#1-背景：" class="headerlink" title="1. 背景："></a>1. 背景：</h3><p>在神经网络中，通常使用Softmax函数将一个向量转换成一个概率分布。这对于分类问题非常有用，因为它确保输出概率的总和为1。然而，在训练期间，如果需要对输出进行采样（例如，从分类分布中选择一个类别），则这种离散采样是不可导的，使得在训练中使用梯度下降变得非常困难。</p><h3 id="2-Gumbel-Softmax技术："><a href="#2-Gumbel-Softmax技术：" class="headerlink" title="2. Gumbel-Softmax技术："></a>2. Gumbel-Softmax技术：</h3><p>Gumbel-Softmax通过引入Gumbel分布来近似离散采样。Gumbel分布是一种连续分布，它用于生成离散分布中的样本。通过以下步骤，可以使用Gumbel-Softmax技术在训练期间进行离散采样：</p><ul><li><strong>Gumbel分布采样：</strong> 从Gumbel分布中采样一些噪声，并应用逆Softmax操作，得到一个概率分布。</li><li><strong>逐元素乘法：</strong> 将这个概率分布与原始Softmax输出进行逐元素相乘。</li><li><strong>采样：</strong> 从乘法结果中进行采样，得到离散的类别。</li></ul><h3 id="3-公式："><a href="#3-公式：" class="headerlink" title="3. 公式："></a>3. 公式：</h3><p>给定一个具有k个类别的Softmax输出向量$\mathbf{x}$，Gumbel-Softmax的过程可以表示为：</p><ol><li>从Gumbel分布中采样噪声 $\mathbf{g}$：$\mathbf{g}_i &#x3D; -\log(-\log(u_i))$，其中$u_i$是来自均匀分布的样本。</li><li>计算带噪声的 logits：$\mathbf{y} &#x3D; \log(\mathbf{x}) + \mathbf{g}$</li><li>应用Softmax操作：$\mathbf{q}<em>i &#x3D; \frac{\exp(\frac{y_i}{\tau})}{\sum</em>{j&#x3D;1}^{k} \exp(\frac{y_j}{\tau})}$</li></ol><p>其中，$\tau$是温度参数，控制了Gumbel-Softmax输出分布的“软硬”程度。当$\tau$趋近于0时，Gumbel-Softmax接近离散的One-Hot编码。</p><h3 id="4-应用："><a href="#4-应用：" class="headerlink" title="4. 应用："></a>4. 应用：</h3><p>Gumbel-Softmax技术在生成模型中，尤其是在变分自编码器（Variational Autoencoders，VAEs）等场景中得到了广泛应用，以实现对离散输出的有效采样和训练。</p><h1 id="论文润色："><a href="#论文润色：" class="headerlink" title="论文润色："></a>论文润色：</h1><p>Hello chatgpt  , I would like to request your help in correcting my research paper in the area of EEG classification. I have already written the paper, but I need assistance in improving the language, grammar, spelling, and punctuation. My paper is intended for submission to a scholarly journal, and I need it to be error-free and polished to the highest standards: </p>]]></content>
      
      
      <categories>
          
          <category> 随心 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Let it go </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据分析与展示(北理)</title>
      <link href="/posts/29160/"/>
      <url>/posts/29160/</url>
      
        <content type="html"><![CDATA[<h1 id="数据分析与展示-北理"><a href="#数据分析与展示-北理" class="headerlink" title="数据分析与展示(北理)"></a>数据分析与展示(北理)</h1><p>Numpy （ndarry）—&gt; Matplotlib （pyplot）—&gt; Pandas （ series、DataFrame ）</p><p>列表和数组：一维数据的有序结构</p><p>区别：</p><p>列表数据类型可以不同</p><p>数组：数据类型相同</p><p>二维数据：一维数据的组合</p><p>表格是典型的二维数据</p><p>多维数据：一维或者二维数据在新的维度上扩展形成。例如时间维度。</p><p>高维数据：仅利用最基本的二元关系展示数据间的复杂结构。</p><p>由&#x3D;&#x3D;键值对&#x3D;&#x3D;将数据组织起来形成的数据方式</p><h2 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h2><p>强大的 N 维数组对象 ndarray</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310162003443.webp" alt="image-20231016200309172" style="zoom:50%;" /><p>可以去掉元素间循环</p><h3 id="ndarray"><a href="#ndarray" class="headerlink" title="ndarray"></a>ndarray</h3><p>实际的数据</p><p>描述这些数据的元数据（数据维度、数据类型）</p><p>轴（axis）：保存数据的维度</p><p>秩（rank）：轴的数量</p><p>属性：</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310162009663.webp" alt="image-20231016200923517" style="zoom:50%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310162010307.webp" alt="image-20231016201011165" style="zoom: 67%;" /><p>元素类型：</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310162011846.webp" alt="image-20231016201145671" style="zoom:67%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310162012855.webp" alt="image-20231016201219678" style="zoom:67%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310162012840.webp" alt="image-20231016201249663" style="zoom:67%;" /><p>从列表、元组等类型创建</p><p>使用创建函数</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310162018208.webp" alt="image-20231016201854055" style="zoom:67%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310162020849.webp" alt="image-20231016202045709" style="zoom:67%;" /><p>其他函数：</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310162022621.webp" alt="image-20231016202201493" style="zoom:67%;" /><p>起始元素，最后一个元素，元素个数</p><p>变换：维度变换、类型变换</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310162026218.webp" alt="image-20231016202614070" style="zoom:67%;" /><p>astype(类型) 会创建新数组</p><p>数组向列表转换：</p><p>list()</p><p>操作：索引、切片</p><p>起始：索引：步长</p><p>运算：</p><p>数组与标量：每一个元素与标量</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310162041940.webp" alt="image-20231016204136784" style="zoom:67%;" /><p>ceiling 表示不超过元素的整数值</p><p>floor 表示小于这个元素的最大整数值</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310162043399.webp" alt="image-20231016204310240" style="zoom:67%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310162056283.webp" alt="image-20231016205604112" style="zoom:67%;" /><h3 id="数据的-CSV-文件存取"><a href="#数据的-CSV-文件存取" class="headerlink" title="数据的 CSV 文件存取"></a>数据的 CSV 文件存取</h3><p>保存：</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310181919754.webp" alt="image-20231018191922403" style="zoom: 50%;" /><p>写入：</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310181922994.webp" alt="image-20231018192223683" style="zoom:50%;" /><p>只能有效存储一维和二维数据</p><p>多维数据的存取：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a.tofile(frame, seq=<span class="string">&#x27;&#x27;</span>, <span class="built_in">format</span>=<span class="string">&#x27;%s&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># frame: 文件、字符串</span></span><br><span class="line"><span class="comment"># seq: 数据分割字符串，如果是空串，写入文件为二进制。</span></span><br><span class="line"><span class="comment"># format: 写入数据格式</span></span><br></pre></td></tr></table></figure><p>读取：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a.fromfile(frame, dtype=<span class="built_in">float</span>, count= -<span class="number">1</span>, seq=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># frame: 文件、字符串</span></span><br><span class="line"><span class="comment"># dtype: 读取数据类型</span></span><br><span class="line"><span class="comment"># count: 读入元素个数，-1 为读取整个文件。</span></span><br><span class="line"><span class="comment"># seq: 数据分割字符串，如果是空串，写入文件为二进制</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>需要知道存入文件数组的维度和元素类型</p><p>a.tofile()、a.fromfile () 需要配合使用</p><p>Numpy 的便捷文件存取：</p><p>np.save（frame，array）或 np.savez（frame，array）</p><p>文件名、数组名</p><p>np.load（frame） </p><h3 id="Numpy-随机数函数："><a href="#Numpy-随机数函数：" class="headerlink" title="Numpy 随机数函数："></a>Numpy 随机数函数：</h3><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310181942823.webp" alt="image-20231018194203554" style="zoom: 50%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310181943534.webp" alt="image-20231018194305379" style="zoom:50%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310181945964.webp" alt="image-20231018194525808" style="zoom:50%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310181949091.webp" alt="image-20231018194949944" style="zoom:50%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310181951657.webp" alt="image-20231018195134440" style="zoom:50%;" /><h3 id="Numpy-统计函数："><a href="#Numpy-统计函数：" class="headerlink" title="Numpy 统计函数："></a>Numpy 统计函数：</h3><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310181952448.webp" alt="image-20231018195219282" style="zoom:67%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310181953404.webp" alt="image-20231018195335227" style="zoom: 50%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310181958968.webp" alt="image-20231018195828809" style="zoom: 80%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310181959384.webp" alt="image-20231018195947222" style="zoom:50%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310182001588.webp" alt="image-20231018200118412" style="zoom:80%;" /><h3 id="Numpy-的梯度函数："><a href="#Numpy-的梯度函数：" class="headerlink" title="Numpy 的梯度函数："></a>Numpy 的梯度函数：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">np.gradient(f)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算数组 f 中元素的梯度，当 f 为多维时，返回每个维度的梯度。</span></span><br></pre></td></tr></table></figure><p>梯度：连续值得变化率，斜率。</p><p>X Y 坐标轴连续的三个 X 坐标对应的 Y 轴值：a，b，c</p><p>&#x3D;&#x3D;其中，b的梯度是：（c-a）&#x2F;2&#x3D;&#x3D;</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310182007405.webp" alt="image-20231018200750236" style="zoom: 80%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310182012276.webp" alt="image-20231018201210111" style="zoom:80%;" /><h3 id="图像"><a href="#图像" class="headerlink" title="图像"></a>图像</h3><p>RGB：0-255</p><p>PIL库</p><p>from PIL import Image</p><p>shape: 高度、宽度、3</p><p>变换：</p><p>a &#x3D; np.array ( Image.open ( ) )</p><p>运算数组</p><p>数组还原为新图片</p><p>Image.fromarray（）</p><p>a &#x3D; np.array ( Image.open ( ) ) .convert （’  L ‘）  #灰度</p><h2 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h2><p>数据可视化</p><p>Matplotlib.pyplot库</p><p>import matplotlib.pyplot as plt</p><p>输出图形存储为文件：plt.savefig（）默认PNG 格式，可通过 dpi 修改输出质量（每一英寸空间中包含点的数量）</p><p>plt.plot（x ，y）</p><p>plt.axis ([-1, 10, 0, 6])  修改xy轴起始点与结束点 </p><h3 id="分割绘图区域subplot"><a href="#分割绘图区域subplot" class="headerlink" title="分割绘图区域subplot"></a>分割绘图区域subplot</h3><p>plt.subplot（nrows ，ncols，plot_number）</p><p>横轴数量、纵轴数量、绘图区域</p><p>plt.subplot（3，2，4）</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310191857241.webp" alt="image-20231019185703685"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310191908732.webp" alt="image-20231019190822558"></p><h3 id="pyplot-函数："><a href="#pyplot-函数：" class="headerlink" title="pyplot 函数："></a>pyplot 函数：</h3><p>plt.plot（ x，y，format_string, **Kwargs ）</p><p>x : X 轴数据，列表或者数组，可选。</p><p>y : Y轴数据，列表或者数组。</p><p>format_String : 控制曲线的格式字符串，可选。</p><p>**Kwargs：第二组或更多（x，y，format_string）</p><p>format_string : 控制曲线的格式字符串，可选。</p><p>可以直接在 ’ ‘ 中同时加三种字符。</p><p>也可以使用 color &#x3D; ‘ ’ ， linestyle &#x3D; ‘ ‘, maker &#x3D; ‘ ‘ ,  标记颜色makerfacecolor &#x3D; ‘ ‘ ，标记尺寸， markersize &#x3D; 20 。</p><p>由颜色字符、风格字符和标记字符组成</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310191921479.webp" alt="image-20231019192127326" style="zoom:50%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310191922078.webp" alt="image-20231019192238949" style="zoom:50%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310191925750.webp" alt="image-20231019192505573" style="zoom:50%;" /><h3 id="pyplot-的中文显示"><a href="#pyplot-的中文显示" class="headerlink" title="pyplot 的中文显示"></a>pyplot 的中文显示</h3><p>并不默认可以使用中文，如果要用中文可以：</p><p>方法一</p><p>impot matplotlib</p><p>matplotlib.rcParams [ ‘ font.family ‘ ] &#x3D; ‘SimHei’    #(黑体)</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310191947575.webp" alt="image-20231019194708422" style="zoom: 67%;" /><p>size 会改变图中出现的所有字符的大小</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310191947965.webp" alt="image-20231019194737816" style="zoom:67%;" /><p>方法二：</p><p>在有中文输入的地方，增加一个属性：fontproperties</p><p>输入中文后，在后面添加 fontproperties &#x3D; ‘ 字体’，也可以在后续加 font.size &#x3D;   ，此时的 size 只改变此处的字符大小。</p><h3 id="pyplot-的文本显示方法"><a href="#pyplot-的文本显示方法" class="headerlink" title="pyplot 的文本显示方法"></a>pyplot 的文本显示方法</h3><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310191954731.webp" alt="image-20231019195435600" style="zoom:67%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310192037971.webp" alt="image-20231019203722761"  /><p>plt.annotate &#x3D; ( s, xy &#x3D; arrow_crd,  xytext &#x3D; text_crd, arrowprops &#x3D; dict)</p><p>xy : 箭头显示位置</p><p>xytext：文本显示位置</p><p>arrowprops : 箭头属性</p><h3 id="子区域绘图subplot2grid"><a href="#子区域绘图subplot2grid" class="headerlink" title="子区域绘图subplot2grid"></a>子区域绘图subplot2grid</h3><p>复杂绘图区域</p><p>plt.subplot2grid ( )</p><p>plt.subplot2grid ( GridSpec , CurSpex，colspan &#x3D; 1, rowspan &#x3D; 1)</p><p>理念：设定网格，选中网格，确定选中行列区域数量，编号从0开始。</p><p>GridSpec ：一个元组，表示要将一个区域分割成什么样的网格形状。</p><p>CurSpex ：元组，选定的位置在哪里。</p><p>colspan ：选定位置列的延申长度</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310192116075.webp" alt="image-20231019211637829" style="zoom: 67%;" /><p>GridSpec 类</p><p>不用每次都写，使用GridSpec 类结合 subplot 也可达到上述效果</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310192118336.webp" alt="image-20231019211852113" style="zoom:67%;" /><p>第二个 有冒号是不包括那一列，所以是到第二列，没冒号是指最后一列</p><h3 id="pyplot-图表"><a href="#pyplot-图表" class="headerlink" title="pyplot 图表"></a>pyplot 图表</h3><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310211642867.webp" alt="image-20231021164212592" style="zoom: 50%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310211643681.webp" alt="image-20231021164321503" style="zoom: 50%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310211643296.webp" alt="image-20231021164355142" style="zoom:50%;" /><p>饼图的绘制：</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310211704394.webp" alt="image-20231021170449179" style="zoom:50%;" /><p>直方图的绘制：</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310211710442.webp" alt="image-20231021171007217" style="zoom:67%;" /><p>bin 表示直方的个数， normed 为 1 ，显示直方图的概率，取 0 ，显示出现的个数。</p><p>极坐标的绘制：</p><p>N 表示极坐标图中绘制数据的个数</p><p>projection ：绘制图的类型</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310211718597.webp" alt="image-20231021171813364" style="zoom:67%;" /><p>散点图的绘制：</p><p>面向对象</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310211723615.webp" alt="image-20231021172319455"></p>]]></content>
      
      
      <categories>
          
          <category> 数据分析 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据分析 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch Neural Network</title>
      <link href="/posts/29164/"/>
      <url>/posts/29164/</url>
      
        <content type="html"><![CDATA[<h1 id="Pytorch-Neural-Network"><a href="#Pytorch-Neural-Network" class="headerlink" title="Pytorch Neural Network"></a>Pytorch Neural Network</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># import</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn    <span class="comment"># All neural network modules</span></span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim     <span class="comment"># For optimizers like SGD, Adam, etc.</span></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F    <span class="comment"># Parameterless functions, like (some) activation functions</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> (DataLoader,) <span class="comment">#加载数据集</span></span><br><span class="line"><span class="keyword">import</span> torchvision.datasets <span class="keyword">as</span> datasets    <span class="comment"># Standard datasets</span></span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms <span class="comment"># Transformations we can perform on our dataset for augmentation</span></span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="comment"># creat Fully connected network</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(NN, self).__init__() </span><br><span class="line">        self.fc1 = nn.Linear(input_size, <span class="number">50</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">50</span>, num_classes)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#检查一下，模型有没有起作用</span></span><br><span class="line">    <span class="comment"># model = NN(784,10)</span></span><br><span class="line">    <span class="comment"># x = torch.randn(64,784)</span></span><br><span class="line">    <span class="comment"># print(model(x).shape)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># set device</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span><span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Hyperparanmeter</span></span><br><span class="line">input_size = <span class="number">784</span>   <span class="comment"># 28*28 手写数字识别</span></span><br><span class="line">num_classes = <span class="number">10</span> </span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">num_epochs = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load data</span></span><br><span class="line"></span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&quot;dataset/&quot;</span>, train=<span class="literal">True</span>, transform=transforms.ToTensor(), download=<span class="literal">True</span>)</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># root：这是指定 MNIST 数据集的根目录的参数。如果该目录不存在，它将被创建。</span></span><br><span class="line">    <span class="comment"># 它将 MNIST 图像数据转换为 PyTorch 张量。transforms.ToTensor() 将图像从 PIL 格式转换为张量，并将像素值缩放到范围 [0, 1]</span></span><br><span class="line">    <span class="comment"># download=True：如果数据集尚未下载到指定的 root 目录中，这个参数将自动下载 MNIST 数据集。</span></span><br><span class="line">  </span><br><span class="line">train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># shuffle=True：这个参数指定是否在每个 epoch（训练周期）之前对数据进行洗牌（随机重排）。</span></span><br><span class="line">    <span class="comment"># 洗牌可以帮助模型更好地学习，因为它会打破数据的顺序，防止模型过于依赖数据的排列顺序。</span></span><br><span class="line">    </span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;dataset/&#x27;</span>, train=<span class="literal">False</span>, transform=transforms.ToTensor(), download=<span class="literal">True</span>)</span><br><span class="line">test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize network</span></span><br><span class="line"></span><br><span class="line">model = NN(input_size=input_size, num_classes= num_classes).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loss and optimizer</span></span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train network</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> batch_idx,(data, targets) <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(train_loader)):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># enumerate 的应用，用于同时获取循环索引和批次数据。</span></span><br><span class="line">        </span><br><span class="line">        data = data.to(device=device)</span><br><span class="line">        targets = targets.to(device=device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 这两行代码将数据张量和目标标签移动到指定的设备上进行训练。</span></span><br><span class="line">        </span><br><span class="line">        data = data.reshape(data.shape[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 重塑成正确的形状</span></span><br><span class="line">        <span class="comment"># 前向传播</span></span><br><span class="line">        scores = model(data)</span><br><span class="line">        loss = criterion(scores, targets)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#反向传播</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#梯度下降和adam优化</span></span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line"><span class="comment"># Check accuracy on training &amp; test to see how our model</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_accuracy</span>(<span class="params">loader, model</span>):</span><br><span class="line">    <span class="comment"># if loader.dataset.train:</span></span><br><span class="line">    <span class="comment">#         print(&quot;训练集准确率为：&quot;)</span></span><br><span class="line">    <span class="comment"># else:</span></span><br><span class="line">    <span class="comment">#         print(&quot;测试集准确率为：&quot;)</span></span><br><span class="line">            </span><br><span class="line">    num_correct = <span class="number">0</span></span><br><span class="line">    num_samples = <span class="number">0</span> </span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():  </span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> loader:</span><br><span class="line">            x = x.to(device=device)</span><br><span class="line">            y = y.to(device=device)</span><br><span class="line">            </span><br><span class="line">            x = x.reshape(x.shape[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line">            </span><br><span class="line">            scores = model(x)</span><br><span class="line">            _, predictions = scores.<span class="built_in">max</span>(<span class="number">1</span>)</span><br><span class="line">            num_correct += (predictions == y).<span class="built_in">sum</span>()</span><br><span class="line">            num_samples += predictions.size(<span class="number">0</span>)</span><br><span class="line">            </span><br><span class="line">        model.train()</span><br><span class="line">    <span class="keyword">return</span> num_correct / num_samples</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Check accuracy on training &amp; test to see how good our model</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Accuracy on training set: <span class="subst">&#123;check_accuracy(train_loader, model)*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Accuracy on test set: <span class="subst">&#123;check_accuracy(test_loader, model)*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">      </span><br><span class="line">            </span><br></pre></td></tr></table></figure><hr><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310070955316.webp" alt="image-20231007095526051"></p><h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># import</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn    <span class="comment"># All neural network modules</span></span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim     <span class="comment"># For optimizers like SGD, Adam, etc.</span></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F    <span class="comment"># Parameterless functions, like (some) activation functions</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> (DataLoader,) <span class="comment">#加载数据集</span></span><br><span class="line"><span class="keyword">import</span> torchvision.datasets <span class="keyword">as</span> datasets    <span class="comment"># Standard datasets</span></span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms <span class="comment"># Transformations we can perform on our dataset for augmentation</span></span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="comment"># creat Fully connected network</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">NN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(NN, self).__init__() </span><br><span class="line">        self.fc1 = nn.Linear(input_size, <span class="number">50</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">50</span>, num_classes)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#检查一下，模型有没有起作用</span></span><br><span class="line">    <span class="comment"># model = NN(784,10)</span></span><br><span class="line">    <span class="comment"># x = torch.randn(64,784)</span></span><br><span class="line">    <span class="comment"># print(model(x).shape)</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="comment"># creat simple cnn</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels = <span class="number">1</span> , num_classes = <span class="number">10</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(CNN, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=<span class="number">1</span>, out_channels=<span class="number">8</span>, kernel_size=(<span class="number">3</span>,<span class="number">3</span>), stride=(<span class="number">1</span>,<span class="number">1</span>), padding=(<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">        self.pool = nn.MaxPool2d(kernel_size=(<span class="number">2</span>,<span class="number">2</span>), stride=(<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">        self.conv2 = nn.Conv2d(in_channels=<span class="number">8</span>, out_channels=<span class="number">16</span>, kernel_size=(<span class="number">3</span>,<span class="number">3</span>), stride=(<span class="number">1</span>,<span class="number">1</span>), padding=(<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span>*<span class="number">7</span>*<span class="number">7</span>, num_classes)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(self.conv1(x))</span><br><span class="line">        x = self.pool(x)</span><br><span class="line">        </span><br><span class="line">        x = F.relu(self.conv2(x))</span><br><span class="line">        x = self.pool(x)</span><br><span class="line">        </span><br><span class="line">        x = x.reshape(x.shape[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line"><span class="comment"># model = CNN()</span></span><br><span class="line"><span class="comment"># x = torch.randn(64,1,28,28)</span></span><br><span class="line"><span class="comment"># print(model(x).shape)</span></span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line"><span class="comment"># set device</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span><span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Hyperparanmeter</span></span><br><span class="line">input_channel = <span class="number">1</span>  <span class="comment"># 28*28 手写数字识别</span></span><br><span class="line">num_classes = <span class="number">10</span> </span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">num_epochs = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load data</span></span><br><span class="line"></span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&quot;dataset/&quot;</span>, train=<span class="literal">True</span>, transform=transforms.ToTensor(), download=<span class="literal">True</span>)</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># root：这是指定 MNIST 数据集的根目录的参数。如果该目录不存在，它将被创建。</span></span><br><span class="line">    <span class="comment"># 它将 MNIST 图像数据转换为 PyTorch 张量。transforms.ToTensor() 将图像从 PIL 格式转换为张量，并将像素值缩放到范围 [0, 1]</span></span><br><span class="line">    <span class="comment"># download=True：如果数据集尚未下载到指定的 root 目录中，这个参数将自动下载 MNIST 数据集。</span></span><br><span class="line">  </span><br><span class="line">train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># shuffle=True：这个参数指定是否在每个 epoch（训练周期）之前对数据进行洗牌（随机重排）。</span></span><br><span class="line">    <span class="comment"># 洗牌可以帮助模型更好地学习，因为它会打破数据的顺序，防止模型过于依赖数据的排列顺序。</span></span><br><span class="line">    </span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;dataset/&#x27;</span>, train=<span class="literal">False</span>, transform=transforms.ToTensor(), download=<span class="literal">True</span>)</span><br><span class="line">test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize network</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#model = NN(input_size=input_size, num_classes= num_classes).to(device)</span></span><br><span class="line">model = CNN().to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loss and optimizer</span></span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train network</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> batch_idx,(data, targets) <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(train_loader)):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># enumerate 的应用，用于同时获取循环索引和批次数据。</span></span><br><span class="line">        </span><br><span class="line">        data = data.to(device=device)</span><br><span class="line">        targets = targets.to(device=device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 这两行代码将数据张量和目标标签移动到指定的设备上进行训练。</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># data = data.reshape(data.shape[0], -1)</span></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 重塑成正确的形状</span></span><br><span class="line">        <span class="comment"># 前向传播</span></span><br><span class="line">        scores = model(data)</span><br><span class="line">        loss = criterion(scores, targets)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#反向传播</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#梯度下降和adam优化</span></span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line"><span class="comment"># Check accuracy on training &amp; test to see how our model</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_accuracy</span>(<span class="params">loader, model</span>):</span><br><span class="line">    <span class="comment"># if loader.dataset.train:</span></span><br><span class="line">    <span class="comment">#         print(&quot;训练集准确率为：&quot;)</span></span><br><span class="line">    <span class="comment"># else:</span></span><br><span class="line">    <span class="comment">#         print(&quot;测试集准确率为：&quot;)</span></span><br><span class="line">            </span><br><span class="line">    num_correct = <span class="number">0</span></span><br><span class="line">    num_samples = <span class="number">0</span> </span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():  </span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> loader:</span><br><span class="line">            x = x.to(device=device)</span><br><span class="line">            y = y.to(device=device)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># x = x.reshape(x.shape[0], -1)</span></span><br><span class="line">            </span><br><span class="line">            scores = model(x)</span><br><span class="line">            _, predictions = scores.<span class="built_in">max</span>(<span class="number">1</span>)</span><br><span class="line">            num_correct += (predictions == y).<span class="built_in">sum</span>()</span><br><span class="line">            num_samples += predictions.size(<span class="number">0</span>)</span><br><span class="line">            </span><br><span class="line">        model.train()</span><br><span class="line">    <span class="keyword">return</span> num_correct / num_samples</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Check accuracy on training &amp; test to see how good our model</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Accuracy on training set: <span class="subst">&#123;check_accuracy(train_loader, model)*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Accuracy on test set: <span class="subst">&#123;check_accuracy(test_loader, model)*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">      </span><br><span class="line">            </span><br></pre></td></tr></table></figure><h1 id="RNN、GRU、LSTM"><a href="#RNN、GRU、LSTM" class="headerlink" title="RNN、GRU、LSTM"></a>RNN、GRU、LSTM</h1><ol><li>初始隐藏状态 <code>h0</code>（Initial Hidden State）：<ul><li>h0是LSTM网络在序列开始之前的初始隐藏状态。它是一个张量，其形状为 (num_layers, batch_size, hidden_size)，其中：<ul><li><code>num_layers</code> 是LSTM层数。</li><li><code>batch_size</code> 是批处理大小。</li><li><code>hidden_size</code> 是隐藏状态的大小。</li></ul></li><li>初始隐藏状态 <code>h0</code> 包含了模型在开始处理序列数据之前的信息。它通常可以被设置为零向量，也可以根据具体任务和应用从数据中提取或进行初始化。</li></ul></li><li>细胞状态 <code>c0</code>（Cell State）：<ul><li><code>c0</code> 是LSTM网络的初始细胞状态，也是一个张量，其形状与初始隐藏状态相同，即 <code>(num_layers, batch_size, hidden_size)</code>。</li><li>细胞状态 <code>c0</code> 是LSTM网络用于存储和传递信息的一部分，它在整个序列处理过程中被更新和调整。</li></ul></li></ol><p>在LSTM中，这些初始状态 <code>h0</code> 和 <code>c0</code> 对于序列数据的处理非常重要。它们可以通过手动设置为零向量，从数据中提取，或者根据任务和应用进行初始化。在训练和推断期间，LSTM网络将根据序列数据的信息来更新这些状态，并在序列处理中捕获长期依赖关系。这些状态对于LSTM的功能至关重要，有助于网络记住和理解序列中的重要信息。</p><hr><p>在循环神经网络（RNN）、门控循环单元（GRU）等循环神经网络架构中，通常只需要一个初始隐藏状态 <code>h0</code> 而不需要初始细胞状态 <code>c0</code> 的原因是：</p><ol><li>RNN 和 GRU 中的细胞状态 <code>c</code> 的设计差异：<ul><li>在LSTM（长短时记忆网络）中，细胞状态 <code>c</code> 是网络的一部分，它具有自己的状态并负责捕捉序列中的长期依赖关系。LSTM中的更新门和遗忘门用于控制细胞状态的更新和遗忘。</li><li>与此不同，GRU设计得更加简化，它没有显式的细胞状态 <code>c</code>。GRU将隐藏状态 <code>h</code> 和记忆门（memory gate）结合在一起，以实现类似的功能，但减少了参数量和计算复杂性。</li></ul></li><li>简化网络结构：<ul><li>GRU是为了简化LSTM而设计的，以降低模型的复杂性。GRU中只有一个隐藏状态，不需要额外的细胞状态 <code>c</code>。</li><li>简化的结构使得GRU更容易训练，减少了参数数量，同时在许多序列建模任务中表现出色。</li></ul></li></ol><hr><p><code>out, _ = self.rnn(x, h0)</code> 这行代码使用了 Python 中的解构（unpacking）语法，它的目的是从 <code>self.rnn(x, h0)</code> 的返回值中获取两个变量：<code>out</code> 和 <code>_</code>。</p><p>在这里，<code>self.rnn(x, h0)</code> 返回了一个元组，其中包含两个值：第一个值是模型的输出 <code>out</code>，第二个值是状态信息，通常是隐藏状态（在RNN中是 <code>h</code>）。</p><p>解构语法 <code>out, _ = ...</code> 中的下划线 <code>_</code> 通常用作一个占位符，表示我们不打算使用或进一步处理第二个返回值。因此，我们只提取了 <code>out</code>，并将其用于后续的计算。</p><p>如果您有兴趣获取并使用隐藏状态或其他返回值，可以将下划线 <code>_</code> 替换为适当的变量名，并将其用于后续的计算。但如果您不需要这个值，可以使用下划线 <code>_</code> 来忽略它，这是一种常见的做法，用于表明我们不关心或不使用某个特定值。</p><hr><p><code>out = self.fc(out[:, -1, :])</code> 这行代码用于计算模型的最终输出：</p><ol><li><code>out</code> 是模型中RNN层的输出，它是一个三维张量，具有形状 <code>(batch_size, sequence_length, hidden_size)</code>。在这个张量中，每个时间步的隐藏状态都被保存在不同的时间步维度上。</li><li><code>out[:, -1, :]</code> 是 Python 切片（slicing）操作，用于从 <code>out</code> 张量中选择所有批次（<code>:</code> 表示选择所有批次）、最后一个时间步（<code>-1</code> 表示最后一个时间步）以及所有隐藏单元（<code>:</code> 表示选择所有隐藏单元）。结果是一个形状为 <code>(batch_size, hidden_size)</code> 的张量，其中包含了每个样本在序列的最后一个时间步的隐藏状态信息。</li><li><code>self.fc</code> 是一个全连接（fully connected）层，用于将隐藏状态映射到输出空间。这个全连接层的初始化在模型的 <code>__init__</code> 方法中定义。</li><li>最终，<code>self.fc(out[:, -1, :])</code> 将最后一个时间步的隐藏状态传递给全连接层 <code>self.fc</code>，并计算模型的最终输出。这个输出通常用于最终的分类或回归任务，具体取决于模型的用途。</li></ol><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># import</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn    <span class="comment"># All neural network modules</span></span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim     <span class="comment"># For optimizers like SGD, Adam, etc.</span></span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F    <span class="comment"># Parameterless functions, like (some) activation functions</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> (DataLoader,) <span class="comment">#加载数据集</span></span><br><span class="line"><span class="keyword">import</span> torchvision.datasets <span class="keyword">as</span> datasets    <span class="comment"># Standard datasets</span></span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms <span class="comment"># Transformations we can perform on our dataset for augmentation</span></span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="comment"># create Fully connected network</span></span><br><span class="line"><span class="comment"># class NN(nn.Module):</span></span><br><span class="line"><span class="comment">#     def __init__(self, input_size, num_classes):</span></span><br><span class="line"><span class="comment">#         super(NN, self).__init__() </span></span><br><span class="line"><span class="comment">#         self.fc1 = nn.Linear(input_size, 50)</span></span><br><span class="line"><span class="comment">#         self.fc2 = nn.Linear(50, num_classes)</span></span><br><span class="line">        </span><br><span class="line"><span class="comment">#     def forward(self, x):</span></span><br><span class="line"><span class="comment">#         x = F.relu(self.fc1(x))</span></span><br><span class="line"><span class="comment">#         x = self.fc2(x)</span></span><br><span class="line"><span class="comment">#         return x</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#检查一下，模型有没有起作用</span></span><br><span class="line">    <span class="comment"># model = NN(784,10)</span></span><br><span class="line">    <span class="comment"># x = torch.randn(64,784)</span></span><br><span class="line">    <span class="comment"># print(model(x).shape)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># set device</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span><span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Hyperparanmeter</span></span><br><span class="line">input_size = <span class="number">28</span>  <span class="comment"># 几乎不在图像上用RNN</span></span><br><span class="line">sequence_length  = <span class="number">28</span></span><br><span class="line">num_layers = <span class="number">2</span></span><br><span class="line">hidden_size = <span class="number">256</span></span><br><span class="line">num_classes = <span class="number">10</span> </span><br><span class="line">learning_rate = <span class="number">0.001</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">num_epochs = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># create a RNN</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># class RNN(nn.Module):</span></span><br><span class="line"><span class="comment">#     def __init__(self, input_size, hidden_size, num_layers, num_classes):</span></span><br><span class="line"><span class="comment">#         super(RNN, self).__init__()</span></span><br><span class="line"><span class="comment">#         self.hidden_size = hidden_size</span></span><br><span class="line"><span class="comment">#         self.num_layers = num_layers</span></span><br><span class="line"><span class="comment">#         self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True)</span></span><br><span class="line"><span class="comment">#         # N* time_sequence * features</span></span><br><span class="line"><span class="comment">#         self.fc = nn.Linear(hidden_size * sequence_length, num_classes)</span></span><br><span class="line">    </span><br><span class="line"><span class="comment">#     def forward (self ,x ):</span></span><br><span class="line"><span class="comment">#         h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)</span></span><br><span class="line"><span class="comment">#         c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)</span></span><br><span class="line"><span class="comment">#         #forward prop</span></span><br><span class="line"><span class="comment">#         out, _ = self.lstm(x, (h0, c0))</span></span><br><span class="line"><span class="comment">#         out = out.reshape(out.shape[0], -1)</span></span><br><span class="line"><span class="comment">#         out = self.fc(out)</span></span><br><span class="line"><span class="comment">#         return out</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># create bi-lstm</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BRNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, hidden_size, num_layers, num_classes</span>):</span><br><span class="line">        <span class="built_in">super</span>(BRNN, self).__init__()</span><br><span class="line">        self.hidden_size = hidden_size</span><br><span class="line">        self.num_layers = num_layers</span><br><span class="line">        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = <span class="literal">True</span>, bidirectional = <span class="literal">True</span>)</span><br><span class="line">        self.fc = nn.Linear(hidden_size * <span class="number">2</span>, num_classes)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span> (self, x):</span><br><span class="line">        h0 = torch.zeros(self.num_layers * <span class="number">2</span>, x.size(<span class="number">0</span>), self.hidden_size).to(device)  <span class="comment"># Note: Multiply by 2 for bidirectional LSTM</span></span><br><span class="line">        c0 = torch.zeros(self.num_layers * <span class="number">2</span>, x.size(<span class="number">0</span>), self.hidden_size).to(device) </span><br><span class="line">        out, _ = self.lstm(x, (h0, c0))</span><br><span class="line">        out = self.fc(out[:, -<span class="number">1</span>, :])  <span class="comment"># Get the last time step&#x27;s output</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load data</span></span><br><span class="line"></span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">&quot;dataset/&quot;</span>, train=<span class="literal">True</span>, transform=transforms.ToTensor(), download=<span class="literal">True</span>)</span><br><span class="line">  </span><br><span class="line">    <span class="comment"># root：这是指定 MNIST 数据集的根目录的参数。如果该目录不存在，它将被创建。</span></span><br><span class="line">    <span class="comment"># 它将 MNIST 图像数据转换为 PyTorch 张量。transforms.ToTensor() 将图像从 PIL 格式转换为张量，并将像素值缩放到范围 [0, 1]</span></span><br><span class="line">    <span class="comment"># download=True：如果数据集尚未下载到指定的 root 目录中，这个参数将自动下载 MNIST 数据集。</span></span><br><span class="line">  </span><br><span class="line">train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># shuffle=True：这个参数指定是否在每个 epoch（训练周期）之前对数据进行洗牌（随机重排）。</span></span><br><span class="line">    <span class="comment"># 洗牌可以帮助模型更好地学习，因为它会打破数据的顺序，防止模型过于依赖数据的排列顺序。</span></span><br><span class="line">    </span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">&#x27;dataset/&#x27;</span>, train=<span class="literal">False</span>, transform=transforms.ToTensor(), download=<span class="literal">True</span>)</span><br><span class="line">test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize network</span></span><br><span class="line"></span><br><span class="line">model = BRNN(input_size, hidden_size, num_layers, num_classes).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loss and optimizer</span></span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train network</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="keyword">for</span> batch_idx,(data, targets) <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(train_loader)):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># enumerate 的应用，用于同时获取循环索引和批次数据。</span></span><br><span class="line">        </span><br><span class="line">        data = data.to(device=device).squeeze(<span class="number">1</span>)</span><br><span class="line">        targets = targets.to(device=device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 这两行代码将数据张量和目标标签移动到指定的设备上进行训练。</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># data = data.reshape(data.shape[0], -1)</span></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 重塑成正确的形状</span></span><br><span class="line">        <span class="comment"># 前向传播</span></span><br><span class="line">        scores = model(data)</span><br><span class="line">        loss = criterion(scores, targets)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#反向传播</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#梯度下降和adam优化</span></span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line"><span class="comment"># Check accuracy on training &amp; test to see how our model</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_accuracy</span>(<span class="params">loader, model</span>):</span><br><span class="line">    <span class="comment"># if loader.dataset.train:</span></span><br><span class="line">    <span class="comment">#         print(&quot;训练集准确率为：&quot;)</span></span><br><span class="line">    <span class="comment"># else:</span></span><br><span class="line">    <span class="comment">#         print(&quot;测试集准确率为：&quot;)</span></span><br><span class="line">            </span><br><span class="line">    num_correct = <span class="number">0</span></span><br><span class="line">    num_samples = <span class="number">0</span> </span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():  </span><br><span class="line">        <span class="keyword">for</span> x, y <span class="keyword">in</span> loader:</span><br><span class="line">            x = x.to(device=device).squeeze(<span class="number">1</span>)</span><br><span class="line">            y = y.to(device=device)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># x = x.reshape(x.shape[0], -1)</span></span><br><span class="line">            </span><br><span class="line">            scores = model(x)</span><br><span class="line">            _, predictions = scores.<span class="built_in">max</span>(<span class="number">1</span>)</span><br><span class="line">            num_correct += (predictions == y).<span class="built_in">sum</span>()</span><br><span class="line">            num_samples += predictions.size(<span class="number">0</span>)</span><br><span class="line">            </span><br><span class="line">        model.train()</span><br><span class="line">    <span class="keyword">return</span> num_correct / num_samples</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Check accuracy on training &amp; test to see how good our model</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Accuracy on training set: <span class="subst">&#123;check_accuracy(train_loader, model)*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Accuracy on test set: <span class="subst">&#123;check_accuracy(test_loader, model)*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">      </span><br><span class="line">            </span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>预训练语言模型的前世今生</title>
      <link href="/posts/29163/"/>
      <url>/posts/29163/</url>
      
        <content type="html"><![CDATA[<p>参考、感谢：<a href="https://www.cnblogs.com/nickchen121/p/15105048.html">Transformer、GPT、BERT，预训练语言模型的前世今生（目录） - B站-水论文的程序猿 - 博客园 (cnblogs.com)</a></p><h1 id="01预训练"><a href="#01预训练" class="headerlink" title="01预训练"></a>01预训练</h1><p>预先训练</p><p>两个相似的任务 A 和 B ，任务 A 已经完成了得到一个模型 A 。</p><p>任务 B ( 数据量小 )</p><p>用到一个特性： CNN 浅层参数通用</p><p>任务 B 就可以使用模型 A 的浅层参数，后面的参数通过 B 训练 —》1.冻结（浅层参数不变） 2.微调（变）</p><p>任务 B (大数据）可以训练出模型 B （还可以使用模型 A 的浅层参数，节省训练实践，节省成本）</p><h1 id="02统计语言模型"><a href="#02统计语言模型" class="headerlink" title="02统计语言模型"></a>02统计语言模型</h1><h2 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h2><p>语言（人说的话） + 模型（为了完成某个任务）</p><ol><li>比较：p（“判断这个词的词性”），p（“判断这个词的磁性”）</li><li>预测下一个任务：“判断这个词的<code>_____</code>”</li></ol><h2 id="统计语言模型"><a href="#统计语言模型" class="headerlink" title="统计语言模型"></a>统计语言模型</h2><p>用统计的方法解决上述两个问题</p><p>“判断这个词的词性” &#x3D; ”判断”，“这”，“个”，“词”，“的”，“词性”</p><p>这句话是序列（有顺序的）</p><p>用一个条件概率的链式法则（概率论）</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310041014015.webp" alt="条件概率公式"></p><p>通过这个法则，我们可以求出每一个词出现的概率，然后连乘，就是这句话出现的概率。</p><p>解决第二个问题：</p><p> “判断这个词的<code>_____</code>”</p><p>p（w_next| ”判断”，“这”，“个”，“词”，“的”）—–（1）</p><p>词库（词典–V），搞出一个集合，把所有词装入集合 V 里</p><p>把集合里的每一个词，都进行上一步（1）的计算</p><p>词库 V &#x3D; {“词性”，“火星”}</p><p>p（词性| ”判断”，“这”，“个”，“词”，“的”）</p><p>p（火星| ”判断”，“这”，“个”，“词”，“的”）</p><p>p（词性| ”判断”，“这”，“个”，“词”，“的”，…………）</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310041022539.webp" alt="image-20231004102258396"></p><h2 id="n元统计语言模型"><a href="#n元统计语言模型" class="headerlink" title="n元统计语言模型"></a>n元统计语言模型</h2><p>p（词性| “这”，“个”，“词”，“的”）</p><p>p（火星| “这”，“个”，“词”，“的”）</p><p>p（词性|“词”，“的”）</p><p>p（词性|“的”）</p><p>把 n 个词，取 2 个词（二元），取 3 个词（三元）</p><h2 id="如何去计算"><a href="#如何去计算" class="headerlink" title="如何去计算"></a>如何去计算</h2><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">“词性是动词”</span><br><span class="line">“判断单词的词性”</span><br><span class="line">“磁性很强的磁铁”</span><br><span class="line">“北京的词性是名词”</span><br></pre></td></tr></table></figure><p>$$<br>p(词性|的)&#x3D;\frac{count(词，的)}{count(的)}&#x3D;\frac{2}{3}<br>$$</p><h2 id="平滑策略"><a href="#平滑策略" class="headerlink" title="平滑策略"></a>平滑策略</h2><p>由于数据稀疏问题，则会出现概率值为 0 的情况（填空题将无法从词典中选择一个词填入），为了避免 0 值的出现，会使用一种平滑的策略——分子和分母都加入一个非 0 正数，</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310041037052.webp" alt="image-20231004103729910"></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>语言模型： 计算一句话的概率，计算下一个词可能是什么</p><p>统计语言模型：统计的方法去解决语言模型的问题（条件概率）</p><p>n元语言模型：只取一部分词</p><p>平滑策略：词未在库中出现</p><h1 id="03神经网络语言模型"><a href="#03神经网络语言模型" class="headerlink" title="03神经网络语言模型"></a>03神经网络语言模型</h1><p>神经网络 + 语言模型—–&gt; 用神经网络的方法去完成上述任务</p><p>第二个任务</p><p>“判断”，“这个”，“词”，“的”，”<code>____</code>“</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310041119683.webp" alt="image-20231004111956451" style="zoom: 80%;" /><p>w1,w2.w3,w4(上述四个单词的独热编码)</p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">w1*Q = c1,</span><br><span class="line">w2*Q = c2,</span><br><span class="line">w3*Q = c3,</span><br><span class="line">w4*Q = c4,</span><br><span class="line"></span><br><span class="line">C = [c1,c2,c3,c4]</span><br><span class="line">Q 一个随机矩阵，是一个参数（可学习）</span><br><span class="line">有残差，下述内容忽略残差部分</span><br></pre></td></tr></table></figure><p>“判断”  “这个”  “词”   “的”    “词性”</p><p>softmax (U[tanh(WC+b1)]+b2)  &#x3D;&#x3D; [0.1, 0.1 , 0.2 , 0.2, 0.4 ]  假设是5维<br>$$<br>\in (1,V_L)<br>$$</p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">上图所示有一个 V × m 的矩阵 Q，这个矩阵 Q 包含 V 行，V 代表词典大小，每一行的内容代表对应单词的 Word Embedding 值。只不过 Q 的内容也是网络参数，需要学习获得，训练刚开始用随机值初始化矩阵 Q ，当这个网络训练好之后，矩阵 Q 的内容被正确赋值，每一行代表一个单词对应的 Word embedding 值。</span><br></pre></td></tr></table></figure><h2 id="独热编码（one-hot）"><a href="#独热编码（one-hot）" class="headerlink" title="独热编码（one-hot）"></a>独热编码（one-hot）</h2><p>让计算机认识单词</p><p>余弦相似度 —-&gt; 每个词都没相似度  —— 缺点 </p><p>提出词向量</p><h2 id="词向量（神经网络语言模型的副产品Q）"><a href="#词向量（神经网络语言模型的副产品Q）" class="headerlink" title="词向量（神经网络语言模型的副产品Q）"></a>词向量（神经网络语言模型的副产品Q）</h2><p>假设L:</p><p>“判断”—-&gt;  one-hot  w1 [1,0,0,0,0]</p><p>w1*Q &#x3D; c1 （“判断”这个词的词向量）</p><p>词向量：就是用一个向量来表示一个单词</p><p>可以控制词向量的维度</p><p>可以描述相似度</p><p>得到词向量，很多任务就可以解决（下游任务）</p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><p>神经网络语言模型：通过神经网络解决两个人说的话的问题。</p><p>softmax（w2（tanh（w1x+b1)）+b2）</p><p>有个副产品：Q —&gt; 是个可学习的矩阵。对于任何一个独热编码都可以通过 Q —-&gt;新的词向量（可以选择维度，可以求相似度）</p><p>下游任务改造</p><h1 id="04-Word2vec-模型-—-gt-为了得到词向量"><a href="#04-Word2vec-模型-—-gt-为了得到词向量" class="headerlink" title="04 Word2vec 模型 —&gt;为了得到词向量"></a>04 Word2vec 模型 —&gt;为了得到词向量</h1><p>神经网络语言模型 —-&gt; 主要目的是为了得到词向量</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310041435953.webp" alt="Word2vec"></p><p>NNLM 和 Word2vec 基本一致，网络架构是一样的。</p><h2 id="CBOW"><a href="#CBOW" class="headerlink" title="CBOW"></a>CBOW</h2><p>给出一个词的 &#x3D;&#x3D;上下文&#x3D;&#x3D;，得到这个词。</p><p>“我是最<code>___</code>的男生”</p><p>“帅”  $w_t$</p><h2 id="Skip-gram"><a href="#Skip-gram" class="headerlink" title="Skip-gram"></a>Skip-gram</h2><p>给出一个词，得到这个词的上下文</p><p>“帅” </p><p>“我是最<code>___</code>的男生”</p><h2 id="NNLM-和-Word2vec-的区别"><a href="#NNLM-和-Word2vec-的区别" class="headerlink" title="NNLM 和 Word2vec 的区别"></a>NNLM 和 Word2vec 的区别</h2><p>NNLM —&gt; 重点预测下一词，多层感知机 —&gt; softmax（w2（tanh（w1（XQ）+b1)）+b2）</p><p>Word2vec —&gt; CPOW 和 Skip-gram —&gt; 重点得到一个 Q 矩阵 —&gt; softmax（w1（XQ）+b1）</p><ol><li>CBOW：一个老师告诉多个学生，Q 矩阵怎么变</li><li>Skip：多个老师告诉一个学生，Q 矩阵怎么变</li></ol><h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><p>Q 矩阵的设计：</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310041509965.webp" alt="image-20231004150951804"></p><p>假设 00010 代表 apple ，✖ Q  &#x3D; 10，12，19</p><p>apple （苹果，🍎）</p><p>假设数据集里 apple 只代表苹果，没有🍎这个意思（训练）</p><p>（测试，应用）apple ，表示🍎这个意思。</p><p>缺点：词向量不能进行多义 —&gt; ELMO</p><h1 id="05预训练语言模型的下游任务改造简介"><a href="#05预训练语言模型的下游任务改造简介" class="headerlink" title="05预训练语言模型的下游任务改造简介"></a>05预训练语言模型的下游任务改造简介</h1><p>Word2vec —&gt; 是一个神经网络语言模型，其次主要任务是（生成词向量，Q）</p><p>Word2vec 模型是不是预训练模型？</p><p>是</p><p>给出两个任务 A 和 B，任务 A 已经做出了模型 A，任务 B 无法解决（通过使用 A 加快任务的解决）</p><p>给一个NLP任务：给一个问题 X（ni+hao），给出一个回答 Y （ hello ）</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310041533067.webp" alt="image-20231004153350698"></p><p>预训练模型（先使用独热编码（一一对应的一种表查询），再使用 Word2vec 预训练好的 Q 矩阵直接得到词向量，然后进行接下来的任务）</p><ol><li>冻结 ：可以不改变 Q 矩阵</li><li>微调 ：随着任务的改变，改变 Q 矩阵</li></ol><h1 id="06-ELMO-模型（双向LSTM）"><a href="#06-ELMO-模型（双向LSTM）" class="headerlink" title="06 ELMO 模型（双向LSTM）"></a>06 ELMO 模型（双向LSTM）</h1><p>NNLM 模型（预测下一个词，副产品词向量）</p><p>Word2vec 模型：专门做词向量</p><ol><li>CBOW</li><li>Skip-gram</li></ol><p>缺陷：不能解决多义问题，一对一。</p><p>解决：ELMO 模型</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310041557604.webp" alt="image-20231004155737308"></p><p>ELMO（专门做词向量，通过预训练）</p><p>不止训练一个 Q 矩阵，还可以把这个词的上下文信息融入这个 Q 矩阵中</p><p>左边的 LSTM 获取 E2 的上文信息，右边的是下文信息。</p><p>获取上下文信息后，把三层信息进行叠加。</p><p>E1 + E2 + E3 &#x3D; T1 (一个新的词向量) ≈ E1         ————–&#x3D;&#x3D;看清楚是数字是正标还是小标&#x3D;&#x3D;</p><p>E2 , E3 相当于两个上下文信息</p><p>T1 包含了第一个词向量的 单词特征、句法特征、语义特征</p><p>x1，x2,，x4，x5 —&gt; Word2vec : x1 + x2 + x4 + x5 ( 一个个词叠加 ) —&gt; 预测一个词</p><p>怎么用？</p><p>E2，E3 不同，E1 + E2 + E3 不同</p><p>apple —&gt; 我吃了一个苹果 —&gt; [1，20，10]            eg，一般词向量是512维</p><p>apple —&gt; 我在用苹果手机 —&gt; [1，10，20]</p><p>&#x3D;&#x3D;上下文对生成的词向量造成了影响，不同上下文处的同一个词的词向量不同。&#x3D;&#x3D;</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310041631743.webp" alt="image-20231004163151459"></p><h2 id="LSTM-无法并行，长期依赖。"><a href="#LSTM-无法并行，长期依赖。" class="headerlink" title="LSTM : 无法并行，长期依赖。"></a>LSTM : 无法并行，长期依赖。</h2><h1 id="07-Attention"><a href="#07-Attention" class="headerlink" title="07 Attention"></a>07 Attention</h1><p>大数据（什么数据都有，重要的，不重要的）</p><p>但是对于 CNN ，LSTM , 很难决定什么重要，什么不重要。</p><p>注意力机制诞生了。（ 在深度学习的模型上做注意力。）</p><p>文章看标题</p><p>段落看开头</p><h2 id="怎么做注意力"><a href="#怎么做注意力" class="headerlink" title="怎么做注意力"></a>怎么做注意力</h2><p>我（查询 Q query），一张图（被查询对象 V value）</p><p>哪些重要？？ 去计算 Q 和 V 的重要度</p><p>等于相似度计算，点积注意力。</p><p>Q，$K &#x3D; k_1,k_2,…………，k_n$</p><p>Q 与  $k_1$ 点乘得到相似度  $a_1$ , ………Q 与  $k_n$ 点乘得到相似度  $a_n$ </p><p>做  $softmax(a_1,a_2,\cdots,a_n)$ 就可以得到概率</p><p><a href="https://www.demonlover.top/posts/29159/">Self-Attention | Dyang-blog (demonlover.top)</a><br>$$<br>(a_1,a_2,\cdots,a_n) \cdot ((v_1,v_2,\cdots,v_n) &#x3D; (a_1 * v_1 ,a_2 * v_2 ,\cdots,a_n * v_n) &#x3D; V’<br>$$</p><p>相当于求加权和，得到 $V’$ 然后用 $V’$ 代替  $V$ </p><p>一般  $K$ &#x3D;  $V$ , 在 Transformer中。也可以不相等，但是一定具有某种关系。这样才能知道 $V$ 的哪些重要，哪些不重要。</p><ul><li>缩放点积，缩放的意思是有个<strong>根号dk</strong>的缩放。为了使梯度更加平缓，从而使softmax处理后数据更好区分。</li><li>实际使用时，使用矩阵乘法并行计算。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310060930931.webp" alt="2023"></p><h2 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a>Self-Attention</h2><p>Self-Attention 的关键点在于，K Q V 同源，来自同一个 X </p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310050958810.webp" alt="QKV-矩阵表示" style="zoom:80%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310050959510.webp" alt="QKVZ-结果" style="zoom:80%;" /><p>Z 就是新的词向量，包含了内部联系。</p><p>最后会得到每一个词与每一个词之间关系的如下内容：</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310051002743.webp" alt="注意力机制矩阵图" style="zoom:67%;" /><h2 id="Attention-与-Self-Attention"><a href="#Attention-与-Self-Attention" class="headerlink" title="Attention 与 Self-Attention"></a>Attention 与 Self-Attention</h2><p>注意力机制是一个宽泛的概念，Q K V 相乘就是注意力，但是没有规定 Q K V 是怎么来的，只是规定了 Q K V 怎么做</p><p>自注意力机制规定了 Q K V 同源，做法和注意力机制一样。</p><p>对于同一个词向量（不一定准确），做的是空间上的对应，乘上了参数矩阵，但依然代表 X </p><h2 id="cross-attention"><a href="#cross-attention" class="headerlink" title="cross-attention"></a>cross-attention</h2><p>Q 与 V 不同源，但是 K 和 V 同源</p><h2 id="Self-Attention-与-RNN-LSTM-比较"><a href="#Self-Attention-与-RNN-LSTM-比较" class="headerlink" title="Self - Attention 与 RNN LSTM 比较"></a>Self - Attention 与 RNN LSTM 比较</h2><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310051022112.webp" alt="RNN-unrolled"></p><p>丢失前面的信息，无法做长序列</p><p>LSTM , 通过多种 gate 来选择记忆前面的信息，可以做较长序列</p><p>RNNs（RNN、LSTM）无法长序列依赖问题，无法并行</p><p>Self- Attention 解决了以上问题，&#x3D;&#x3D;并且得到的词向量具有句法特征和语义特征（表征更加完善）&#x3D;&#x3D;</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310060931219.webp" alt="20272"></p><p>但 Self- Attention 计算量太大</p><h2 id="Masked-Self-Attention"><a href="#Masked-Self-Attention" class="headerlink" title="Masked Self - Attention"></a>Masked Self - Attention</h2><p>attention 在训练时能看到全部信息，但在预测生成时，不能让模型看到未来的信息。</p><p>掩码是为了分批次给信息。</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310051057805.webp" alt="mask-attention-map" style="zoom: 67%;" /><h2 id="Multi-head-Self-Attebtion"><a href="#Multi-head-Self-Attebtion" class="headerlink" title="Multi-head Self-Attebtion"></a>Multi-head Self-Attebtion</h2><p>Z 相比 X 有了很大的提升，通过 Multi-head Self-Attebtion 得到的 $Z’$ 会有更进一步的提升</p><p>多头的个数一般用 $h$ 表示，一般使用 $h$ &#x3D;8</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img /202309252134758.webp" alt="Multi-head Self-Attebtion" style="zoom:80%;" /><p>对于 X ，不是直接用 X 去得到 Z，而是把 X 分为 8 块，得到 Z0-Z7 ，然后把其拼接起来做一次线性变换得到 Z </p><p>有什么作用？</p><p>机器学习本质：y &#x3D; $\sigma$（wx+b）{ $\sigma$ 为激活函数 }，在做一件事，非线性变换（把一件看起来不合理的东西，通过训练模型让这个东西变得合理）</p><p>非线性变换的本质：改变空间上的位置坐标，任何一个点都可以在空间维度上找到，通过某个手段，让一个不合理的点（位置不合理），变得合理</p><p>这就是词向量的本质</p><p>one-hot  变换—&gt;</p><p>word2vec</p><p>emlo</p><p>attentionm</p><p>Multi-head Attebtion：把 X 切成 8 块（8个子空间），这样把原先在一个位置上的 X ，投影到了空间上的 8 个位置，通过对 8 个点进行寻找，找到更合适的位置</p><p>要求计算机性能有要求</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310051132620.webp" alt="multi-head-拼接" style="zoom:150%;" /><h2 id="Position-Encoding"><a href="#Position-Encoding" class="headerlink" title="Position Encoding"></a>Position Encoding</h2><h3 id="Attention："><a href="#Attention：" class="headerlink" title="Attention："></a>Attention：</h3><ol><li>解决了长序列</li><li>可以并行</li></ol><p>缺点：</p><ol><li>计算量大</li><li>可以并行，也就是不同词之间不存在顺序关系（打乱一句话，<strong>每个词的词向量不变</strong>），无位置关系，要通过位置编码加入</li></ol><p>&#x3D;&#x3D;Self-Attention ：对于每个词而言都是无位置关系的，把每个词的顺序打乱，得到的注意力值依然不变。&#x3D;&#x3D;</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310051145361.webp" alt="位置向量"></p><h3 id="具体做法"><a href="#具体做法" class="headerlink" title="具体做法"></a>具体做法</h3><p>512 维的词向量 &#x3D;  $d_{model}$</p><p>维度里面的偶数项和奇数项</p><ol><li><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310051438525.webp" alt="位置编码公式"></p></li><li></li></ol><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310051438846.webp" alt="位置编码和词向量之和"></p><h3 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h3><p>pos+K&#x3D;5，我在计算第 5 个单词的位置编码的时候</p><p>pos&#x3D;1，k&#x3D;4</p><p>pos&#x3D;2，k&#x3D;3</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310051439691.webp" alt="位置嵌入解释"></p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">sin</span> (<span class="keyword">pos</span>+k) = <span class="keyword">sin</span>(<span class="keyword">pos</span>) * <span class="keyword">cos</span> k + <span class="keyword">cos</span>(<span class="keyword">pos</span>) * <span class="keyword">sin</span> k </span><br><span class="line"># <span class="keyword">sin</span> 表示 偶数维度， <span class="keyword">cos</span> 表示 奇数维度</span><br><span class="line"><span class="keyword">cos</span> (<span class="keyword">pos</span>+k) = <span class="keyword">cos</span>(<span class="keyword">pos</span>) * <span class="keyword">cos</span> k - <span class="keyword">sin</span>(<span class="keyword">pos</span>) * <span class="keyword">sin</span> k</span><br><span class="line"></span><br><span class="line"><span class="keyword">pos</span> + k 是 <span class="keyword">pos</span> 和 k 的线性组合</span><br></pre></td></tr></table></figure><p>使用这种方法是能够阐明位置关系的，因为每一个词都是完成了位置关系映射，蕴含了与之前词的联系。</p><h1 id="08-Transformer"><a href="#08-Transformer" class="headerlink" title="08 Transformer"></a>08 Transformer</h1><p>预训练 —&gt; NNLM —&gt; Word2vec —&gt; ELMO –&gt; Attention</p><p>NLP 中预训练的目的就是为了生成词向量</p><p>transformer 其实就是 attention 的堆叠</p><p>seq2seq：</p><p>序列到序列</p><p>编码器到解码器</p><p>编码器：把输入变成一个词向量（self- attention）—&gt; &#x3D;&#x3D;向量化&#x3D;&#x3D;</p><p>解码器： —&gt; &#x3D;&#x3D;算结果&#x3D;&#x3D;</p><p>N × 中默认 N 为6</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310060931831.webp" alt="956584"></p><p>通过 6 个编码器，对词向量一步又一步的强化（增强）</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310051524432.webp" alt="tf-ed-复杂" style="zoom: 67%;" /><p>FFN ( Feed Forwad )</p><h2 id="编码器"><a href="#编码器" class="headerlink" title="编码器"></a>编码器</h2><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310051533451.webp" alt="ed-细分" style="zoom: 80%;" /><p>编码器有两个子层，Self- Attention 、Feed Forward</p><p>每一个子层都有一个（残差网络 + 归一化）</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310051537235.webp" alt="encoder-详细图" style="zoom:80%;" /><p>Thinking –&gt; 得到绿色的 x1（词向量，可以通过 one-hot、word2vec 得到）</p><p>—&gt; 叠加位置编码（ 给 x1 赋予位置属性 ）得到黄色的 x1</p><p>—&gt; 输入到 Self-Attention 子层中，做注意力机制（x1、x2 拼接起来的一句话）得到 z1（x1 与 x1，x2拼接起来的句子做了自注意力机制的词向量，表征的仍然是 thinking），也就是说 z1 拥有了位置特征、句法特征、语义特征的词向量</p><p>—&gt; 残差网络（ 避免梯度消失，w3(w2(w1x+b1)+b2)+b3，如果 w1，w2，w3 特别小，0.0000000000000000……1，x 就没了，【w3(w2(w1x+b1)+b2)+b3+&#x3D;&#x3D;x&#x3D;&#x3D;】），归一化（LayerNorm），做标准化（避免梯度爆炸），得到了深粉色的 z1</p><p>—&gt; Feed Forward，Relu（w2(w1x+b1)+b2），（前面每一步都在做线性变换，wx+b，线性变化的叠加永远都是线性变化（线性变化就是空间中平移和伸缩变换），通过 Feed Forward中的 Relu 做一次非线性变换，这样的空间变换可以无限拟合任何一种状态了），得到 r1（是 thinking 的新的表征）</p><p>&#x3D;&#x3D;总结下（这是重点，上面听不懂都没关系）：做词向量，只不过这个词向量更加优秀，让这个词向量能够更加精准的表示这个单词、这句话&#x3D;&#x3D;</p><h2 id="解码器"><a href="#解码器" class="headerlink" title="解码器"></a>解码器</h2><p>编码器在干嘛？输入一个向量，把它转换成一个包含特征最好的一个向量，让计算机更合理（不确定）的认识人类世界。</p><p>Decoder 会把前一时间的输出作为下一时间的输入。</p><p>Masked Self-Attention：考虑一个时间的输出时，会自动隐藏未来的输入。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310060932226.webp" alt="584"></p><h2 id="Encoder-Decoder"><a href="#Encoder-Decoder" class="headerlink" title="Encoder-Decoder"></a>Encoder-Decoder</h2><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310060932694.webp" alt="202309271851081"></p><h2 id="问题一：为什么-Decoder-需要做-Mask"><a href="#问题一：为什么-Decoder-需要做-Mask" class="headerlink" title="问题一：为什么 Decoder 需要做 Mask"></a>问题一：为什么 Decoder 需要做 Mask</h2><p>为了解决训练阶段和测试阶段的 gap（不匹配）</p><p>训练阶段：解码器会有输入，这个输入是目标语句，通过已经生成的词，去让解码器更好的生成（每一次都会把所有信息告诉解码器）</p><p>测试阶段：解码器也会有输入，但是此时，测试的时候是不知道目标语句是什么的，这个时候，你每生成一个词，就会有多一个词放入目标语句中，每次生成的时候，都是已经生成的词（测试阶段只会把已经生成的词告诉解码器）</p><h2 id="问题二：为什么-Encoder-给予-Decoders-的是-K、V-矩阵"><a href="#问题二：为什么-Encoder-给予-Decoders-的是-K、V-矩阵" class="headerlink" title="问题二：为什么 Encoder 给予 Decoders 的是 K、V 矩阵"></a>问题二：为什么 Encoder 给予 Decoders 的是 K、V 矩阵</h2><p>Q 来源解码器，K&#x3D;V 来源于编码器</p><p>Q 是查询变量，Q 是已经生成的词</p><p>K&#x3D;V 是源语句</p><p>当我们生成这个词的时候，通过已经生成的词和源语句做自注意力，就是确定源语句中哪些词对接下来的词的生成更有作用，首先他就能找到当前生成词</p><p>&#x3D;&#x3D;通过部分（生成的词）去全部（源语句）的里面挑重点&#x3D;&#x3D;</p><p>Q 是源语句，K，V 是已经生成的词，源语句去已经生成的词里找重点 ，找信息，已经生成的词里面压根就没有下一个词</p><p>解决了以前的 seq2seq 框架的问题</p><p>lstm 做编码器（得到词向量 C），再用 lstm 做解码器做生成</p><p>用这种方法去生成词，每一次生成词，都是通过 C 的全部信息去生成</p><p>很多信息对于当前生成词而言都是没有意义的</p>]]></content>
      
      
      <categories>
          
          <category> Transformer </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Transformer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>123</title>
      <link href="/posts/29162/"/>
      <url>/posts/29162/</url>
      
        <content type="html"><![CDATA[<h2 id="找目标论文"><a href="#找目标论文" class="headerlink" title="找目标论文"></a>找目标论文</h2><ul><li>开源的[dog]、近两年的。</li><li>顶刊顶会，有的会开源。</li><li>拿到开源代码，尽快复现，复现不了就换，一定要论文代码匹配。</li></ul><h2 id="定基准模型"><a href="#定基准模型" class="headerlink" title="定基准模型"></a>定基准模型</h2><p>​<strong>论文1  &#x3D;  A  (基准模型)   +  b   +  c</strong></p><p>​基准模型可以是：</p><ul><li>A  +  d   +  e</li><li>论文1性能  &gt;  A</li><li><strong>A  +  b；A  +  c；A  +  b  +  c  -  d（更小的模块）</strong></li></ul><p>​可以对论文进行任何对自己有利的改造，基准模型不一定是别人发表过的。</p><h2 id="定模块"><a href="#定模块" class="headerlink" title="定模块"></a>定模块</h2><p>​<strong>模块的目标论文：近5-10年，尽量热门。</strong>最难的部分在 ：”   +   “，<strong>靠基础</strong>。</p><ul><li>论文的组织架构： A  (基准模型)   +  b   +  c  +  ·······</li><li>论文1（近两年）  &#x3D;  A  (基准模型)   +  b   +  c  +  d</li><li>论文2  &#x3D;  B  (基准模型)   +  e   +  f   +  g</li><li>论文2  &#x3D;  C  (基准模型)   +  z</li><li>则可选：A  +  e  +  f  + ······(性能差，再换)<ul><li>A  +  z</li></ul></li><li>创新：排列组合。</li></ul><h3 id="高级模块："><a href="#高级模块：" class="headerlink" title="高级模块："></a>高级模块：</h3><h4 id="1、"><a href="#1、" class="headerlink" title="1、"></a>1、</h4><p>发现问题，然后用现有的模块（改进）去解决问题，放在基准模型上。</p><p>科研：发现问题，创造模块解决问题。</p><h4 id="2、"><a href="#2、" class="headerlink" title="2、"></a>2、</h4><p>通用的模块：去博客找，热门。</p><p>注意力机制、蒸馏学习、对比学习、扩散模型</p><h2 id="缝模块"><a href="#缝模块" class="headerlink" title="缝模块"></a>缝模块</h2><h3 id="1、-1"><a href="#1、-1" class="headerlink" title="1、"></a>1、</h3><p><span style='color:red'>打基础，python。把基础打扎实。</span></p><h3 id="2、-1"><a href="#2、-1" class="headerlink" title="2、"></a>2、</h3><p>基准模型很大，怎么把模块缝上去？—（python）缝什么位置？</p><p>对于基准模型的每个地方都得把握清楚，才能找到合适的位置放进去。</p><p>或者通过注意力机制，把基准模型和模块拼在一起。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>和<strong>你所知道</strong>的<strong>近两年</strong>的sota比较（the state of art），恰好有一篇性能比你的差。</p><p>按照发文级别选择sota，尽量往前冲。发四区，就要比去年的三区的性能好，才适合动手写论文。</p><p>对比实验的时候，可以找一些模型（明牛暗差）跑跑实验，丰富经验。</p><h2 id="编故事"><a href="#编故事" class="headerlink" title="编故事"></a>编故事</h2><p align = "center"><span style='color:red'>故事编得好不好决定发水刊还是顶刊。</span></p ><p>创新就是看故事怎么编。</p><p>计算机基础架构、CNN、RNN、Attention、Transformer、Bert、GPT</p><p>学术：论文&#x3D; A + b + c ，然后编故事。</p><p>科研：发现问题，尝试A + b + c 解决问题。</p><h3 id="1、-2"><a href="#1、-2" class="headerlink" title="1、"></a>1、</h3><p>A + b + c ，来源他人得论文（已经成功发表）</p><p>可以借鉴他的问题，然后做的比他好。</p><h3 id="2、-2"><a href="#2、-2" class="headerlink" title="2、"></a>2、</h3><p>模块可以自己构造，也可以来源于其他领域。</p><p>找自己领域的问题（自己想个问题，让这个问题和模块对应上，自圆其说）</p><p><strong>问题高大上的程度，决定了论文的高度。</strong></p><p>我发现了B问题和C问题，准备设计 b 和 c 去解决问题。</p>]]></content>
      
      
      <categories>
          
          <category> others </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 123 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GNN、GCN</title>
      <link href="/posts/29161/"/>
      <url>/posts/29161/</url>
      
        <content type="html"><![CDATA[<p>​link：</p><p>“图” 通常是指一种用于表示对象之间关系的可视化数据结构。在数学和计算机科学中，图是由节点（或顶点）和边组成的集合，用于描述各种关系和网络结构。以下是图的一些基本概念：</p><ol><li><strong>节点（顶点）</strong>：节点是图中的基本元素，通常用于表示对象、实体或数据点。节点可以具有标识符或属性，用于唯一标识或描述它们。</li><li><strong>边</strong>：边是连接节点的线段或连接，用于表示节点之间的关系。边可以具有方向（有向图）或没有方向（无向图）。</li><li><strong>有向图和无向图</strong>：在有向图中，边具有方向，从一个节点指向另一个节点。在无向图中，边没有方向，只表示节点之间的连接。</li><li><strong>权重</strong>：边可以关联一个权重或值，表示节点之间的关系的强度或权重。这在许多应用中非常重要，如网络流量、社交网络中的好友关系等。</li><li><strong>路径</strong>：路径是图中的一系列连接节点的边，它描述了从一个节点到另一个节点的通路。</li><li><strong>图的类型</strong>：根据其属性和结构，图可以分为多种类型，包括树（一种没有循环的特殊图）、有向无环图（DAG，有向图中没有循环的图）等。</li><li><strong>图的应用</strong>：图在计算机科学、网络分析、社交网络分析、路由算法、数据库查询优化、人工智能、物流规划等领域都有广泛的应用。</li></ol><p>总之，图是一种用于表示对象之间关系的抽象数据结构，具有广泛的应用领域，并提供了一种强大的工具，用于分析和解决各种复杂的问题。</p><hr><p>“Nodes” 和 “Edges” 是图论（Graph Theory）中的基本概念，用于描述图（Graph）中的元素和它们之间的关系。</p><ol><li><strong>Nodes（节点）</strong>：<ul><li>节点，也称为顶点，是图中的基本元素或数据点。它们通常用于表示对象、实体或数据项。</li><li>每个节点可以具有唯一的标识符或属性，以便在图中进行识别或描述。</li><li>节点通常用圆圈、方框或其他符号来表示，具体取决于可视化表示的方式。</li></ul></li><li><strong>Edges（边）</strong>：<ul><li>边是图中连接节点的线段、连接或关系。它们用于表示节点之间的联系或连接。</li><li>在有向图中，边具有方向，从一个节点指向另一个节点。在无向图中，边没有方向，只表示节点之间的连接。</li><li>每条边通常连接两个节点，但也可以连接一个节点到自身，形成自环边。</li></ul></li></ol><p>图是由一组节点和一组边组成的，用于表示对象之间的关系或网络结构。例如，在社交网络中，个人可以表示为节点，而他们之间的友谊或关注关系可以表示为边。在交通路网中，路口可以表示为节点，而道路可以表示为边。</p><hr><p>邻接矩阵（Adjacency Matrix）是用于表示图（Graph）的一种常见的矩阵表示方法。它是一个二维矩阵，用于描述图中节点之间的连接关系。邻接矩阵通常在图论和计算机科学中广泛使用。</p><p>邻接矩阵的基本思想是将图中的每个节点映射到矩阵中的一行和一列，然后使用矩阵中的元素来表示节点之间的连接状态。邻接矩阵的行和列对应于图中的节点，而矩阵的元素表示节点之间的连接。通常，如果节点 i 和节点 j 之间存在边（连接），那么邻接矩阵的第 i 行第 j 列的元素将被标记为1；如果没有连接，则标记为0。</p><hr><p>稀疏矩阵（Sparse Matrix）是一种矩阵，其中大多数元素都是零。与稠密矩阵相比，稀疏矩阵中只包含相对较少的非零元素，因此它们通常以更节省内存和计算资源的方式存储和处理。</p><hr><ul><li>需要有一定的机器学习的背景。</li><li>图是一个非常强大的东西，但是它的强大也带来了很多问题：很难在图上做出优化，图一般比较稀疏，有效的在CPU、GPU、加速器上计算是一件比较难的事情；图神经网络对超参数比较敏感。</li><li>图神经网络门槛比较高，这些年吸引了很多人对他的研究，但在工业界上的应用还需要时间的积累。</li></ul><ol><li>什么是图？图的属性应该用向量来进行表示。对于顶点、边、全局都用向量来表示它的属性。</li><li>现实生活中的现象怎么表示成图，怎么对顶点、边、全局进行预测？</li><li>机器学习的算法用到图上有什么挑战？</li><li>定义GNN：&#x3D;&#x3D;GNN就是对属性做变换，但不改变图的结构。&#x3D;&#x3D;</li><li>&#x3D;&#x3D;属性有缺失可以做聚合操作，把边的数据拿到结点上面，补足缺失的数据。&#x3D;&#x3D;</li><li>GNN：每一层里面通过汇聚操作，把信息传递过来，每个顶点看邻接顶点的信息；每个顶点看邻接边的信息或全局的信息。在每一层上如果能对信息进行充分的汇聚，那么GNN可以对图的结构进行一个发掘。</li><li>实验：做了很多实验，可以看到参数对实验结果的影响。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> GNN、GCN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Self-Attention</title>
      <link href="/posts/29159/"/>
      <url>/posts/29159/</url>
      
        <content type="html"><![CDATA[<h1 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a><p align="center">Self-Attention</p></h1><p>文字叙述查看Transformer：<a href="https://www.demonlover.top/posts/29158/">Transformers | Dyang-blog (demonlover.top)</a>。论文：Long Range Arena : A Benchmark for Efficient Transformers，比较了各式各样的Self-Attention的变形。论文 :Efficient Transformers：A Survey，介绍各式各样的变形，方便进一步研究。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309262104002.webp" alt="image-20230926210416743"></p><ul><li><strong>Self-Attention</strong>考虑一整个<strong>sequence</strong>。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309262116707.webp" alt="image-20230926211641311"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309262123550.webp" alt="image-20230926212346325"></p><p> <img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309262126289.webp" alt="image-20230926212623039"></p><ul><li>并行计算 b。</li><li>分块矩阵方法，组合。</li><li><strong>W^q</strong>   是 network 的参数，是 learn 出来的</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271335788.webp" alt="image-20230927133515532"></p><ul><li><strong>A</strong>  表示 Attention score。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271340439.webp" alt="image-20230927134041166"></p><ul><li><strong>O</strong>  里面的每一个 column 就是 Self-Attention 的输出。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271344436.webp" alt="image-20230927134450193"></p><ul><li>整个里面只有  <strong>W</strong>  是需要训练去学习的，其他都是给定的。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271348443.webp" alt="image-20230927134843200"></p><h2 id="Multi-head-Self-Attention"><a href="#Multi-head-Self-Attention" class="headerlink" title="Multi-head-Self-Attention"></a>Multi-head-Self-Attention</h2><ul><li>q 找相关的 k，但相关可以有很多种不同的形式。所以应该有多个 q，不同的 q 负责不同类型的相关性。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271358052.webp" alt="image-20230927135844796"></p><ul><li>接起来，通过一个transform，得到的结果送到下一层.</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271402284.webp" alt="image-20230927140206125"></p><h2 id="Position-Encoding"><a href="#Position-Encoding" class="headerlink" title="Position Encoding"></a>Position Encoding</h2><p>:star2:解决<strong>Atteneion</strong>  “天涯若比邻”的问题。</p><ul><li>位置向量是人设的，也可以从数据里学习。一个尚待研究的问题。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271413824.webp" alt="image-20230927141344545"></p><p>:satisfied:笑死</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271416809.webp" alt="image-20230927141657555"></p><h2 id="Self-atteneion-VS-CNN"><a href="#Self-atteneion-VS-CNN" class="headerlink" title="Self-atteneion  VS  CNN"></a>Self-atteneion  VS  CNN</h2><p>CNN可以看成一个简化版的Self-atteneion。相当于CNN的recept-field不再是人工划定，而是让机器自己学习和选择出来的。只要设定好参数，Self-atteneion可以做与CNN一样的事。论文：On the Relationship between Self-Atteneion and Convolutional Layers。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271428734.webp" alt="image-20230927142819588"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271434685.webp" alt="image-20230927143421458"></p><p>比较 flexible 的 model 需要更多的 data ，否则更容易 overfitting。</p><h2 id="Self-atteneion-VS-RNN"><a href="#Self-atteneion-VS-RNN" class="headerlink" title="Self-atteneion  VS  RNN"></a>Self-atteneion  VS  RNN</h2><p>Transformers are RNNs：Fast Aetoregressive Transformers with Liner Attention。Self-atteneion 加上什么东西后变成 RNN。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271446372.webp" alt="image-20230927144604115"></p><h2 id="Self-atteneion-for-Graph"><a href="#Self-atteneion-for-Graph" class="headerlink" title="Self-atteneion  for  Graph"></a>Self-atteneion  for  Graph</h2><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271451809.webp" alt="image-20230927145148585"></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deeplearning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Transformer</title>
      <link href="/posts/29158/"/>
      <url>/posts/29158/</url>
      
        <content type="html"><![CDATA[<h1 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a><p align="center">Transformer</p></h1><p>以下是一个示例，说明了如何将二维数据表示为批次和特征的矩阵：</p><ul><li><strong>行（Batch）</strong>：每一行代表一个批次中的一个样本。批次是一组同时输入神经网络进行训练或推理的数据点。批次的大小可以根据任务和硬件资源进行设置，通常是一个超参数。</li><li><strong>列（Feature）</strong>：每一列代表一个特征。特征是用于描述样本的属性或数据的维度。例如，在图像处理任务中，每个特征可能代表像素值；在自然语言处理中，每个特征可能代表词向量的维度。</li></ul><p>假设有3个样本，每个样本有4个特征。那么您可以表示为一个3x4的矩阵，其中每一行是一个批次中的一个样本，每一列是一个特征：</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[[feature1_sample1, feature2_sample1, feature3_sample1, feature4_sample1],</span></span><br><span class="line"><span class="string"> [feature1_sample2, feature2_sample2, feature3_sample2, feature4_sample2],</span></span><br><span class="line"><span class="string"> [feature1_sample3, feature2_sample3, feature3_sample3, feature4_sample3]]</span></span><br></pre></td></tr></table></figure><hr><ul><li>Batch Normalization（批归一化，BatchNorm）和 Layer Normalization（层归一化，LayerNorm）都是深度学习中用于提高神经网络训练稳定性和加速收敛的技术。它们的主要目标是规范神经网络中的激活值分布，使其更稳定，从而加速训练并改善模型的泛化性能。这两种方法的不同之处在于归一化的层级和操作方式。</li></ul><p><strong>Batch Normalization（BatchNorm）</strong>：**(对每一列，把均值变为0，方差变为1)**</p><ol><li><strong>层级</strong>：BatchNorm 是在每个神经网络层的输入上进行归一化的，通常是对每个小批量训练样本中的特征进行标准化。因此，它的归一化是基于每个层的输入数据的统计信息。</li><li><strong>操作方式</strong>：BatchNorm 通过计算每个小批量训练样本的均值和方差来归一化输入特征，然后对输入进行缩放和平移，以使其均值为0，方差为1。这些缩放和平移参数是可学习的，可以通过反向传播进行调整。</li><li><strong>应用领域</strong>：BatchNorm 主要用于卷积神经网络（CNN）和全连接神经网络中，通常用于加速训练和提高模型稳定性。它在深度网络中的训练非常有帮助。</li></ol><p><strong>Layer Normalization（LayerNorm）</strong>：**(对每一行，既每个样本，把均值变为0，方差变为1)**</p><ol><li><strong>层级</strong>：LayerNorm 是在每个神经网络层的输出上进行归一化的，即对每个特征维度进行标准化，而不是每个小批量训练样本。因此，它的归一化是基于每个层的输出数据的统计信息。</li><li><strong>操作方式</strong>：LayerNorm 对每个特征维度计算均值和方差，然后将这些统计值用于对整个特征维度的数据进行标准化。与 BatchNorm 不同，LayerNorm 不涉及小批量内的归一化。</li><li><strong>应用领域</strong>：LayerNorm 主要用于循环神经网络（RNN）和递归神经网络（RecNN）等序列数据处理任务，以及自然语言处理中的 Transformer 模型等。它有助于处理变长序列和减小梯度消失问题。</li></ol><hr><h2 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h2><ul><li><p>作用：把整个序列里面的信息抓取出来，做一次汇聚（aggregation）。</p></li><li><p>注意力函数将一个查询（query）和一组键-值对（key-value pairs）映射成一个输出。在这个过程中，查询、键、值和输出都表示为向量。</p></li></ul><ol><li><strong>输入</strong>：在注意力函数中，我们有三个关键组成部分：查询（query）、键（key）、和值（value）。这些都是向量，它们通常来自于输入数据的不同表示。<ul><li>查询（query）：这是一个向量，表示我们要关注的内容或问题。它是我们希望从输入数据中提取信息的方式。</li><li>键（key）：这也是一个向量，用于表示与每个输入元素相关的关键信息。它帮助我们衡量每个元素与查询的相关性。</li><li>值（value）：这也是一个向量，包含了与每个输入元素关联的实际信息。值表示我们想要根据查询和键的相关性来提取的内容。</li></ul></li><li><strong>计算权重</strong>：为了确定每个值的重要性或权重，需要<strong>计算query与每个key之间的相关性</strong>。这个相关性计算通常是通过一种函数来实现的，这个函数可以是点积（内积）或其他形式的相似性度量。这一步骤计算了每个键与查询之间的匹配程度，用于后续的加权过程。<strong>相关性大的项获得的权重通常也较大。</strong></li><li><strong>权重归一化</strong>：在计算得到相关性之后，这些相关性值可能具有不同的范围和大小。为了使它们变成概率分布，我们应用 softmax 函数。Softmax 将相关性值映射到0到1之间，并确保它们的总和等于1。这样，每个值获得了一个在0到1之间的权重，表示了它在最终输出中的重要性。</li><li><strong>加权求和</strong>：最后，我们将归一化后的权重与对应的值相乘，并对它们求和。这个过程将每个值根据其与查询的相关性进行加权，然后将这些加权值相加，得到最终的输出。</li></ol><ul><li><strong>总结来说，注意力函数的目标是根据query与key之间的相关性来计算值的权重，并将这些权重应用于value，加权求和以生成最终的输出。这种机制允许模型动态地关注输入数据的不同部分，从而更好地处理信息和执行任务。</strong></li></ul><h3 id="Scaled-Dot-Product-Attention（缩放点积注意力）"><a href="#Scaled-Dot-Product-Attention（缩放点积注意力）" class="headerlink" title="Scaled Dot-Product Attention（缩放点积注意力）"></a>Scaled Dot-Product Attention（缩放点积注意力）</h3><p>缩放点积注意力的核心思想是通过计算查询（Query）与键（Key）之间的点积来度量它们之间的相似度，然后将这些相似度值用于权重值的计算。</p><p>​<strong>余弦相似度（Cosine Similarity）</strong>：</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309252102250.webp" alt="image-20230925210231101"></p><ul><li>如果余弦相似度等于1，表示两个向量的方向完全相同，它们是相似的。</li><li>如果余弦相似度等于-1，表示两个向量的方向正好相反，它们是不相似的。</li><li>如果余弦相似度接近0，表示两个向量的夹角接近90度，它们之间的关系不明显。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309252105449.webp" alt="image-20230925210541308"></p><ul><li>缩放点积，缩放的意思是有个<strong>根号dk</strong>的缩放。为了使梯度更加平缓，从而使softmax处理后数据更好区分。</li><li>实际使用时，使用矩阵乘法并行计算。</li><li><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309252134405.webp" alt="image-20230925213401266"></li></ul><h2 id="Mask"><a href="#Mask" class="headerlink" title="Mask"></a>Mask</h2><ul><li>在Transformer模型中，”mask”（掩码）通常用于自注意力机制（Self-Attention）中，以控制模型在生成输出时关注哪些位置的信息。Transformer中的两种常见掩码是填充掩码（Padding Mask）和前瞻掩码（Look-Ahead Mask）：</li></ul><ol><li><p><strong>填充掩码（Padding Mask）</strong>：</p><p>在Transformer中，输入序列的长度通常不同，为了进行批处理，需要将较短的序列进行填充，使它们具有相同的长度。填充掩码用于指示哪些位置是填充的，哪些是有效的输入。填充掩码的作用是告诉模型在计算自注意力时忽略填充位置的信息，以避免对填充部分的注意。这提高了模型的计算效率，并确保填充不会影响模型的输出。</p></li><li><p><strong>前瞻掩码（Look-Ahead Mask）</strong>：</p><p>前瞻掩码用于限制模型在自注意力中只<strong>能关注过去的信息，而不能关注未来的信息。</strong>在语言模型等任务中，当生成下一个单词时，模型不应该使用未来单词的信息。前瞻掩码的作用是确保模型在自注意力中只考虑到当前位置之前的信息，而忽略当前位置之后的信息。这有助于模型进行有序的生成和预测。</p><p>这些掩码通常是二进制矩阵，其中1表示允许关注的位置，0表示禁止关注的位置。这些掩码矩阵与查询（Query）、键（Key）和值（Value）一起在自注意力机制中使用，以确定注意力分布并计算加权和。</p></li></ol><h2 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h2><ul><li>多头注意力（Multi-Head Attention）是Transformer模型的核心组成部分之一，它通过允许模型<strong>同时关注输入序列的不同子空间</strong>或特征来<strong>提高模型的表示能力和捕捉不同类型</strong>的关系。</li><li><strong>原理</strong>： 多头注意力的基本原理是，在处理输入序列时，它可以并行地应用多个注意力头，<strong>每个头都可以学习关注不同的子空间或特征</strong>。这些头通过<strong>学习</strong>不同的权重来计算注意力，并将它们的输出进行组合，以产生更丰富和多样化的表示。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309252134758.webp" alt="image-20230925213454589"></p><ul><li><strong>线性变换</strong>：输入序列（通常是查询Q、键K和值V）通过线性变换，分别映射到多个子空间中。</li><li><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309252148462.webp" alt="image-20230925214832182"></li></ul><h2 id="残差连接"><a href="#残差连接" class="headerlink" title="残差连接"></a>残差连接</h2><ul><li>残差连接（Residual Connection），也称为跳跃连接（Skip Connection），是深度神经网络中的一种重要的连接方式。它的核心思想是将网络的输入直接与网络的输出相加，从而形成一个”跳跃”连接。这个连接使得神经网络可以更轻松地学习恒等映射（identity mapping），即将输入复制到输出，而不引入额外的复杂性。</li></ul><ol><li><strong>缓解梯度消失问题</strong>：在深度神经网络中，通过多层堆叠，梯度可能会逐渐减小到接近零，使得网络难以训练。残差连接通过允许信息在网络中跳跃传播，可以更容易地传递梯度，缓解梯度消失问题，从而加速训练。</li><li><strong>加速训练收敛</strong>：残差连接允许网络在较短的时间内更快地收敛，因为它们使网络更容易学习恒等映射。这意味着模型可以更早地开始捕捉有效的特征，而不必等待网络逐渐学习复杂的映射。</li><li><strong>降低网络复杂性</strong>：残差连接允许深度网络的添加，而不引入额外的参数或计算复杂性。这使得构建非常深的神经网络变得可行，因为每个层都可以通过恒等映射来保持网络的性能。</li></ol><ul><li>数学上，残差连接的操作可以表示为：</li><li>输出&#x3D;输入+子网络(输入)输出&#x3D;输入+子网络(输入)</li><li>其中，输入是传入残差块的原始输入数据，子网络表示了在输入上执行的一系列层次化操作。输出是最终的块输出。通过这种方式，模型可以学习决定是否保留原始输入，以及如何改进原始输入以产生输出。</li><li>残差连接已成功应用于许多深度学习架构，包括ResNet（残差网络）和Transformer模型。这些连接在提高模型性能和训练效率方面发挥了重要作用。</li></ul><h2 id="RNN与Transformer"><a href="#RNN与Transformer" class="headerlink" title="RNN与Transformer"></a>RNN与Transformer</h2><p> <img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309261143564.webp" alt="image-20230926114334131"></p><h2 id="Embeddings"><a href="#Embeddings" class="headerlink" title="Embeddings"></a>Embeddings</h2><ul><li><p>“Embeddings” 是深度学习中常用的概念，它指的是将高维度的数据映射到低维度空间的过程。通常，这个过程涉及到将离散型的符号数据（如单词、类别、标签等）转化为连续型的向量，以便在神经网络中进行处理。Embeddings 可以用于各种任务，包括自然语言处理、计算机视觉和推荐系统等。</p></li><li><p>在Transformer模型中，Embedding层是其中一个关键的组件，用于将输入数据（如单词、位置编码等）映射到连续的向量表示，以便后续的处理。Transformer中的Embedding层通常包括两种主要类型的嵌入：词嵌入（Word Embeddings）和位置嵌入（Position Embeddings）。</p></li></ul><ol><li><strong>词嵌入（Word Embeddings）</strong>：<ul><li>词嵌入用于将自然语言文本中的单词或标记映射为连续的向量表示。这有助于模型理解单词之间的语义关系。</li><li>在Transformer中，通常会使用一个独立的Embedding层来嵌入输入序列中的单词或标记。这个Embedding层的权重矩阵被训练以捕捉单词之间的语义信息。</li><li>例如，将单词 “cat” 映射为一个连续的向量，以便模型能够理解它在上下文中的含义。</li></ul></li><li><strong>位置嵌入（Position Embeddings）</strong>：(保证因果关系)<ul><li>由于Transformer没有循环结构，因此需要一种方式来引入序列中单词的位置信息。位置嵌入用于表示输入序列中每个位置的位置信息。</li><li>位置嵌入通常以一种特定的方式构造，以确保模型能够识别不同位置之间的关系。最常见的方式是使用正弦和余弦函数的组合。</li><li>例如，在输入序列的位置3处的位置嵌入可能不同于在位置4处的位置嵌入，以便模型了解单词在序列中的位置。</li></ul></li></ol><ul><li>在Transformer中，词嵌入和位置嵌入的输出将相加，以获得输入序列的最终嵌入表示。这个嵌入表示将被输入到编码器（Encoder）和解码器（Decoder）中，用于处理序列数据。</li><li>总之，Embedding层在Transformer模型中扮演着至关重要的角色，它有助于将离散的输入数据转化为连续的向量表示，使模型能够更好地理解和处理序列数据，这是Transformer在自然语言处理等领域取得成功的一个关键因素。</li></ul><h2 id="Transformer-1"><a href="#Transformer-1" class="headerlink" title="Transformer"></a>Transformer</h2><h3 id="Seq2seq"><a href="#Seq2seq" class="headerlink" title="Seq2seq"></a>Seq2seq</h3><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271550403.webp" alt="image-20230927155048224" style="zoom:50%;" /><h2 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h2><p><strong>Encoder：给一排向量，输出一排向量。</strong></p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271554658.webp" alt="image-20230927155409326" style="zoom:67%;" /><p>transformer 的 encoder 中的一个 block 中的组成。<strong>self-Attention（multi-head）、残差连接、Layer norm：对同一个feature的不同 dimension 去计算mean 和 standard deviation、全连接层、还有一个重要的 Position Encoding</strong></p><p>:star:一个 block 会重复 n 次。</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271603202.webp" alt="image-20230927160300913" style="zoom:50%;" /> <img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271611859.webp" alt="image-20230927161119553" style="zoom:50%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271617331.webp" alt="image-20230927161724096" style="zoom:50%;" /><h2 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h2><p>Decoder 会把前一时间的输出作为下一时间的输入。</p><p>Masked Self-Attention：考虑一个时间的输出时，会自动隐藏未来的输入。</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271819367.webp" alt="image-20230927181913141" style="zoom:50%;" /><p><strong>Autoregressive AND Non-autoregressive Decoder</strong></p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271837752.webp" alt="image-20230927183755461" style="zoom:50%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271843920.webp" alt="image-20230927184303622" style="zoom:50%;" /><p>NAT is usually worse than AT.</p><h2 id="Encoder-Decoder"><a href="#Encoder-Decoder" class="headerlink" title="Encoder-Decoder"></a>Encoder-Decoder</h2><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271851081.webp" alt="image-20230927185118801" style="zoom:50%;" /><h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><p>在训练时，面对 Decoder 的输出，可以与正确的 one-hot 特征做交叉熵，相当于做一个分类，最小化此交叉熵，才能起到效果。同时还不能忘记 END。</p><p>在训练时，我们要给 Decoder 正确的答案作为输入。</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271915458.webp" alt="image-20230927191537077" style="zoom:50%;" /><h2 id="Attention-is-all-you-need"><a href="#Attention-is-all-you-need" class="headerlink" title="Attention is all you need"></a>Attention is all you need</h2><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309271956584.webp" alt="image-20230927195615020" style="zoom:67%;" />]]></content>
      
      
      <categories>
          
          <category> Transformer </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Transformer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习杂七杂八</title>
      <link href="/posts/29157/"/>
      <url>/posts/29157/</url>
      
        <content type="html"><![CDATA[<hr><h1 id="Triplet-loss"><a href="#Triplet-loss" class="headerlink" title="Triplet loss"></a>Triplet loss</h1><p>Triplet loss（三元组损失）是一种在机器学习和深度学习中使用的损失函数，尤其用于度量学习（metric learning）和相似性或差异性度量任务。它通常用于人脸识别、图像检索和聚类等任务。三元组损失的主要目标是学习嵌入（特征表示），以使两个相似项目之间的相似度最大化，而两个不相似项目之间的相似度最小化。</p><p>以下是三元组损失的工作原理：</p><ol><li><strong>三元组选择</strong>：首先选择数据点的三元组。一个三元组包括锚定数据点（A）、正样本数据点（P）和负样本数据点（N）。A和P是相似的（它们属于相同的类别或类别），而A和N是不相似的（它们属于不同的类别或类别）。</li><li><strong>嵌入空间</strong>：通过神经网络或其他特征提取过程，将数据点映射到嵌入空间。在这个嵌入空间中，每个数据点都用一个向量表示。</li><li><strong>损失计算</strong>：计算每个三元组的损失，以鼓励嵌入空间具有所需的性质。损失通常定义为：</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">L(A, P, N) = <span class="built_in">max</span>(<span class="number">0</span>, d(A, P) - d(A, N) + margin)</span><br></pre></td></tr></table></figure><ul><li><code>d(A, P)</code>表示锚定（A）和正样本（P）在嵌入空间中的距离（相似度）。</li><li><code>d(A, N)</code>表示锚定（A）和负样本（N）在嵌入空间中的距离（相似度）。</li><li><code>margin</code>是一个超参数，指定正负样本之间必须保持的最小边距。</li></ul><p>​4.<strong>目标</strong>：通过在整个数据集上最小化此损失函数来实现目标。通过调整负责将数据点映射到嵌入空间的神经网络的参数来最小化损失。</p><p>三元组损失函数鼓励模型将锚定和正样本放在嵌入空间中靠近彼此的位置，同时将锚定和负样本分开。边距超参数控制正负样本之间需要保持的距离。较大的边距会导致更健壮的嵌入，但可能在计算上具有挑战性。</p><p>三元组损失是孪生网络和三元组网络架构的基本组成部分，广泛用于计算机视觉和自然语言处理等领域的各种任务，其中相似性或差异性度量是必不可少的。</p><p>“triplet loss”（三元组损失）通常与深度学习模型的编码器部分相关。编码器负责将输入数据点映射到嵌入空间，其中三元组损失用于学习如何将这些数据点在嵌入空间中适当地分布。在深度学习任务中，编码器通常由神经网络组成，可以是卷积神经网络（Convolutional Neural Network，CNN）或循环神经网络（Recurrent Neural Network，RNN），用于提取数据点的特征表示。</p><p>编码器与损失函数（如三元组损失）一起协同工作，以确保在嵌入空间中编码了对任务有用的信息。三元组损失帮助模型学习如何在嵌入空间中使相似项目更接近，不相似项目更分散.</p><h1 id="Center-Loss、Triplet-Loss-和-Contrastive-Loss"><a href="#Center-Loss、Triplet-Loss-和-Contrastive-Loss" class="headerlink" title="Center Loss、Triplet Loss 和 Contrastive Loss"></a>Center Loss、Triplet Loss 和 Contrastive Loss</h1><p>Center Loss、Triplet Loss 和 Contrastive Loss 都是用于深度学习中的损失函数，通常用于训练具有监督学习任务的神经网络，例如人脸识别或图像检索。它们有不同的应用和优势，以下是它们的简要介绍：</p><ol><li><strong>Center Loss（中心损失）</strong>:<ul><li><strong>应用领域</strong>：Center Loss 主要应用于人脸识别和图像检索等任务，其中同一类别内的样本需要聚集在一起，以便进行更好的分类或检索。</li><li><strong>工作原理</strong>：Center Loss 的核心思想是为每个类别维护一个中心，每个训练样本的损失是其特征与该中心的距离的函数。这鼓励网络学习到紧凑的类别中心。</li><li><strong>优势</strong>：Center Loss 有助于提高分类性能，减少类别内的散布，从而增强同一类别内样本的相似性。这可以有效解决类内差异问题。</li></ul></li><li><strong>Triplet Loss（三元组损失）</strong>:<ul><li><strong>应用领域</strong>：Triplet Loss 主要用于人脸验证、人脸识别和图像检索等任务，其中需要比较样本之间的相似性。</li><li><strong>工作原理</strong>：Triplet Loss 依赖于构建三元组，包括锚点（anchor）、正样本（positive）和负样本（negative）。目标是使锚点与正样本的距离小于锚点与负样本的距离，从而增强同一类别内样本的相似性，降低不同类别的样本之间的相似性。</li><li><strong>优势</strong>：Triplet Loss 鼓励网络学习到更好的特征表示，有助于在嵌入空间中更好地分离不同类别的样本。</li></ul></li><li><strong>Contrastive Loss（对比损失）</strong>:<ul><li><strong>应用领域</strong>：Contrastive Loss 也常用于人脸识别、图像检索和语音识别等任务，其中需要学习样本的相似性。</li><li><strong>工作原理</strong>：Contrastive Loss 依赖于构建对比样本对，包括相似对（positive pair）和非相似对（negative pair）。它鼓励相似对的嵌入距离趋近于零，而非相似对的距离远离零。</li><li><strong>优势</strong>：Contrastive Loss通过明确地定义相似和非相似对，有助于更好地捕捉嵌入空间中的样本相似性，可以在各种任务中提高性能。</li></ul></li></ol><p>总的来说，这三种损失函数都旨在通过深度学习来学习更好的特征表示，以便在不同的任务中提高模型的性能。它们在样本相似性的定义和鼓励方式上有所不同，因此在特定的应用场景中，选择合适的损失函数非常重要。</p><h1 id="Compatibility-Function"><a href="#Compatibility-Function" class="headerlink" title="Compatibility Function"></a>Compatibility Function</h1><p>兼容性函数（Compatibility Function）通常在度量学习和深度学习任务中使用，特别是在三元组损失（Triplet Loss）和孪生网络（Siamese Network）等任务中。这个函数的目的是度量两个数据点之间的相似性或兼容性。</p><p>通常，兼容性函数 F 接受两个输入数据点，比如锚定数据点（通常标记为 A）和另一个数据点（可能是正样本标记为 P 或负样本标记为 N）。它的输出是一个衡量这两个数据点之间关系的分数或相似性度量。</p><p>兼容性函数的设计取决于具体的任务和应用场景。以下是一些示例：</p><ol><li><strong>欧氏距离</strong>：在一些情况下，兼容性函数可以是简单的欧氏距离计算，即 F(A, P) &#x3D; ||A - P||，其中 ||A - P|| 表示 A 和 P 之间的欧氏距离。</li><li><strong>余弦相似度</strong>：另一个常见的兼容性函数是余弦相似度，它衡量了两个向量之间的夹角余弦值。余弦相似度定义为：F(A, P) &#x3D; (A·P) &#x2F; (||A|| * ||P||)，其中 A·P 表示 A 和 P 的内积，而 ||A|| 和 ||P|| 分别表示 A 和 P 向量的范数。</li><li><strong>神经网络输出</strong>：在深度学习中，兼容性函数通常由神经网络产生。这个神经网络可以是孪生网络的一部分，用于将输入数据点映射到嵌入空间中，并计算它们之间的相似性分数。</li></ol><p>兼容性函数的选择取决于具体的任务和数据特性。它的目标是在学习过程中鼓励模型将相似数据点的兼容性得分增大，而不相似数据点的兼容性得分减小。这有助于嵌入空间中的数据点更好地表示任务所需的关系，如相似性或差异性。在三元组损失中，兼容性函数用于比较锚定数据点与正样本和负样本之间的关系，以确定它们在嵌入空间中的分布。</p><h1 id="Siamese-Network"><a href="#Siamese-Network" class="headerlink" title="Siamese Network"></a>Siamese Network</h1><p>孪生网络（Siamese Network）是一种深度神经网络架构，通常用于度量学习和相似性度量任务。这种网络结构的特点是它包含两个完全相同（或称为孪生）的子网络，这两个子网络共享相同的权重和结构。</p><p>孪生网络的主要应用之一是学习如何度量数据点之间的相似性或差异性。它在识别人脸、图像检索、签名验证、语义匹配等任务中非常有用。以下是孪生网络的工作原理：</p><ol><li><strong>双子网络结构</strong>：孪生网络包含两个相同的子网络，通常称为”孪生支路”。这两个支路具有相同的结构和参数。每个支路接受一个输入数据点，并将其映射到一个嵌入空间中。</li><li><strong>共享权重</strong>：孪生网络的关键特点是两个支路共享相同的权重。这意味着它们在训练过程中学习相同的特征表示。共享权重确保两个支路能够提取类似的特征，从而使它们在嵌入空间中的表示更具可比性。</li><li><strong>比较嵌入空间中的数据点</strong>：一旦两个数据点通过孪生网络的两个支路映射到嵌入空间中，它们的表示可以在该空间中进行比较。这通常涉及计算这两个嵌入之间的相似性分数，例如余弦相似度或欧氏距离。</li><li><strong>学习任务</strong>：孪生网络的学习任务通常包括监督学习，其中模型通过比较两个数据点的嵌入来学习如何判断它们的相似性。在三元组损失中，模型学习如何将锚定数据点与正样本靠拢，同时将锚定数据点与负样本分开。</li></ol><p>总的来说，孪生网络是一种非常有用的架构，用于学习数据点之间的相似性或差异性，以便在各种应用中执行相似性度量任务。通过共享权重的方式，它允许模型从输入数据中提取有关相似性的有用信息。</p><h1 id="Joint-representation"><a href="#Joint-representation" class="headerlink" title="Joint representation"></a>Joint representation</h1><p>“Joint representation”（联合表示）是一个广泛用于不同领域的术语，通常指的是将多个不同特征、属性或数据源组合成一个共同的表示形式，以便更有效地处理或分析数据。这个概念在机器学习、自然语言处理、计算机视觉和其他领域中都有应用。</p><p>在自然语言处理中，”joint representation” 可能指的是将不同类型的信息（例如文本和图像）结合在一起，以便更好地理解语言和视觉之间的关系。这可以用于任务如图像字幕生成，其中模型需要将图像内容与相关的文字描述相结合。</p><p>在机器学习中，”joint representation” 可以指的是将多个特征或数据源组合在一起，以便训练一个模型来更好地捕捉它们之间的关系。这可以提高模型的性能，特别是当数据源之间存在复杂的相互作用时。</p><p>总的来说，”joint representation” 是一种数据表达方法，它旨在将多个信息源结合在一起，以便更好地理解和利用这些信息。具体的含义可能因上下文和领域而异。</p><p>“Joint representation”（联合表示）是一个跨足多个领域的概念，因此它不属于某个特定的知识点分支，而是可以在多个学科中找到应用。这包括但不限于：</p><ol><li>机器学习和深度学习：在这些领域中，联合表示可以用于将多个数据源或特征组合在一起，以便训练更复杂的模型，提高性能。</li><li>自然语言处理：在NLP中，联合表示可以用于将文本和图像数据结合在一起，以便处理多模态信息，例如图像字幕生成、视觉问答等任务。</li><li>计算机视觉：在计算机视觉中，联合表示可以用于将不同的视觉特征（例如颜色、纹理、形状等）结合在一起，以更好地理解图像内容。</li><li>数据科学和统计学：在数据分析中，联合表示可以用于将多个数据集或特征合并，以进行综合分析或建模。</li><li>人工智能和机器人学：在这些领域中，联合表示可以用于将感知、决策和控制信息融合在一起，以支持自主智能系统的运行。</li></ol><h1 id="Swish激活函数"><a href="#Swish激活函数" class="headerlink" title="Swish激活函数"></a>Swish激活函数</h1><p>Swish（又称Swish激活函数）是一种神经网络中的非线性激活函数，用于增加模型的表示能力。它在2017年由Google的研究人员提出，通过实验证明在某些情况下，它能够提供更好的性能和更快的训练速度。</p><p>Swish激活函数的数学表达式如下：</p><p>Swish(x) &#x3D; x * sigmoid(βx)</p><p>其中，x是输入，sigmoid表示S型函数（logistic函数），β是一个可调整的参数。Swish函数的输出是输入x和S型函数的乘积。</p><p>以下是Swish激活函数的一些关键特点：</p><ol><li><strong>平滑性</strong>: Swish函数是光滑的，这意味着它是可导的，并且可以用于梯度下降等优化算法中，这有助于神经网络的训练。</li><li><strong>非线性性</strong>: Swish是一种非线性激活函数，它有助于神经网络学习复杂的非线性关系。与传统的激活函数如ReLU相比，Swish具有更强的非线性性质。</li><li><strong>自适应性</strong>: Swish函数具有自适应性，因为它的形状受到输入x的影响。在输入较大的情况下，S型函数趋于1，因此Swish函数变得类似于恒等函数，允许信息更自由地传递。在输入较小的情况下，S型函数趋于0，施加了非线性变换。</li><li><strong>参数化</strong>: Swish函数具有一个参数β，可以调整其形状。通过调整这个参数，可以改变Swish函数的曲线，以适应不同的数据和任务</li></ol><h1 id="ELU激活函数"><a href="#ELU激活函数" class="headerlink" title="ELU激活函数"></a>ELU激活函数</h1><p>ELU（Exponential Linear Unit）是一种激活函数，常用于神经网络中。ELU激活函数的数学定义如下：</p><p>对于输入 x，ELU 函数的输出 y 是：</p><ul><li>当 x &gt; 0 时，y &#x3D; x。</li><li>当 x ≤ 0 时，y &#x3D; α * (exp(x) - 1)，其中 α 是一个小的正数，通常接近于零。</li></ul><p>ELU 激活函数的主要特点包括：</p><ol><li>幅度有界：ELU 对于正值没有上限，因此可以处理大的正输入。这有助于减轻梯度消失问题，因为神经元在正值上可以继续学习。</li><li>幅度有界：当输入为负数时，ELU 具有负数幅度，有助于防止激活神经元过度激活并减轻梯度爆炸问题。</li><li>连续可导：ELU 在整个输入范围内都是可导的，这对于使用梯度下降算法进行优化非常重要。</li><li>带参数：ELU 函数包括一个参数 α，该参数控制输入为负时的饱和度（saturation），通常取较小的正值，比如 0.01。这个参数可以根据具体问题进行调整。</li></ol><p>ELU 激活函数在一些神经网络架构中表现出良好的性能，特别是在解决梯度消失和梯度爆炸问题时。它是一种替代 ReLU（Rectified Linear Unit）激活函数的选择，因为它在处理负值输入时的平滑性和饱和度方面更具优势。</p><h1 id="深度度量学习"><a href="#深度度量学习" class="headerlink" title="深度度量学习"></a>深度度量学习</h1><p>一种深度学习的分支，它专注于学习数据之间的相似性度量或距离度量。深度度量学习的目标是通过神经网络和深度学习技术来学习更具代表性的数据嵌入（embedding），以便更好地捕获数据之间的相似性和差异性。这在许多机器学习任务中都非常有用，例如人脸识别、物体检测、图像检索、推荐系统等。</p><p>以下是深度度量学习的一些关键特点和方法：</p><ol><li><strong>嵌入学习（Embedding Learning）</strong>：深度度量学习的核心概念是学习将数据映射到一个低维嵌入空间的函数。这个嵌入空间被设计为能够更好地捕获数据的相似性，因此在该空间中，相似的数据点应该更接近，而不相似的数据点应该更远。</li><li><strong>孪生网络（Siamese Networks）</strong>：一种常见的深度度量学习方法是使用孪生网络结构。孪生网络接受一对数据点（例如，一对图像）作为输入，然后共享权重来学习它们的嵌入表示，使得相似的数据点在嵌入空间中更接近。</li><li><strong>三元损失（Triplet Loss）</strong>：在孪生网络中，通常使用三元损失函数，它要求使正例对的嵌入距离尽可能小，负例对的嵌入距离尽可能大。这有助于强调相似性的学习。</li><li><strong>度量学习算法</strong>：除了神经网络方法，深度度量学习还可以使用传统的度量学习算法，如局部线性嵌入（Locally Linear Embedding, LLE）、等度量映射（Isomap）等，与深度学习结合来学习更具代表性的嵌入。</li><li><strong>应用领域</strong>：深度度量学习广泛应用于图像处理、自然语言处理、推荐系统和生物信息学等领域。在图像处理中，它可用于图像检索、人脸识别和物体检测。在自然语言处理中，可以用于学习句子或文档之间的语义相似性。</li></ol><p>深度度量学习的主要目标是改善特征表示，以更好地捕获数据之间的相似性结构。通过学习适当的度量或距离度量，深度度量学习有助于提高各种机器学习任务的性能，从而实现更好的数据挖掘和信息检索。</p><h1 id="Inductive-bias"><a href="#Inductive-bias" class="headerlink" title="Inductive bias"></a>Inductive bias</h1><p>“Inductive bias”（归纳偏置）是指机器学习算法或模型在学习任务中对某些假设或先验知识的倾向性或偏好性。这种偏置使得模型更倾向于对某些模型类别或函数的学习，而非其他可能的类别或函数。归纳偏置是模型中的一种设计选择，旨在简化学习问题并提高模型的泛化能力。</p><p>在机器学习中，归纳偏置有助于缩小搜索空间，从而提高学习的效率。然而，选择的归纳偏置可能会导致对某些模式的过度拟合，从而影响模型在未见数据上的性能。因此，设计合适的归纳偏置需要权衡，以确保模型在特定任务上的表现良好，并能够在未知数据上泛化。</p><p>(以上内容来自chatgpt)</p><p>归纳偏置在机器学习中是一种很微妙的概念：在<strong>机器学习中，很多学习算法经常会对学习的问题做一些假设，这些假设就称为归纳偏置（inductive bias）</strong>。</p><p>归纳偏置这个译名可能不能很好地帮助理解，不妨拆开来看：</p><ul><li><strong>归纳</strong>：是自然科学中常用的两大方法之一（归纳与演绎，inductive and deduction），指的是从一些例子中寻找共性，泛化，形成一个比较通用的过程；</li><li><strong>偏置</strong>：是指我们对模型的偏好。</li></ul><p>因此，<strong>归纳偏置可以理解为，从现实生活中观察到的现象中归纳出一定的规则（heuristics），然后对模型做一定对约束，从而起到“模型选择”的作用。即从假设空间中选择出更符合现实规则的模型。</strong>其实，贝叶斯学习中的“先验（prior）”这个叫法，可能比“归纳偏置”更直观一些。</p><p>卷积神经网络（CNN）和变压器（Transformer）都具有归纳偏置，而CNN的归纳偏置可以被用来指导Transformer的学习。这种组合利用两种不同类型的模型，各自的优势能够在一些任务中取得更好的性能。</p><ol><li><strong>CNN的归纳偏置：</strong> CNN在处理图像等空间数据时，具有局部感知和参数共享的归纳偏置。卷积层通过卷积核在局部区域上提取特征，这有助于模型捕捉到空间层次的结构和模式。</li><li><strong>Transformer的归纳偏置：</strong> Transformer则更适合处理序列数据，例如自然语言处理任务。其自注意力机制允许模型在序列中捕捉长距离的依赖关系，而不依赖于固定大小的局部感知。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deeplearning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>强化学习</title>
      <link href="/posts/29156/"/>
      <url>/posts/29156/</url>
      
        <content type="html"><![CDATA[<h1 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a><p align="center">强化学习</p></h1><p>以下内容来自chatgpt：</p><ul><li>强化学习（Reinforcement Learning，简称RL）是一种机器学习方法，旨在使智能体（或代理程序）通过与环境的交互学习来制定决策，以最大化某种累积奖励信号。在强化学习中，智能体需要在不断尝试和观察环境中的动态过程中学习最佳策略，以达到特定的目标。</li></ul><p>​以下是强化学习的主要概念和要点：</p><ol><li><strong>智能体（Agent）</strong>：强化学习中的主体，它负责从环境中观察状态、采取行动，并根据其行动获得奖励或惩罚。</li><li><strong>环境（Environment）</strong>：智能体操作的外部系统，可以是真实世界中的物理环境，也可以是虚拟模拟环境。环境的状态可能是可观测的，也可能是部分可观测的或隐含的。</li><li><strong>状态（State）</strong>：描述环境的特定瞬时情况的信息。状态可以是完全可观测的，也可以是部分可观测的。智能体的决策通常基于当前状态。</li><li><strong>行动（Action）</strong>：智能体可以采取的操作或策略，它们会影响环境的演化。</li><li><strong>策略（Policy）</strong>：智能体的策略是一种映射，它将状态映射到采取的行动。策略可以是确定性的或随机性的。</li><li><strong>奖励（Reward）</strong>：环境向智能体提供的一个标量信号，用于评估智能体行动的好坏。奖励通常用于引导智能体学习适当的策略。</li><li><strong>累积奖励（Cumulative Reward）</strong>：智能体在与环境互动的过程中，通过时间累积的奖励信号。智能体的目标是最大化累积奖励。</li><li><strong>价值函数（Value Function）</strong>：用于估计在给定状态或状态-行动对下能够获得的预期累积奖励。价值函数有两种形式：状态值函数和动作值函数。</li><li><strong>强化学习算法</strong>：用于学习策略或价值函数的算法。常见的强化学习算法包括Q-learning、深度Q网络（DQN）、策略梯度方法、蒙特卡洛方法等。</li><li><strong>探索与利用</strong>：在强化学习中，智能体需要在尝试已知有效行动（利用）和尝试未知行动（探索）之间取得平衡，以便更好地学习。</li><li><strong>马尔可夫决策过程（MDP）</strong>：强化学习问题通常被建模为马尔可夫决策过程，其中状态转移和奖励函数满足马尔可夫性质，即未来的状态和奖励仅依赖于当前状态和行动。</li></ol><ul><li>强化学习在许多领域有广泛的应用，包括自动化控制、机器人学、自动驾驶、游戏玩法、金融交易等。它的核心思想是通过与环境的交互来学习最佳策略，而不需要显式的监督标签，因此在处理复杂的、动态的决策问题时具有潜在的优势。然而，强化学习也面临着许多挑战，包括训练稳定性、样本效率、探索问题等。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241346900.webp" alt="image-20230924134643712"></p><ul><li>给出奖励或者奖励函数，来告诉智能体怎样才算做的好。<strong>指定奖励函数而不是设计操作，可以使系统更加灵活且表现得更好。</strong></li><li>算法得工作时自动找出如何才是好的操作。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241356050.webp" alt="image-20230924135610804"></p><h2 id="以火星探测器启发的简化示例来开发强化学习："><a href="#以火星探测器启发的简化示例来开发强化学习：" class="headerlink" title="以火星探测器启发的简化示例来开发强化学习："></a>以火星探测器启发的简化示例来开发强化学习：</h2><ul><li>状态</li><li>动作</li><li>奖励</li><li>下一个状态</li></ul><p> <img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241407778.webp" alt="image-20230924140735573"></p><h2 id="回报（Return）"><a href="#回报（Return）" class="headerlink" title="回报（Return）"></a>回报（Return）</h2><p>在强化学习中，”回报”（Return）和”折扣因子”（Discount Factor）是两个相关但不同的概念，它们通常一起使用，用于计算累积奖励。</p><ol><li><p><strong>回报（Return）</strong>：</p><ul><li>回报是在强化学习任务中表示智能体在与环境互动的过程中所获得的奖励信号的总和。</li><li>回报通常用符号 “G” 表示，它是从某一时间步 t 开始到任务结束时间步 T 之间的未来奖励的总和。</li><li>回报是衡量智能体在执行一系列行动后所获得的总效用或总奖励的指标。它是一个累积的量，反映了智能体的决策策略在整个任务或轨迹中的表现。</li></ul></li><li><p><strong>折扣因子（Discount Factor）</strong>：</p><ul><li><p>折扣因子是一个控制未来奖励在回报计算中的权重的参数。</p></li><li><p>折扣因子通常用符号 “γ”（小写希腊字母gamma）表示。</p></li><li><p><strong>折扣因子的作用是在计算回报时考虑未来奖励的折现程度，以便更关注当前时间步的奖励，而较少关注将来的奖励。</strong></p></li><li><p>折扣因子引入后，回报在考虑折扣因子的情况下可以表示为：</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241416043.webp" alt="image-20230924141635899"></p></li><li><p><strong>折扣因子的取值通常在0到1之间。较小的折扣因子会导致未来奖励以指数方式减小，而较大的折扣因子会使未来奖励以线性方式减小。</strong></p></li></ul></li></ol><ul><li><strong>折扣因子的存在使强化学习智能体能够考虑未来奖励的折现程度，以便更好地学习长期决策策略。通常，较高的折扣因子鼓励智能体更长远地规划，而较小的折扣因子会使其更注重短期奖励。</strong></li><li>总之，回报和折扣因子是强化学习中的重要概念，它们一起用于描述智能体在任务中的表现以及如何考虑未来奖励的影响。回报是累积奖励的总和，而折扣因子控制着未来奖励的权重。根据任务的性质和要求，可以调整折扣因子的值来调整智能体的学习策略。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241420236.webp" alt="image-20230924142050937"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241428050.webp" alt="image-20230924142805781"></p><ul><li>如果有奖励是负的，折扣因子会激励系统将负奖励尽可能推迟到未来。</li></ul><h2 id="强化学习策略"><a href="#强化学习策略" class="headerlink" title="强化学习策略"></a>强化学习策略</h2><p>​具体地，Π 可以表示为：</p><p>​Π(s) &#x3D; a</p><p>​其中，</p><ul><li>Π(s) 表示在状态 s 下智能体选择的行动。</li><li>s 表示当前的状态。</li><li>a 表示智能体根据策略 Π 在状态 s 下选择的行动。</li></ul><p>策略 Π 定义了智能体在环境中如何行动，它是强化学习问题的关键组成部分。强化学习的目标通常是找到一个最优策略 Π*，使得在给定任务下获得最大的累积奖励。</p><p>策略可以是确定性的，即对于每个状态 s，它都映射到一个具体的行动 a。也可以是随机的，即对于每个状态 s，它可以映射到一个概率分布，从中随机选择行动 a。随机策略通常在探索问题中使用，以便智能体可以更好地探索环境。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241457108.webp" alt="image-20230924145718914"></p><h2 id="马尔可夫决策过程"><a href="#马尔可夫决策过程" class="headerlink" title="马尔可夫决策过程"></a>马尔可夫决策过程</h2><ul><li><strong>强化学习问题通常被建模为马尔可夫决策过程，其中状态转移和奖励函数满足马尔可夫性质，即未来的状态和奖励仅依赖于<code>当前状态</code>和行动。</strong>而不考虑是如何到达现在状态的。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241518204.webp" alt="image-20230924151800022"></p><p>马尔可夫决策过程（MDP，Markov Decision Process）是强化学习中用于建模决策问题的数学框架。它是一个数学模型，用于描述智能体（或代理）在与环境互动的过程中做出决策的情境。MDP 是一个非常重要的概念，用于研究和解决各种决策问题，如机器人控制、自动化决策、游戏策略等。</p><p>​MDP 的核心特点包括：</p><ol><li><strong>状态（States）</strong>：MDP 描述了一个包含多个状态的环境，每个状态代表了环境的一个可能情境或配置。状态可以是离散的（例如，在棋盘游戏中的不同棋盘布局）或连续的（例如，在机器人控制中的位置和速度）。</li><li><strong>行动（Actions）</strong>：在每个状态下，智能体可以采取一组可能的行动或操作。行动集合通常是固定的，且对于每个状态都可以选择。行动可以是离散的或连续的，取决于具体的问题。</li><li><strong>奖励（Rewards）</strong>：在MDP中，每次智能体采取一个行动后，环境会返回一个奖励信号，用来表示该行动的好坏程度。奖励是一个标量值，可以是正数（奖励）、负数（惩罚）或零。</li><li><strong>转移概率（Transition Probabilities）</strong>：MDP 也包括状态转移概率，用来描述在采取某个行动后，智能体将以何种概率转移到下一个状态。这个概率通常用条件概率分布表示，表示为 P(s’ | s, a)，其中 s’ 是下一个状态，s 是当前状态，a 是采取的行动。</li><li><strong>折扣因子（Discount Factor）</strong>：折扣因子（通常用符号 γ 表示）用来考虑未来奖励的折现程度。折扣因子决定了智能体更关注即时奖励还是长期奖励。折扣因子通常取值在0到1之间。</li></ol><ul><li><p>MDP 的目标是寻找一个策略（Policy），即一个从状态到行动的映射，以最大化在任务过程中获得的累积奖励。通常，这个最优策略被表示为 π*，并且在给定 MDP 参数的情况下，通过不同的强化学习算法来寻找。</p></li><li><p>总之，马尔可夫决策过程（MDP）是强化学习中用于建模和解决决策问题的数学框架，它包括状态、行动、奖励、状态转移概率和折扣因子等要素，用于描述智能体在与环境互动的环境中做出决策的情境。</p></li></ul><h2 id="状态-动作价值函数"><a href="#状态-动作价值函数" class="headerlink" title="状态-动作价值函数"></a>状态-动作价值函数</h2><p>状态-动作价值函数（State-Action Value Function），通常用符号 Q(s, a) 表示，也称为 Q 函数或动作值函数，是一个函数，用于估计在给定状态 s 下采取行动 a 的价值或效用。状态-动作价值函数表示了智能体在特定状态下采取特定行动的预期累积奖励。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241539570.webp" alt="image-20230924153952346"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241543604.webp" alt="image-20230924154302355"></p><ul><li>找出能使得Q(s, a) 最大的  s  和  a  ，找到最优Q函数。</li></ul><h2 id="贝尔曼方程"><a href="#贝尔曼方程" class="headerlink" title="贝尔曼方程"></a>贝尔曼方程</h2><ul><li>​贝尔曼方程（Bellman Equation）是强化学习中的一个重要方程，用于描述状态值函数（State Value Function）或状态-动作值函数（State-Action Value Function）之间的关系。贝尔曼方程表达了一个状态（或状态-动作对）的价值与其未来状态（或状态-动作对）的价值之间的递归关系，从而帮助在强化学习问题中估计或计算这些价值函数。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241650005.webp" alt="image-20230924165040797"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241650628.webp" alt="image-20230924165056375"></p><p> <img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241651089.webp" alt="image-20230924165112895"></p><ul><li><p>在强化学习问题中获得的总回报由两部分，一是立即获得的奖励，二是而是下一个状态开始获得的回报。</p></li><li><p><strong>贝尔曼方程的实质就是分解奖励。</strong></p> <img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241655150.webp" alt="image-20230924165513932" style="zoom:200%;" /></li></ul><h2 id="连续状态下的应用"><a href="#连续状态下的应用" class="headerlink" title="连续状态下的应用"></a>连续状态下的应用</h2><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309261352782.webp" alt="image-20230926135258527"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309261353537.webp" alt="image-20230926135316307"></p><h2 id="深度Q网络"><a href="#深度Q网络" class="headerlink" title="深度Q网络"></a>深度Q网络</h2><p>（Deep Q-Network，DQN）</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309261353428.webp" alt="image-20230926135345182"></p><ul><li>使用监督学习，训练一个神经网络，即从状态动作对到Q的映射，进行训练。</li><li>构建构建x和y的数据集。</li><li>训练深度神经网络来实现 Q 函数估计的训练数据集的构建是强化学习中非常关键的一步。这个数据集应该包含了在环境中代理（agent）与世界（环境）互动的经验。以下是构建 Q 函数估计的训练数据集的一般步骤：<ol><li><strong>环境和任务定义</strong>：首先，明确定义包括状态空间、动作空间、奖励函数和终止条件。</li><li><strong>初始化数据集</strong>：开始时，可以创建一个空的数据集来存储经验。</li><li><strong>Agent-Environment 交互</strong>：将代理放置在环境中，并开始与环境互动。在每个时间步，代理根据当前策略选择一个动作，并将其应用于环境。环境返回下一个状态和获得的奖励。这个过程将重复进行，直到达到终止条件。</li><li><strong>收集经验</strong>：在每个时间步，将代理的经验元组 (s, a, r, s’) 存储到数据集中，其中：<ul><li>s：当前状态。</li><li>a：代理选择的动作。</li><li>r：从环境中获得的奖励。</li><li>s’：下一个状态，即环境的响应状态。</li><li><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309261549184.webp" alt="image-20230926154934926"></li></ul></li><li><strong>定义经验回放缓冲区</strong>：创建一个经验回放缓冲区，用于存储先前的经验元组 (s, a, r, s’)，其中 s 是当前状态，a 是采取的动作，r 是获得的奖励，s’ 是下一个状态。这个缓冲区用于随机抽样以减小数据之间的相关性。</li><li><strong>初始化目标网络</strong>：创建一个目标神经网络Q_new，它是 Q 网络的一个副本，但参数更新频率较低。目标网络用于计算目标 Q 值，以减小目标值与当前估计值之间的相关性，提高训练的稳定性。</li><li><strong>训练神经网络</strong>：使用经验回放缓冲区中的样本数据，通过最小化 Q 网络的损失函数来训练神经网络。损失函数通常是 Q 网络输出与目标 Q 值之间的均方误差（MSE）。优化算法（如随机梯度下降）用于更新网络参数。</li><li><strong>更新目标网络</strong>：定期更新目标网络的参数，通常采用软更新策略，将目标网络的参数与 Q 网络的参数进行平滑更新。</li><li><strong>执行策略</strong>：使用已经训练好的 Q 网络来执行策略。在每个时间步，根据 Q 值选择动作，可以使用 ε-贪心策略来进行探索和利用的权衡。</li><li><strong>训练迭代</strong>：重复执行上述步骤，不断收集经验和训练网络，直到 Q 函数收敛或满足终止条件。</li><li><strong>评估性能</strong>：对训练后的模型进行性能评估，可以在训练过程中定期测试模型的性能，并根据评估结果来调整训练参数。</li></ol></li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309261605725.webp" alt="image-20230926160527470"></p><blockquote><ol><li><strong>初始化目标网络</strong>：<ul><li>在 DQN 中，我们使用两个神经网络：一个是 Q 网络，另一个是目标网络（通常称为 Q_new）。两者的结构相同，但参数不同。</li><li>Q 网络用于估计当前状态下每个动作的 Q 值。</li><li>目标网络用于计算目标 Q 值，以减小目标值与当前估计值之间的相关性，从而提高训练的稳定性。目标网络的参数在训练过程中更新得相对较慢，使其更稳定。</li><li>初始化目标网络的参数通常是将 Q 网络的参数复制给目标网络，但在训练过程中不直接更新目标网络的参数。</li></ul></li><li><strong>训练神经网络</strong>：<ul><li>训练神经网络是为了使 Q 网络能够准确估计每个状态下的 Q 值，从而实现最优策略的学习。</li><li>使用经验回放缓冲区中存储的经验数据，随机选择一小批数据，包括状态 (s)、采取的动作 (a)、获得的奖励 (r)、下一个状态 (s’) 以及标志着任务是否结束的信息。</li><li>计算目标 Q 值，通常使用 Bellman 方程来计算，具体是 Q-learning 的更新规则：Q(s, a) &#x3D; r + γ * max(Q_new(s’))</li><li>计算 Q 网络的输出，并计算其与目标 Q 值之间的均方误差（MSE）作为损失函数。</li><li>使用优化算法（如随机梯度下降）来最小化损失函数，从而更新 Q 网络的参数。</li></ul></li><li><strong>更新目标网络</strong>：<ul><li>为了进一步提高训练的稳定性，定期更新目标网络的参数。</li><li>更新通常采用软更新策略，即将 Q 网络的参数以一定比例复制给目标网络。这个比例通常很小，例如，每次更新只有一小部分参数被复制，这有助于使目标网络的参数变化较为平滑。</li><li>目标网络的更新频率相对较低，通常是每隔一定数量的训练步骤才更新一次，这有助于提高训练的稳定性。</li></ul></li></ol></blockquote><h2 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h2><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309261626377.webp" alt="image-20230926162646094"></p><h2 id="ε-贪心策略"><a href="#ε-贪心策略" class="headerlink" title="ε-贪心策略"></a>ε-贪心策略</h2><blockquote><p>ε-贪心策略（ε-Greedy Strategy）是在强化学习中常用的一种探索与利用的权衡策略，用于在探索未知情况和利用已知信息之间做出决策。这个策略的名称中的ε表示一个小的正数，通常是一个很小的概率值，如0.1或0.05。ε-贪心策略的基本思想如下：</p><ul><li>在每次选择动作的时候，以概率ε选择随机动作，以概率(1-ε)选择当前已知的最佳动作（也就是根据当前的 Q 函数估计选择最高 Q 值的动作）。</li></ul><p>具体来说，ε-贪心策略可以用以下方式描述：</p><ol><li>以概率ε（即探索率）选择随机动作：在每个时间步，以ε的概率随机选择一个动作，不考虑当前的 Q 值估计。这个随机选择的动作有助于探索环境中的未知情况，以便更好地了解环境。</li><li>以概率(1-ε)选择当前已知的最佳动作：以(1-ε)的概率选择当前 Q 函数估计中具有最高 Q 值的动作，即选择当前已知的最佳策略。这个部分有助于利用已知信息，以获得更高的奖励。</li></ol><p>ε-贪心策略的目标是在不断地探索新情况的同时，渐进地转向利用已知信息。选择合适的ε值对于训练强化学习代理非常重要，因为过高的ε值可能导致代理过于频繁地随机探索，无法有效地利用已知信息，而过低的ε值可能导致代理过于贪心，错过了探索未知情况的机会。</p><p>通常，在训练初期，ε值较大，以便代理更多地探索环境。随着训练的进行，可以逐渐减小ε，使代理更加倾向于利用已知信息。<strong>这种动态调整ε的策略称为ε衰减策略。</strong></p></blockquote><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309261637244.webp" alt="image-20230926163711999"></p><ul><li>强化学习才是真正的炼丹</li></ul>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>推荐系统</title>
      <link href="/posts/29155/"/>
      <url>/posts/29155/</url>
      
        <content type="html"><![CDATA[<h1 id="推荐系统"><a href="#推荐系统" class="headerlink" title="推荐系统"></a><p align="center">推荐系统</p></h1><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309231349819.webp" alt="image-20230923134955598"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309231350367.webp" alt="image-20230923135019057"></p><h2 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h2><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309231353772.webp" alt="image-20230923135337594"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309231356932.webp" alt="image-20230923135633739"></p><h3 id="协同过滤算法"><a href="#协同过滤算法" class="headerlink" title="协同过滤算法"></a>协同过滤算法</h3><p>协同过滤是一类流行的推荐系统算法，它们利用用户历史行为数据来进行推荐，而不依赖于物品的内容信息。协同过滤算法基于以下两个核心思想：</p><ol><li><strong>用户协同过滤</strong>（User-Based Collaborative Filtering）：这种方法基于用户之间的相似性来进行推荐。它假设如果两个用户在过去有相似的行为模式，那么他们在将来可能会有相似的兴趣。具体步骤包括：<ul><li>计算用户之间的相似性，通常使用余弦相似度或皮尔逊相关系数等度量。</li><li>选择与目标用户最相似的一组用户。</li><li>基于这些相似用户的行为来生成推荐，例如，选择相似用户喜欢的物品。</li></ul></li><li><strong>物品协同过滤</strong>（Item-Based Collaborative Filtering）：这种方法基于物品之间的相似性来进行推荐。它假设如果一个用户喜欢某个物品，那么他们也可能喜欢与该物品相似的其他物品。具体步骤包括：<ul><li>计算物品之间的相似性，通常使用余弦相似度或其他相似性度量。</li><li>对于目标用户，找到他们喜欢的物品，并基于这些物品的相似性来生成推荐。</li></ul></li></ol><p>协同过滤算法的优点包括能够捕捉用户的复杂兴趣和推荐个性化的物品。然而，它们也面临一些挑战，如稀疏性（用户-物品交互数据通常是稀疏的）、冷启动问题（对于新用户或新物品，没有足够的历史数据进行推荐）和可扩展性问题（处理大规模数据时的计算复杂性）。</p><p>在实际应用中，通常会将协同过滤算法与其他技术一起使用，如基于内容的推荐、深度学习模型等，以提高推荐系统的性能。此外，还可以采用改进的协同过滤算法，如加权协同过滤、矩阵分解方法（如奇异值分解和隐语义模型）等，以解决协同过滤算法的一些限制。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309231422848.webp" alt="image-20230923142205549"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309231422456.webp" alt="image-20230923142220267"></p><ul><li><strong>将上述两个代价函数结合在一起，得到学习 <em>w</em>、<em>b</em> 和 <em>x</em> 的总体代价函数。</strong></li><li>先对人进行评估，选择最小化 <em>*<em>w</em>、*b</em>** 的代价函数。</li><li>再基于电影进行评估，选择最小化  <em><strong>x</strong></em> 的代价函数。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309231422827.webp" alt="image-20230923142239629"></p><h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h3><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309231435536.webp" alt="image-20230923143553349"></p><blockquote><p>   <em><strong>i</strong></em>   表示电影、   <em><strong>j</strong></em>   表示用户、   <em><strong>k</strong></em>   表示特征向量。</p></blockquote><h2 id="二分类的泛化"><a href="#二分类的泛化" class="headerlink" title="二分类的泛化"></a>二分类的泛化</h2><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309231453662.webp" alt="image-20230923145323447"></p><h4 id="二分类协同过滤代价函数"><a href="#二分类协同过滤代价函数" class="headerlink" title="二分类协同过滤代价函数"></a>二分类协同过滤代价函数</h4><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309231454843.webp" alt="image-20230923145450595"></p><h2 id="均值归一化"><a href="#均值归一化" class="headerlink" title="均值归一化"></a>均值归一化</h2><p>​帮助尚未对任何电影进行评级的新用户更好的预测电影等级。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309231540713.webp" alt="image-20230923154059477"></p><h2 id="TensorFlow实现协同过滤"><a href="#TensorFlow实现协同过滤" class="headerlink" title="TensorFlow实现协同过滤"></a>TensorFlow实现协同过滤</h2><p>Auto Grad（Diff ）：自动计算梯度</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309231629111.webp" alt="image-20230923162948840"></p><h2 id="寻找相关特征"><a href="#寻找相关特征" class="headerlink" title="寻找相关特征"></a>寻找相关特征</h2><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241003826.webp" alt="image-20230924100350568"></p><h3 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h3><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241004481.webp" alt="image-20230924100418204"></p><h2 id="基于内容的过滤算法"><a href="#基于内容的过滤算法" class="headerlink" title="基于内容的过滤算法"></a>基于内容的过滤算法</h2><ul><li>基于内容的过滤关键在于，能否充分利用用户和项目的特征来找到比纯粹的协同过滤算法更好的匹配。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241010109.webp" alt="image-20230924101027874"></p><p>以下内容来自chatgpt：</p><p>基于内容的协同过滤算法（Content-Based Filtering）和纯粹的协同过滤算法（Collaborative Filtering）是两种不同类型的推荐系统方法，它们在推荐原理和工作方式上有很大的区别。</p><p>以下是基于内容的协同过滤算法和纯粹的协同过滤算法之间的主要区别：</p><ol><li><p>推荐依据：</p><ul><li>基于内容的协同过滤：这种算法基于物品的属性和用户的个人偏好来进行推荐。它关注物品的特征和用户的历史行为，通过比较物品和用户的特征向量来生成推荐。因此，它假设用户会喜欢与他们以前喜欢的物品类似的物品。</li><li>纯粹的协同过滤：这种算法主要基于用户-物品交互数据（例如用户的评分、购买历史或点击行为）。它不考虑物品的属性或用户的特征，而是通过分析用户之间的行为相似性或物品之间的关联性来进行推荐。它假设用户会与具有相似行为模式的其他用户或与其他用户有共同喜好的物品产生相似的兴趣。</li></ul></li><li><p>数据要求：</p><ul><li>基于内容的协同过滤：需要有关物品的详细描述和属性数据，以及用户的个人特征或历史行为数据。这意味着它在某些情况下可以处理冷启动问题（新物品或新用户），因为它可以使用物品的属性信息来进行推荐。</li><li>纯粹的协同过滤：不需要有关物品的详细描述或属性数据，只需有足够的用户-物品交互数据，如评分或行为历史。它对于新物品和新用户的处理相对困难，因为它无法直接使用物品的属性信息。</li></ul></li><li><p>推荐解释性：</p><ul><li>基于内容的协同过滤：由于它考虑了物品的属性，因此可以提供更具解释性的推荐结果。用户可以理解为什么某个物品被推荐，因为它与他们以前喜欢的物品具有相似的属性。</li><li>纯粹的协同过滤：通常难以提供解释性强的推荐，因为它主要基于用户-物品的交互模式，不直接考虑物品的属性。用户可能不清楚为什么某个物品被推荐给他们。</li></ul></li><li><p>推荐多样性：</p><ul><li>基于内容的协同过滤：倾向于提供与用户过去行为相似的物品，因此可能缺乏多样性，如果用户的历史行为偏向某一类物品。</li><li>纯粹的协同过滤：可以提供更多的推荐多样性，因为它基于用户-物品交互数据来推荐，不受物品属性的限制，可以涵盖更广泛的物品领域。</li></ul></li></ol><p>总的来说，基于内容的协同过滤算法和纯粹的协同过滤算法在推荐的原理、数据需求、解释性和多样性等方面有明显的不同。在实际应用中，选择哪种算法取决于可用数据、推荐场景和用户需求。通常，混合使用这两种方法可以充分发挥它们的优势，提供更准确和多样化的推荐结果。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241028046.webp" alt="image-20230924102812803"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241052190.webp" alt="image-20230924105248817"></p><h3 id="基于内容过滤的深度学习算法"><a href="#基于内容过滤的深度学习算法" class="headerlink" title="基于内容过滤的深度学习算法"></a>基于内容过滤的深度学习算法</h3><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241107196.webp" alt="image-20230924110713864"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241110724.webp" alt="image-20230924111025432"></p><ul><li>找相似特征：</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241116235.webp" alt="image-20230924111636006"></p><ul><li>局限性：如果有大量可能想要推荐的不同电影的大目录，运行的计算成本非常高。</li></ul><h3 id="从大目录中推荐"><a href="#从大目录中推荐" class="headerlink" title="从大目录中推荐"></a>从大目录中推荐</h3><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241123569.webp" alt="image-20230924112355326"></p><ul><li>检索和排名：在检索过程中生成大量可能的项目或者候选列表，涵盖可能向用户推荐的东西。</li></ul><p> <img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241128302.webp" alt="image-20230924112838997"></p><ul><li>使用学习模型对检索出的内容进行排名。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241136908.webp" alt="image-20230924113620580"></p><h3 id="基于内容过滤的TensorFlow实现"><a href="#基于内容过滤的TensorFlow实现" class="headerlink" title="基于内容过滤的TensorFlow实现"></a>基于内容过滤的TensorFlow实现</h3><ul><li>对神经网络输出向量长度进行归一化，算法会工作的更好。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309241152401.webp" alt="image-20230924115251078"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>聚类、异常检测</title>
      <link href="/posts/29154/"/>
      <url>/posts/29154/</url>
      
        <content type="html"><![CDATA[<h1 id="聚类、异常检测"><a href="#聚类、异常检测" class="headerlink" title="聚类、异常检测"></a><p align="center">聚类、异常检测</p></h1><h2 id="1、聚类（Clustering）"><a href="#1、聚类（Clustering）" class="headerlink" title="1、聚类（Clustering）"></a>1、聚类（Clustering）</h2><h3 id="k-means"><a href="#k-means" class="headerlink" title="k-means"></a>k-means</h3><p>K均值（K-means）是一种常见的聚类算法，用于机器学习和数据分析，根据数据点的相似性将它们分成不同的组或簇。K均值的主要目标是将数据点分配到K个簇中，以使簇内的方差最小化。</p><p>​K均值算法的工作原理如下：</p><ol><li><strong>初始化</strong>：选择K个初始簇中心点（簇质心），这些可以是随机选择的数据点，或者使用其他方法如k-means++确定。</li><li><strong>分配</strong>：将每个数据点分配给最近的簇中心，创建K个簇。</li><li><strong>更新中心点</strong>：通过计算分配给该簇的所有数据点的<strong>平均值</strong>，重新计算每个簇的中心点。</li><li><strong>重复</strong>：重复步骤2和3，直到达到收敛，也就是说<strong>中心点不再显著变化</strong>，或者达到预定的迭代次数。</li><li><strong>最终聚类</strong>：算法终止后，得到K个簇，每个数据点属于其中之一  。</li></ol><p>K的选择，即簇的数量，是K均值中的关键参数，可以显著影响结果。可以使用各种方法，如肘部法和轮廓分数，来确定K的合适值。</p><p>K均值是高效的，当簇大致呈球形且大小相近时效果良好。但是，它有一些局限性，比如对初始中心点位置敏感，不适用于具有非凸形状或不均匀密度的簇。为了解决一些这些限制，不同情况下会使用其他聚类算法，如层次聚类和DBSCAN。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309202006691.webp" alt="image-20230920200617406"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">find_closest_centroids</span>(<span class="params">X, centroids</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set K</span></span><br><span class="line">    K = centroids.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># You need to return the following variables correctly</span></span><br><span class="line">    idx = np.zeros(X.shape[<span class="number">0</span>], dtype=<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(X.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="comment"># Array to hold distance between X[i] and each centroids[j]</span></span><br><span class="line">        distance = [] </span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(centroids.shape[<span class="number">0</span>]):</span><br><span class="line">            norm_ij = np.linalg.norm(X[i] - centroids[j]) 、</span><br><span class="line">            <span class="comment"># norm 范数，liner线性+algebra代数</span></span><br><span class="line">            <span class="comment"># Your code to calculate the norm between (X[i] - centroids[j])</span></span><br><span class="line">            distance.append(norm_ij) <span class="comment"># append 函数用于向列表的末尾添加一个元素</span></span><br><span class="line">            </span><br><span class="line">        idx[i] = np.argmin(distance)</span><br><span class="line">        <span class="comment">#aigmin给出最小值下标</span></span><br><span class="line">        <span class="comment"># Your code here to calculate index of minimum value in distance</span></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    <span class="keyword">return</span> idx</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309212023475.webp" alt="image-20230921202352790"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_centroids</span>(<span class="params">X, idx, K</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Returns the new centroids by computing the means of the </span></span><br><span class="line"><span class="string">    data points assigned to each centroid.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        X (ndarray):   (m, n) Data points</span></span><br><span class="line"><span class="string">        idx (ndarray): (m,) Array containing index of closest centroid for each </span></span><br><span class="line"><span class="string">                       example in X. Concretely, idx[i] contains the index of </span></span><br><span class="line"><span class="string">                       the centroid closest to example i</span></span><br><span class="line"><span class="string">        K (int):       number of centroids</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        centroids (ndarray): (K, n) New centroids computed</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Useful variables</span></span><br><span class="line">    m, n = X.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># You need to return the following variables correctly</span></span><br><span class="line">    centroids = np.zeros((K, n))</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ###</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(K):   </span><br><span class="line">            </span><br><span class="line">            points = X[idx == k]</span><br><span class="line">            <span class="comment"># Your code here to get a list of all data points in X assigned to centroid k  </span></span><br><span class="line">            centroids[k] = np.mean(points, axis = <span class="number">0</span>) <span class="comment"># Your code here to compute the mean of the points assigned</span></span><br><span class="line">            </span><br><span class="line">    <span class="comment">### END CODE HERE ## </span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> centroids</span><br></pre></td></tr></table></figure><h3 id="优化目标"><a href="#优化目标" class="headerlink" title="优化目标"></a>优化目标</h3><p>K均值（K-means）的代价函数通常被称为簇内平方和（Inertia）或误差平方和（SSE，Sum of Squared Errors）。这个代价函数的目标是度量簇内数据点与其所属簇中心之间的距离的总和，从而评估聚类的质量。K均值算法的目标是最小化这个代价函数。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309202020954.webp" alt="image-20230920202028690"></p><p>在这个代价函数中，1&#x2F;m用于将平方和除以数据点的总数 m，以计算平均簇内平方和。这个归一化的代价函数更容易解释和比较，因为它不受数据集大小的影响，从而使不同规模的数据集的K均值结果可以进行有效比较。</p><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><p>随机以训练示例为质心初始化，计算选择代价最小的聚类即可。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309202043689.webp" alt="image-20230920204313438"></p><h3 id="选择聚类数"><a href="#选择聚类数" class="headerlink" title="选择聚类数"></a>选择聚类数</h3><p>选择聚类数量（K的值）是K均值聚类中的一个重要决策，它会直接影响到聚类结果的质量。以下是一些常见的方法和技巧来选择合适的聚类数量：</p><ol><li><strong>肘部法（Elbow Method）</strong>：肘部法是一种直观的方法，它涉及尝试不同的K值，然后绘制K值与代价函数的关系图。通常，代价函数（簇内平方和）会随着K的增加而减小，但在某个点后下降速度会减慢，形成一个肘部状的曲线。选择肘部处对应的K值作为最佳聚类数量。</li><li><strong>轮廓分数（Silhouette Score）</strong>：轮廓分数是一种量化聚类效果的方法，它考虑了簇内数据点的紧密度和簇间数据点的分离度。通过计算不同K值下的轮廓分数，可以选择使轮廓分数最大化的K值作为最佳聚类数量。</li><li><strong>Gap统计量（Gap Statistics）</strong>：Gap统计量是一种比较实际数据集的代价函数与随机数据集的代价函数之间的差异来选择K值的方法。通过比较观察到的数据集代价函数与一组生成的随机数据集代价函数的差异，可以找到最佳的K值。</li><li><strong>专业领域知识</strong>：在某些情况下，您可能具有关于数据的领域知识，可以帮助您估计合适的聚类数量。例如，如果您了解数据的特性，并且知道数据应该被分成多少个明显的群组，那么您可以选择相应的K值。</li><li><strong>可视化</strong>：对数据进行可视化分析也可以帮助您选择聚类数量。通过绘制数据点的散点图、簇中心的位置和簇的分布情况，您可以直观地观察到数据的聚类结构，并估计适当的K值。</li><li><strong>交叉验证</strong>：在某些情况下，您可以使用交叉验证来选择聚类数量。将数据集分成训练集和测试集，然后在训练集上使用不同的K值进行聚类，然后在测试集上评估聚类性能，选择性能最佳的K值。</li></ol><p>最终，选择聚类数量通常是一个权衡过程，需要考虑数据的特性以及您的分析目标。不同的方法可能会产生不同的结果，因此通常建议尝试多种方法来选择最佳的K值。</p><h2 id="2、异常检测"><a href="#2、异常检测" class="headerlink" title="2、异常检测"></a>2、异常检测</h2><p>异常检测是一种数据分析和机器学习技术，用于识别数据集中的异常或异常行为。<strong>异常通常指的是与大多数数据点不同或不符合正常模式的数据点或事件</strong>。异常检测在许多领域中都有广泛的应用，包括金融欺诈检测、网络安全、制造业质量控制、医疗诊断等。以下是一些常见的异常检测方法和技术：</p><ol><li><strong>统计方法</strong>：统计方法是最简单的异常检测方法之一，它们基于数据的统计特性来识别异常。例如，通过计算数据点的均值和标准差，可以使用Z分数方法来检测异常值。</li><li><strong>机器学习方法</strong>：机器学习方法包括使用监督学习、无监督学习或半监督学习来构建模型来识别异常。常见的算法包括支持向量机 (SVM)、随机森林、神经网络和聚类方法（如K均值聚类）。</li><li><strong>基于距离的方法</strong>：这些方法使用数据点之间的距离来度量异常程度。例如，K近邻算法（K-Nearest Neighbors）可以通过计算数据点与其最近邻居之间的距离来识别异常。</li><li><strong>基于密度的方法</strong>：这些方法尝试识别数据中的低密度区域作为异常。LOF（局部离群因子）和DBSCAN（基于密度的空间聚类应用噪声）是一些常见的基于密度的异常检测方法。</li><li><strong>时间序列异常检测</strong>：用于时间序列数据的特定方法，如季节性分解、指数平滑和ARIMA模型，可用于检测时间序列数据中的异常。</li><li><strong>深度学习方法</strong>：深度学习方法，尤其是循环神经网络（RNN）和长短时记忆网络（LSTM），在时间序列数据和文本数据中的异常检测方面表现出色。</li><li><strong>无监督异常检测</strong>：无监督方法不需要标记的异常数据，而是试图从数据中学习正常模式，并识别与之不符的模式。</li><li><strong>集成方法</strong>：这些方法将多个异常检测模型组合起来，以提高检测性能。例如，Isolation Forest和One-Class SVM是集成方法的示例。</li><li><strong>领域知识</strong>：在某些情况下，领域知识和专业知识对于异常检测非常重要。专家可以定义哪些情况下应该报告异常，并帮助改进模型。</li></ol><h3 id="高斯正太分布"><a href="#高斯正太分布" class="headerlink" title="高斯正太分布"></a>高斯正太分布</h3><p>高斯分布，也称为正态分布，是统计学中非常重要的概率分布之一，通常用于建模自然界和人类行为中的许多现象。高斯分布的概率密度函数（Probability Density Function，PDF）如下：</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309221443295.webp" alt="image-20230922144310142"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309221448406.webp" alt="image-20230922144849103"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309221456419.webp" alt="image-20230922145613176"></p><h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><p>使用高斯正态分布（也称为高斯分布）对特征建模是一种常用的方法来检测异常。这个方法通常被称为基于概率的异常检测，它假设正常数据点符合高斯分布，而异常点则位于分布的尾部。以下是使用高斯分布进行异常检测的一般步骤：</p><ol><li><strong>数据准备</strong>：<ul><li>收集和准备要用于异常检测的数据。</li><li>确保数据的特征（属性）是数值型的。</li></ul></li><li><strong>特征工程</strong>：<ul><li>对数据进行必要的特征工程，包括缺失值处理、数据标准化等，以确保数据满足高斯分布的假设。</li></ul></li><li><strong>建立高斯模型</strong>：<ul><li>对每个特征（属性）独立地建立高斯分布模型。对于每个特征，估计其均值（$\mu$）和方差（$\sigma^2$）。</li><li>这可以通过计算每个特征的样本均值和样本方差来完成。</li></ul></li><li><strong>计算概率密度</strong>：<ul><li>对于给定的数据点，计算每个特征的概率密度值，使用高斯分布的概率密度函数。</li><li>对于多维数据，将每个特征的概率密度值相乘得到整体概率密度。</li></ul></li><li><strong>确定异常阈值</strong>：<ul><li>选择一个适当的异常阈值，通常是一个小概率值（例如，0.01% 或 0.1%）。</li><li>如果数据点的整体概率密度低于此阈值，则将其标记为异常点。</li></ul></li><li><strong>进行异常检测</strong>：<ul><li>对于新的数据点，将其输入到已建立的高斯分布模型中，计算其概率密度。</li><li>如果概率密度低于异常阈值，则将该数据点标记为异常。</li></ul></li><li><strong>可视化和解释</strong>：<ul><li>可视化结果以便于理解和解释。可以使用直方图、概率密度图、散点图等方法来展示异常点。</li></ul></li><li><strong>模型评估</strong>：<ul><li>对异常检测模型进行评估，通常使用准确率、召回率、F1分数等指标。</li><li>还可以使用交叉验证来评估模型性能。</li></ul></li></ol><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309221522643.webp" alt="image-20230922152247373"></p><p> <img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309221530235.webp" alt="image-20230922153026007"></p><p> complete the <code>select_threshold</code> function below to find the best threshold to use for selecting outliers based on the results from a validation set (<code>p_val</code>) and the ground truth (<code>y_val</code>).</p><p><code>np.sum</code> 是NumPy库中的一个函数，用于计算数组或矩阵中元素的和。它的用法非常简单，可以对数组中的所有元素或者指定的轴进行求和操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对整个数组或矩阵的元素求和</span></span><br><span class="line">result = np.<span class="built_in">sum</span>(array)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 沿指定轴(axis)对数组或矩阵的元素进行求和</span></span><br><span class="line">result = np.<span class="built_in">sum</span>(array, axis=<span class="number">0</span>)  <span class="comment"># 对列求和</span></span><br><span class="line">result = np.<span class="built_in">sum</span>(array, axis=<span class="number">1</span>)  <span class="comment"># 对行求和</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><ul><li><code>array</code> 可以是一个NumPy数组或矩阵。</li><li><code>axis</code> 是一个可选参数，表示要沿着哪个轴进行求和操作。如果不指定 <code>axis</code> 参数，将对整个数组中的元素进行求和。</li></ul></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个示例数组</span></span><br><span class="line">arr = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">                [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对整个数组的元素求和</span></span><br><span class="line">total_sum = np.<span class="built_in">sum</span>(arr)</span><br><span class="line"><span class="built_in">print</span>(total_sum)  <span class="comment"># 输出：21</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 沿列(axis=0)求和</span></span><br><span class="line">column_sum = np.<span class="built_in">sum</span>(arr, axis=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(column_sum)  <span class="comment"># 输出：[5 7 9]</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 沿行(axis=1)求和</span></span><br><span class="line">row_sum = np.<span class="built_in">sum</span>(arr, axis=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(row_sum)  <span class="comment"># 输出：[ 6 15]</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: estimate_gaussian</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">estimate_gaussian</span>(<span class="params">X</span>): </span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Calculates mean and variance of all features </span></span><br><span class="line"><span class="string">    in the dataset</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        X (ndarray): (m, n) Data matrix</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        mu (ndarray): (n,) Mean of all features</span></span><br><span class="line"><span class="string">        var (ndarray): (n,) Variance of all features</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    m, n = X.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### </span></span><br><span class="line">    mu = <span class="number">1</span> / m * np.<span class="built_in">sum</span>(X, axis = <span class="number">0</span>)</span><br><span class="line">    var = <span class="number">1</span> / m * np.<span class="built_in">sum</span>((X - mu) ** <span class="number">2</span>, axis = <span class="number">0</span>)</span><br><span class="line">    <span class="comment">### END CODE HERE ### </span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> mu, var</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: select_threshold</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">select_threshold</span>(<span class="params">y_val, p_val</span>): </span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Finds the best threshold to use for selecting outliers </span></span><br><span class="line"><span class="string">    based on the results from a validation set (p_val) </span></span><br><span class="line"><span class="string">    and the ground truth (y_val)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        y_val (ndarray): Ground truth on validation set</span></span><br><span class="line"><span class="string">        p_val (ndarray): Results on validation set</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        epsilon (float): Threshold chosen </span></span><br><span class="line"><span class="string">        F1 (float):      F1 score by choosing epsilon as threshold</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span> </span><br><span class="line"></span><br><span class="line">    best_epsilon = <span class="number">0</span></span><br><span class="line">    best_F1 = <span class="number">0</span></span><br><span class="line">    F1 = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    step_size = (<span class="built_in">max</span>(p_val) - <span class="built_in">min</span>(p_val)) / <span class="number">1000</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> epsilon <span class="keyword">in</span> np.arange(<span class="built_in">min</span>(p_val), <span class="built_in">max</span>(p_val), step_size):</span><br><span class="line">    </span><br><span class="line">        <span class="comment">### START CODE HERE ### </span></span><br><span class="line">        </span><br><span class="line">        predictions = (p_val &lt; epsilon)</span><br><span class="line">    </span><br><span class="line">        </span><br><span class="line">        tp = np.<span class="built_in">sum</span>((predictions == <span class="number">1</span>) &amp; (y_val == <span class="number">1</span>))</span><br><span class="line">        fp = np.<span class="built_in">sum</span>((predictions == <span class="number">1</span>) &amp; (y_val == <span class="number">0</span>))</span><br><span class="line">        </span><br><span class="line">        fn = np.<span class="built_in">sum</span>((predictions == <span class="number">0</span>) &amp; (y_val == <span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        prec = tp / (tp + fp)</span><br><span class="line">        rec = tp / (tp + fn)</span><br><span class="line">        </span><br><span class="line">        F1 = <span class="number">2</span> * prec * rec / (prec + rec)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">### END CODE HERE ### </span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> F1 &gt; best_F1:</span><br><span class="line">            best_F1 = F1</span><br><span class="line">            best_epsilon = epsilon</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> best_epsilon, best_F1</span><br></pre></td></tr></table></figure><h3 id="开发与评估"><a href="#开发与评估" class="headerlink" title="开发与评估"></a>开发与评估</h3><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309221538992.webp" alt="image-20230922153806772"></p><p>​如果已知少量的异常示例，将它放在交叉验证集里效果是很好的。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309221632262.webp" alt="image-20230922163254088"></p><h3 id="异常检测与监督学习对比"><a href="#异常检测与监督学习对比" class="headerlink" title="异常检测与监督学习对比"></a>异常检测与监督学习对比</h3><p>异常检测（无监督学习）和监督学习是两种不同的机器学习方法，用于解决不同类型的问题。以下是异常检测与监督学习的主要对比：</p><ol><li><strong>目标</strong>：<ul><li>异常检测：目标是识别数据中的异常或不寻常的模式，通常假设正常样本比异常样本多得多。</li><li>监督学习：目标是通过已知标签的训练数据来学习一个模型，以便对新数据进行分类或回归预测。</li></ul></li><li><strong>标签</strong>：<ul><li>异常检测：通常不需要标签，因为异常点通常很难获取或成本较高。</li><li>监督学习：需要已知的标签来训练模型，这些标签指示了每个训练样本的正确类别或值。</li></ul></li><li><strong>数据分布</strong>：<ul><li>异常检测：通常假设正常数据和异常数据具有不同的数据分布，异常点位于分布的尾部或稀疏区域。</li><li>监督学习：通常假设训练数据和测试数据的分布相似，模型根据已知的标签进行分类或回归。</li></ul></li><li><strong>模型训练</strong>：<ul><li>异常检测：通常使用无监督方法，如基于距离、密度或概率的算法。</li><li>监督学习：使用带有标签的训练数据来训练监督学习模型，如决策树、神经网络、支持向量机等。</li></ul></li><li><strong>评估</strong>：<ul><li>异常检测：通常使用异常检测指标，如精确度、召回率、F1分数等来评估性能。</li><li>监督学习：通常使用分类或回归的评估指标，如准确率、均方误差、ROC曲线等。</li></ul></li><li><strong>数据量</strong>：<ul><li>异常检测：通常适用于少量的异常数据点。</li><li>监督学习：通常需要大量的标记数据来训练监督学习模型。</li></ul></li><li><strong>应用领域</strong>：<ul><li>异常检测：适用于金融欺诈检测、网络安全、工业质量控制、医疗诊断等需要检测罕见事件的领域。</li><li>监督学习：广泛应用于分类、回归和预测任务，如图像分类、文本分类、自然语言处理等。</li></ul></li><li><strong>可解释性</strong>：<ul><li>异常检测方法通常更容易解释，因为它们通常不依赖于复杂的特征工程或模型。</li><li>监督学习方法可能会涉及更复杂的模型和特征工程，因此可能较难解释。</li></ul></li></ol><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309221658698.webp" alt="image-20230922165806451"></p><h3 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h3><ul><li><p>特征的选择对于构建异常检测系统时非常重要。</p></li><li><p>一种选择是确保特征服从高斯分布。非高斯特征将其进行变换，使其基本符合高斯分布。（炼丹）无论对训练集数据作何种转换，也要记得对交叉验证和测试集作相同的转换。</p></li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309221705244.webp" alt="image-20230922170528968"></p><ul><li>训练模型，查看算法未能检测到的检查验证集中的异常。尝试创建新的功能，允许算法识别。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309221742106.webp" alt="image-20230922174200903"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CNN、RNN</title>
      <link href="/posts/29153/"/>
      <url>/posts/29153/</url>
      
        <content type="html"><![CDATA[<h1 id="MLP"><a href="#MLP" class="headerlink" title="MLP"></a>MLP</h1><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310011646025.webp" alt="image-20231001164554848"></p><p>加入非线性，加入激活函数。下为具有一个隐藏层的MLP:</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310011652456.webp" alt="image-20231001165208320"></p><h2 id="全连接层权重正则化"><a href="#全连接层权重正则化" class="headerlink" title="全连接层权重正则化"></a>全连接层权重正则化</h2><p>全连接层的权重正则化是一种用于减轻过拟合问题和提高神经网络模型的泛化能力的技术。在这种正则化中，对全连接层的权重施加了额外的限制，以限制权重的幅度。有两种主要的权重正则化方法可用于全连接层：</p><ol><li><strong>L2 正则化</strong>：也称为权重衰减。L2 正则化通过在损失函数中添加权重的L2范数的惩罚项来限制权重的大小。这个惩罚项是权重值的平方和的乘积与一个称为正则化强度的超参数的乘积。它的效果是鼓励权重值保持在较小的范围内，以减少过拟合风险。</li><li><strong>L1 正则化</strong>：L1 正则化通过在损失函数中添加权重的L1范数的惩罚项来限制权重的大小。与L2 正则化不同，L1 正则化鼓励权重值变得稀疏，即许多权重趋向于零。这有助于模型自动选择最重要的特征，从而提高泛化能力。</li></ol><p>这些正则化技术通常通过添加正则化项到损失函数中来实现，其中正则化项的强度是一个可调整的超参数，通常需要根据具体的问题进行调优。正则化有助于限制权重的幅度，从而降低模型过度拟合训练数据的风险，使模型更能够泛化到未见过的数据。</p><p>正则化可以应用于神经网络的全连接层以及其他类型的层，如卷积层。这是训练深度学习模型时常用的技术之一，以提高模型的性能和鲁棒性。</p><hr><p>The FC layer weights are also regularized using a maximum norm constraint of 0.5, i.e., ‖w‖2 &lt; 0.5 (weight-normalization).</p><p>这句话指的是对全连接层（Fully Connected Layer）的权重进行了正则化，使用的是最大范数约束为0.5的权重归一化技术。让我为您解释一下这个句子的关键要点：</p><ol><li><strong>FC层权重</strong>：全连接层是神经网络中的一种层，通常包含大量的可学习参数（权重），用于将输入数据连接到输出数据。这些权重是在训练中学习的，它们决定了模型如何从输入数据中提取特征和进行预测。</li><li><strong>最大范数约束为0.5</strong>：这是权重归一化（weight normalization）的一种形式，它对全连接层的权重进行了约束。最大范数约束是指权重矩阵中的每个权重向量的L2范数（欧几里得范数，即向量的长度）不应超过0.5。这意味着每个权重向量的所有权重值的平方和的平方根不应大于0.5。如果有某个权重向量违反了这一约束，它将被缩放到满足这个条件。</li><li><strong>权重归一化</strong>：权重归一化是一种正则化技术，旨在稳定和约束模型的权重。它可以减少过拟合的风险，提高模型的泛化能力。通过将权重的幅度归一化，权重归一化技术有助于防止权重变得过大，从而减少梯度爆炸的问题，并有助于提高模型的稳定性和训练效率。</li></ol><p>综合而言，这句话的含义是，在全连接层中，通过权重归一化技术，确保每个权重向量的L2范数不超过0.5，以便限制权重的大小，防止过拟合，同时提高模型的稳定性和泛化能力。这有助于确保模型在训练过程中的权重不会变得过大，从而减少梯度问题，并提高模型的性能。</p><h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><p>在2014年，斯里瓦斯塔瓦等人 :cite:<code>Srivastava.Hinton.Krizhevsky.ea.2014</code> 就如何将毕晓普的想法应用于网络的内部层提出了一个想法： 在训练过程中，<strong>他们建议在计算后续层之前向网络的每一层注入噪声</strong>。 因为当训练一个有多层的深层网络时，注入噪声只会在输入-输出映射上增强平滑性。</p><p>这个想法被称为<em>暂退法</em>（dropout）。 暂退法在前向传播过程中，计算每一内部层的同时注入噪声，这已经成为训练神经网络的常用技术。 这种方法之所以被称为<em>暂退法</em>，因为我们从表面上看是在训练过程中丢弃（drop out）一些神经元。 在整个训练过程的每一次迭代中，标准暂退法包括在计算下一层之前将当前层中的一些节点置零。</p><p>需要说明的是，暂退法的原始论文提到了一个关于有性繁殖的类比： 神经网络过拟合与每一层都依赖于前一层激活值相关，称这种情况为“共适应性”。 作者认为，暂退法会破坏共适应性，就像有性生殖会破坏共适应的基因一样。</p><p>那么关键的挑战就是如何注入这种噪声。 一种想法是以一种<em>无偏向</em>（unbiased）的方式注入噪声。 这样在固定住其他层时，每一层的期望值等于没有噪音时的值。</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310111447510.webp" alt="image-20231011144705280" style="zoom:67%;" /><p>&#x3D;&#x3D;翻译：比如 p 是 0.2 ，就把 20% 的数据变成 0 ，剩下的数据除以 0.8 保持总期望不变。&#x3D;&#x3D; </p><p>&#x3D;&#x3D;Dropout 只在训练中使用，影响模型参数的更新；在推理过程中，直接返回输入；&#x3D;&#x3D;</p><p>Dropout（丢弃法）是一种用于神经网络的正则化技术，尤其常用于深度学习和机器学习中，以防止过拟合。过拟合发生在模型在训练数据上表现良好但在未见或验证数据上无法有效泛化的情况下。Dropout通过在每次训练迭代中随机关闭（”丢弃”）一部分神经元（单元）来帮助减轻过拟合问题。</p><p>以下是Dropout的工作原理：</p><ol><li>训练时：在每次前向传播和反向传播中，Dropout随机选择一部分神经元，以一定的概率关闭它们，将它们的输出设置为零。通常，这个概率通常选择在0.2到0.5之间，但具体应用可以有所不同。</li><li>Dropout是独立应用于每个神经元的，因此在每次训练迭代中都会随机关闭不同的神经元。</li><li>这个过程本质上为每个训练迭代创建了一个不同的神经网络架构，防止网络过于依赖任何一个特征或连接。</li><li>根据使用随机“稀化”网络进行的预测，计算损失并更新权重。</li></ol><p>在推断或测试时，通常会关闭Dropout，使用所有神经元。这样，模型可以进行不带随机性的预测。</p><p>Dropout的主要好处是它作为一种集成学习形式，降低了过拟合的风险，并鼓励网络学习更稳健和通用的特征。它已广泛应用于各种深度学习架构，并已在许多应用中改善了模型性能。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul><li>暂退法在前向传播过程中，计算每一内部层的同时丢弃一些神经元。</li><li>暂退法可以避免过拟合，它通常与控制权重向量的维数和大小结合使用的。</li><li>暂退法将活性值ℎℎ替换为具有期望值ℎℎ的随机变量。</li><li>暂退法仅在训练期间使用。</li></ul><h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1><p>&#x3D;&#x3D;<strong>先通过卷积激活进行升维（增加通道数，减少图片大小），Flatten 后再通过 MLP 进行降维，最后通过 softmax 输出。</strong>&#x3D;&#x3D;</p><ul><li>平移不变性</li><li>局部性</li><li>多输入多输出通道可以用来扩展卷积层的模型。</li><li>当以每像素为基础应用时，1×1卷积层相当于全连接层。</li><li>1×1卷积层通常用于调整网络层的通道数量和控制模型复杂性。</li></ul><p>以下是 CNN 的关键特点和组成部分：</p><ol><li><strong>卷积层（Convolutional Layers）</strong>：卷积层是 CNN 的核心组件。它通过在输入数据上滑动卷积核（一个小的可学习权重矩阵），将局部感知域内的特征提取出来。这有助于网络捕捉图像中的边缘、纹理和其他低级特征。</li><li><strong>池化层（Pooling Layers）</strong>：池化层用于减小特征图的尺寸，并减少计算复杂性。常见的池化操作包括最大池化（选择局部区域中的最大值）和平均池化（计算局部区域的平均值）。</li><li><strong>激活函数（Activation Functions）</strong>：激活函数引入非线性性质，允许网络学习复杂的特征。常见的激活函数包括 ReLU（修正线性单元）、Sigmoid 和 Tanh。</li><li><strong>全连接层（Fully Connected Layers）</strong>：全连接层用于将卷积层和池化层的输出连接到一个密集连接的神经网络，以进行分类或回归等任务。</li><li><strong>权重共享（Weight Sharing）</strong>：CNN 中的卷积操作是通过权重共享来实现的。这意味着同一个卷积核被应用于图像中的不同位置，从而减少网络参数的数量。</li><li><strong>卷积神经网络的层级结构</strong>：CNN 通常由多个卷积层和池化层交替堆叠在一起。网络的深度和复杂性可以根据任务的复杂性而调整。</li><li><strong>卷积神经网络的训练</strong>：CNN 的训练通常采用反向传播算法，通过最小化损失函数来优化网络参数。常见的损失函数包括均方误差（MSE）和交叉熵（Cross Entropy），具体取决于任务类型。</li></ol><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309261930276.webp" alt="image-20230926193026065" style="zoom:67%;" /><img src="C:\Users\Haodanyang\AppData\Roaming\Typora\typora-user-images\image-20230926195021147.png" alt="image-20230926195021147" style="zoom:67%;" /><hr><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309261939448.webp" alt="image-20230926193928180" style="zoom:67%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309261942875.webp" alt="image-20230926194255613" style="zoom:67%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309261947306.webp" alt="image-20230926194711009" style="zoom:67%;" /> <img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309261952479.webp" alt="image-20230926195241270" style="zoom:67%;" /><h2 id="pooling"><a href="#pooling" class="headerlink" title="pooling"></a>pooling</h2><ul><li><p>将卷积处理后的“图像”变小，分块，在每块选择合适数字代替整个块。（减少计算量，也可以不用pooling）减少对位置的敏感。</p></li><li><p>汇聚：max、mean。</p></li><li><p>减少维度、增加鲁棒性。</p></li><li><p>对于给定输入元素，最大汇聚层会输出该窗口内的最大值，平均汇聚层会输出该窗口内的平均值。</p></li><li><p>汇聚层的主要优点之一是减轻卷积层对位置的过度敏感。</p></li><li><p>可以指定汇聚层的填充和步幅。</p></li><li><p>使用最大汇聚层以及大于1的步幅，可减少空间维度（如高度和宽度）。</p></li><li><p>汇聚层的输出通道数与输入通道数相同。</p></li><li><p>默认情况下，(<strong>深度学习框架中的步幅与汇聚窗口的大小相同</strong>)</p></li></ul><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309261957542.webp" alt="image-20230926195746227" style="zoom: 67%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309261959531.webp" alt="image-20230926195939285" style="zoom:80%;" /><p>教科书级pooling代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">pool2d</span>(<span class="params">X, pool_size, mode=<span class="string">&#x27;max&#x27;</span></span>):</span><br><span class="line">    p_h, p_w = pool_size</span><br><span class="line">    Y = torch.zeros((X.shape[<span class="number">0</span>] - p_h + <span class="number">1</span>, X.shape[<span class="number">1</span>] - p_w + <span class="number">1</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">0</span>]):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(Y.shape[<span class="number">1</span>]):</span><br><span class="line">            <span class="keyword">if</span> mode == <span class="string">&#x27;max&#x27;</span>:</span><br><span class="line">                Y[i, j] = X[i: i + p_h, j: j + p_w].<span class="built_in">max</span>()</span><br><span class="line">            <span class="keyword">elif</span> mode == <span class="string">&#x27;avg&#x27;</span>:</span><br><span class="line">                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()</span><br><span class="line">    <span class="keyword">return</span> Y</span><br></pre></td></tr></table></figure><h2 id="Flatten"><a href="#Flatten" class="headerlink" title="Flatten"></a>Flatten</h2><p>“Flatten” 是深度学习中常用的操作，通常用于将多维张量（如二维、三维或更高维的张量）转换为一维向量。这个操作在神经网络的前馈过程中经常用到，特别是当从卷积层或池化层的输出转换为全连接层的输入时。</p><p>在深度学习中，神经网络的不同层之间通常使用特定形状的张量传递数据。例如，卷积层和池化层的输出是三维张量（通常是高度、宽度和通道维度），而全连接层的输入通常是一维向量。为了将卷积层或池化层的输出与全连接层相连接，需要将输出张量 “Flatten” 为一维向量。</p><p>Flatten 操作的工作原理很简单，它将输入张量的所有元素按顺序排列成一个长向量，不改变元素的值，只改变它们的排列。这使得神经网络可以处理不同尺寸的输入，因为 Flatten 操作会将输入重新排列为固定长度的向量，以供后续的全连接层使用。</p><p>以下是一个示例，说明如何使用 Flatten 操作：</p><p>假设卷积层或池化层的输出张量的形状是 (batch_size, height, width, channels)，其中 <code>batch_size</code> 表示批量大小，<code>height</code> 和 <code>width</code> 表示图像的高度和宽度，<code>channels</code> 表示通道数。</p><p>使用 Flatten 操作后，输出张量的形状将变为 (batch_size, height * width * channels)。这个一维向量可以直接连接到全连接层，用于进行分类或其他任务。</p><p>Flatten 操作是神经网络中的一个常见操作，用于在不同层之间转换数据的形状，以适应网络的需求。这有助于神经网络处理各种输入数据，并在不同任务中实现高效的前馈传递。</p><hr><h2 id="卷积神经网络（CNN）通常在处理图片放大和缩小的问题上表现不佳，"><a href="#卷积神经网络（CNN）通常在处理图片放大和缩小的问题上表现不佳，" class="headerlink" title="卷积神经网络（CNN）通常在处理图片放大和缩小的问题上表现不佳，"></a>卷积神经网络（CNN）通常在处理图片放大和缩小的问题上表现不佳，</h2><p>主要原因如下：</p><ol><li><strong>固定大小的卷积核</strong>：CNN 使用卷积核来捕捉图像中的局部特征，这些卷积核的大小通常是固定的，因此无法有效地处理图像的缩小和放大。当图像被缩小时，卷积核可能会跨越多个特征，导致信息丢失。当图像被放大时，卷积核可能会导致信息的冗余。</li><li><strong>池化层的尺寸问题</strong>：池化层通常用于减小特征图的尺寸，但它们的操作是固定的。当图像被缩小时，池化层可能会导致信息的进一步丢失。当图像被放大时，池化层的操作无法适应新的图像尺寸。</li><li><strong>空间信息的丢失</strong>：CNN 在卷积和池化过程中可能会丢失图像的空间信息，这对于图像放大和缩小任务来说是关键的。放大图像需要保留更多的细节，而缩小图像需要保持清晰度。</li></ol><p>为了解决这些问题，研究人员已经提出了一些方法，如超分辨率技术和图像生成模型（如生成对抗网络，GANs）。这些方法旨在通过生成高分辨率图像或重建缩小的图像来应对放大和缩小的问题。一些特殊的神经网络架构也被设计用于处理不同尺寸的图像，如金字塔网络。</p><p>总之，虽然CNN在很多计算机视觉任务中表现出色，但它们对于图像放大和缩小问题可能需要额外的技术和架构来处理。放大和缩小问题通常需要考虑到更多的空间信息和细节，因此需要不同的方法来应对。</p><h2 id="卷积核的权重施加"><a href="#卷积核的权重施加" class="headerlink" title="卷积核的权重施加"></a>卷积核的权重施加</h2><p>对于卷积核的权重施加”最大范数约束为2”是一种在深度学习中用于防止过拟合的权重正则化方法。这个约束限制了卷积核权重的L2范数（欧几里得范数）不超过2。</p><p>具体解释如下：</p><ol><li><p><strong>卷积核</strong>：在卷积神经网络（CNN）中，卷积核用于从输入数据中提取特征。这些卷积核具有与之相关的权重，在训练期间会被学习优化。</p></li><li><p><strong>L2范数</strong>：一个向量的L2范数（在这种情况下是卷积核的权重向量）是该向量的长度或幅度的度量。对于具有组件（w1，w2，w3，…，wn）的向量，L2范数的计算方法是这些组件的平方和的平方根：</p><p>L2范数 &#x3D; sqrt(w1^2 + w2^2 + w3^2 + … + wn^2)</p></li><li><p><strong>最大范数约束</strong>：在这种情况下，权重的最大范数约束为2意味着卷积核的权重向量的L2范数不应超过2。换句话说，权重向量中权重的平方和的平方根应小于或等于2。</p></li></ol><p>这一约束的目的是限制训练过程中权重的增长。在训练深度神经网络时，尤其是当参数数量很大时，容易出现过拟合。过拟合发生在模型对训练数据过于专业化，而在新的、未见过的数据上表现不佳。正则化技巧，如权重约束，可以帮助减轻过拟合。</p><p>通过对权重施加最大范数约束，可以鼓励模型具有更稳定和广义的表示。这个约束有效地防止任何单个权重变得过于庞大，从而降低过拟合的风险。它还鼓励权重共享，有助于模型的泛化。</p><p>这种正则化方法可以在训练过程中实施，以确保卷积核的权重不违反指定的最大范数约束（在这种情况下是2）。这是提高深度学习模型泛化能力的工具之一。</p><h2 id="Lenet"><a href="#Lenet" class="headerlink" title="Lenet"></a>Lenet</h2><ul><li>卷积神经网络（CNN）是一类使用卷积层的网络。</li><li>在卷积神经网络中，我们组合使用卷积层、非线性激活函数和汇聚层。</li><li>为了构造高性能的卷积神经网络，我们通常对卷积层进行排列，逐渐降低其表示的空间分辨率，同时增加通道数。</li><li>在传统的卷积神经网络中，卷积块编码得到的表征在输出之前需由一个或多个全连接层进行处理。</li><li>LeNet是最早发布的卷积神经网络之一。</li></ul><h2 id="Alexnet"><a href="#Alexnet" class="headerlink" title="Alexnet"></a>Alexnet</h2><ul><li>AlexNet的架构与LeNet相似，但使用了更多的卷积层和更多的参数来拟合大规模的ImageNet数据集。10 * 参数， 260 * 计算复杂度。</li><li>AlexNet已经被更有效的架构所超越，但它是从浅层网络到深层网络的关键一步。</li><li>激活函数从 sigmoid 变为 Relu (减缓梯度消失)</li><li>隐藏层后加入了丢弃层。</li><li>数据增强</li><li>MaxPooling</li><li>尽管AlexNet的代码只比LeNet多出几行，但学术界花了很多年才接受深度学习这一概念，并应用其出色的实验结果。这也是由于缺乏有效的计算工具。</li><li>Dropout、ReLU和预处理是提升计算机视觉任务性能的其他关键步骤。</li></ul><h2 id="NIN"><a href="#NIN" class="headerlink" title="NIN"></a>NIN</h2><p><em>网络中的网络</em>（<em>NiN</em>）提供了一个非常简单的解决方案：在每个像素的通道上分别使用多层感知机.</p><ul><li>NiN 使用由一个卷积层和多个1×1卷积层组成的块。该块可以在卷积神经网络中使用，以允许更多的每像素非线性。</li><li>NiN 去除了容易造成过拟合的全连接层，将它们替换为全局平均汇聚层（即在所有位置上进行求和）。该汇聚层通道数量为所需的输出数量（例如，Fashion-MNIST的输出为10）。</li><li>移除全连接层可减少过拟合，同时显著减少 NiN 的参数。</li><li>NiN的设计影响了许多后续卷积神经网络的设计。</li></ul><h2 id="GoogLenet"><a href="#GoogLenet" class="headerlink" title="GoogLenet"></a>GoogLenet</h2><ul><li>Inception 块相当于一个有4条路径的子网络。它通过不同窗口形状的卷积层和最大汇聚层来并行抽取信息，并使用1×1卷积层减少每像素级别上的通道维数从而降低模型复杂度。</li><li>GoogLeNet 将多个设计精细的 Inception 块与其他层（卷积层、全连接层）串联起来。其中 Inception 块的通道数分配之比是在ImageNet 数据集上通过大量的实验得来的。</li><li>GoogLeNet 和它的后继者们一度是 ImageNet 上最有效的模型之一：它以较低的计算复杂度提供了类似的测试精度。</li></ul><h2 id="Resnet"><a href="#Resnet" class="headerlink" title="Resnet"></a>Resnet</h2><p>卷积操作可以改变特征图（feature map）的维度，主要是因为卷积核（卷积滤波器）的大小和数量以及步幅（stride）的选择会影响到输出特征图的尺寸。下面是卷积操作如何改变维度的一些关键因素：</p><ol><li><p><strong>卷积核的大小</strong>：卷积核的大小决定了它在输入特征图上滑动的区域大小。例如，一个3x3的卷积核将在输入特征图上以3x3的窗口滑动，而一个5x5的卷积核将以5x5的窗口滑动。不同大小的卷积核会导致输出特征图的尺寸不同。</p></li><li><p><strong>卷积核的数量</strong>：卷积层可以有多个卷积核，每个卷积核都会生成一个输出特征图。这意味着卷积层的输出深度（通道数）取决于卷积核的数量。更多的卷积核会生成更多的输出通道。</p></li><li><p><strong>步幅（stride）</strong>：步幅定义了卷积核在输入特征图上的移动间隔。较大的步幅会导致输出特征图的尺寸缩小，而较小的步幅会导致输出特征图的尺寸增大。</p></li></ol><p>综合考虑这些因素，卷积操作在滑动卷积核的过程中，会对输入特征图的不同部分进行局部计算，并生成相应的输出值，这些输出值构成了输出特征图。因此，卷积操作的组合和参数设置可以灵活地调整输出特征图的维度（尺寸和通道数），从而允许神经网络适应不同大小和复杂度的数据以及任务需求。</p><p>总之，卷积操作的灵活性和可调整性使得它可以改变特征图的维度，以便网络可以有效地提取和表示输入数据的各种特征。这是卷积神经网络在计算机视觉和其他领域中非常成功的原因之一。</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310131814125.webp" alt="image-20231013181407494" style="zoom: 50%;" /><hr><ol><li>输入：假设输入残差块的特征图为 x。</li><li>主要路径（Main Path）：主要路径包括两个卷积层，通常是3x3的卷积核。这些卷积层对输入 x 进行非线性变换和特征提取，然后生成主要路径的输出，记为 F(x)。</li><li>快捷连接（Shortcut Connection）：快捷连接是一个直接连接，它将输入 x 直接传递到残差块的输出。</li><li>输出计算：残差块的输出是主要路径的输出（F(x)）与快捷连接的输入（x）之和。即，残差块的输出等于 F(x) + x。</li></ol><p>这个输出计算的过程实际上是将输入和主要路径的输出相加，这就是为什么它被称为”残差”块。这种方式允许主要路径学习如何微调输入 x，以获得更好的表示。如果主要路径能够学到一个恒等映射，即 F(x) &#x3D; x，那么输出就等于输入 x，表示没有进行任何变换。</p><p>总之，残差块的输出是输入 x 和主要路径的输出 F(x) 的和，这个和表示了残差块的最终输出，被传递到网络的下一层进行进一步的处理。这种设计有助于克服深度神经网络中的梯度消失问题，使网络更容易训练并学习复杂的特征表示。</p><ul><li><strong>保护内函数的梯度，保护浅层信息。</strong></li><li><strong>训练比较快，解决了梯度消失问题。（梯度一般是0-1之间的高斯分布，越往后越小）</strong></li><li><strong>SGD的精髓是能一直跑的动。用SGD优化人生。</strong></li></ul><h2 id="DenseNet"><a href="#DenseNet" class="headerlink" title="DenseNet"></a>DenseNet</h2><p>ResNet 和 DenseNet 的关键区别在于，DenseNet 输出是连接而不是如 ResNet 的简单相加。</p><p>稠密层：一个<em>稠密块</em>由多个卷积块组成，每个卷积块使用相同数量的输出通道。 然而，在前向传播中，我们将每个卷积块的输入和输出在通道维上连结。</p><p>过渡层：由于每个稠密块都会带来通道数的增加，使用过多则会过于复杂化模型。 而过渡层可以用来控制模型复杂度。 它通过1×11×1卷积层来减小通道数，并使用步幅为2的平均汇聚层减半高和宽，从而进一步降低模型复杂度。</p><h2 id="Mixed-Depthwise-Convolution（混合深度卷积）"><a href="#Mixed-Depthwise-Convolution（混合深度卷积）" class="headerlink" title="Mixed Depthwise Convolution（混合深度卷积）"></a>Mixed Depthwise Convolution（混合深度卷积）</h2><p>混合深度卷积（Mixed Depthwise Convolution）是一种深度学习和卷积神经网络（CNN）中的卷积层，结合了深度可分离卷积和标准卷积的原理。它是一种专门设计用于提高模型效率同时保持或增强模型性能的层。</p><p>以下是混合深度卷积的关键组成部分：</p><ol><li><strong>深度可分离卷积</strong>：<ul><li>深度可分离卷积是一种将标准卷积分为两个独立操作的技术：深度卷积和逐点卷积。</li><li>深度卷积将单独的卷积操作应用于输入特征图的每个通道。</li><li>逐点卷积然后使用1x1卷积来组合深度卷积的结果，生成最终的输出特征图。</li></ul></li><li><strong>标准卷积</strong>：<ul><li>标准卷积是传统的卷积操作，其中一个卷积核（滤波器）与整个输入特征图进行卷积操作。</li><li>它在整个输入深度上操作，并生成全深度输出。</li></ul></li><li><strong>混合深度卷积</strong>：<ul><li>在混合深度卷积中，深度可分离卷积和标准卷积并行使用。</li><li>网络的不同分支可以具有不同的卷积类型，这允许在计算复杂性和模型容量之间进行灵活的权衡。</li><li>两种类型卷积的输出会以适合特定架构的方式进行连接或组合。</li></ul></li></ol><p>混合深度卷积可在为移动设备或嵌入式设备设计的模型架构中非常有益，因为它允许在不显著降低准确性的情况下，灵活地权衡计算和模型大小。它经常用于提高神经网络的效率，同时在图像分类和目标检测等任务中保持或提高性能。</p><h1 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h1><p>训练深层神经网络是十分困难的，特别是在较短的时间内使他们收敛更加棘手。 本节将介绍<em>批量规范化</em>（batch normalization） :cite:<code>Ioffe.Szegedy.2015</code>，这是一种流行且有效的技术，可持续加速深层网络的收敛速度。 再结合在 :numref:<code>sec_resnet</code>中将介绍的残差块，批量规范化使得研究人员能够训练100层以上的网络。</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310112110787.webp" alt="image-20231011211044576" style="zoom: 67%;" /><p>减均值，除以标准差就是正则化，由原始分布近似限定为均值为0方差为1的正态分布</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310112111731.webp" alt="image-20231011211134593" style="zoom:67%;" /><p>应用标准化后，生成的小批量的平均值为0和单位方差为1。 由于单位方差（与其他一些魔法数）是一个主观的选择，因此我们通常包含 拉伸参数（scale）𝜸 和偏移参数（shift）𝜷，它们的形状与 𝐱 相同。 请注意，𝜸 和 𝜷 是需要与其他模型参数一起学习的参数。</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202310112114462.webp" alt="image-20231011211430294" style="zoom: 50%;" /><p>总结：</p><ul><li>批量归一化固定小批量中得均值和方差，然后学习出适合的偏移和缩放。</li><li>&#x3D;&#x3D;可以加速收敛速度，但一般不改变模型精度&#x3D;&#x3D;</li></ul><h1 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h1><p>传统的神经网络无法获取时序信息，然而<strong>时序信息在自然语言处理任务中非常重要</strong>。</p><p>RNN 的出现，让处理时序信息变为可能。</p><ul><li>需要让network有记忆力。</li><li>memory需要给定initial value。输出的值存入memory，加入下次运算。</li><li>在RNN中，input sequence 的order变化，输出完全不一样。</li></ul><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309280945256.webp" alt="image-20230928094525293" style="zoom: 67%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309280951700.webp" alt="image-20230928095158424" style="zoom:67%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309280953308.webp" alt="image-20230928095316056" style="zoom:67%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309280954996.webp" alt="image-20230928095436759" style="zoom:67%;" /><ul><li>双向RNN</li></ul><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309280956890.webp" alt="image-20230928095647656" style="zoom:67%;" /><h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><ul><li>Long Shot-term Memory</li><li>在 memory 的前和后加入 gate，机器会自动学习何时打开和关闭。</li><li>memory 自身也加入了 Forget Gate 的机制，学习自动保留或删除memory中的值。</li></ul><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309281002072.webp" alt="image-20230928100232761" style="zoom:67%;" /><ul><li>这个Forget Gate或许可以被称为Remember Gate，开启时记忆，关闭时遗忘。</li></ul><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309281010729.webp" alt="image-20230928101027481" style="zoom:67%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309281015550.webp" alt="试试看" style="zoom:67%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309281025210.webp" alt="搞懂计算" style="zoom:67%;" /><ul><li>可以理解为将普通的 neuron 换成LSTM。</li><li>只不过换成了四个 input 后才能有一个output。</li><li>四个 input 可由原 input 乘不同的权重得到。需要4倍的参数。</li></ul><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309281028765.webp" alt="对比" style="zoom:50%;" /><ul><li>以下所有箭头都代表一个transform。</li><li>将其转换成矩阵并行计算。</li></ul><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309281040932.webp" alt="返回RNN的原理" style="zoom:67%;" /><ul><li>一个LSTM的计算过程</li></ul><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309281044431.webp" alt="一个LSTM" style="zoom:67%;" /><ul><li>一层中的两个LSTM的连接。</li><li>LSTM通常不止一层。</li></ul><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309281046954.webp" alt="一层中的两个LSTM的连接" style="zoom:67%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309281050392.webp" alt="image-20230928105012130" style="zoom:50%;" /><p>Gated Recurrent Unit（GRU）和Long Short-Term Memory（LSTM）是两种常见的循环神经网络（RNN）结构，而GRU可以被视为LSTM的一种变体，它包含了较少的门（gates）。</p><p>LSTM 和 GRU 的主要区别在于其内部结构，特别是在如何处理和传递信息上。LSTM包括三个门：输入门（Input Gate）、遗忘门（Forget Gate）、输出门（Output Gate）。每个门都有一个相关的权重，用于控制信息的流动。相比之下，GRU只包括两个门：更新门（Update Gate）和重置门（Reset Gate）。</p><p>具体来说，GRU的内部状态更新规则如下：</p><p>zₜ &#x3D; σ(Wₓₕ [hₜ₋₁, xₜ])  <!-- 更新门 --><br>        rₜ &#x3D; σ(Wᵣ [hₜ₋₁, xₜ])  <!-- 重置门 --><br>        ḣₜ &#x3D; tanh(W [rₜ ⊙ hₜ₋₁, xₜ])  <!-- 新状态的候选值 --><br>        hₜ &#x3D; (1 - zₜ) ⊙ hₜ₋₁ + zₜ ⊙ ḣₜ  <!-- 更新状态 --></p><ul><li><code>σ</code> 表示 sigmoid 函数。</li><li><code>⊙</code> 表示元素级别的乘法。</li><li>下标（如ₜ、ₓₕ、ᵣ）使用 <code>_</code>。</li><li>LaTeX中的 <code>[...]</code> 表示向量或矩阵。</li></ul><p>相较于LSTM，GRU的结构更简单，参数数量更少，因此在某些情况下更容易训练，特别是当数据较少或计算资源有限时。然而，对于某些复杂的序列建模任务，LSTM 仍然可能表现更好。选择使用 LSTM 还是 GRU 取决于具体的任务和数据。</p><h3 id="Learning-Target"><a href="#Learning-Target" class="headerlink" title="Learning Target"></a>Learning Target</h3><ul><li>Loss function：对应时间点的 RNN 的 output 和 Reference vector 的 cross entropy。</li><li>Gradient decent 方式去 update 每一个参数。</li><li>使用反向传播的进阶版算法 Backpropagation through time(BPTT) 。需要考虑时间问题。</li></ul><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309281132093.webp" alt="反向传播" style="zoom:67%;" /><ul><li>RNN的error surface存在非常大的跳跃，训练时参数非常容易大幅度变化。</li></ul><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309281143023.webp" alt="RNN的梯度" style="zoom:67%;" /><ul><li>LSTM 可以解决 RNN 梯度消失的问题，可以放心的将 lr 调小。可以代替普通的 RNN。</li><li>LSTM 中 memory 乘上一个值后和 input 相加，再覆盖 memory，这样会保留前一时刻对后续输出的影响（除非Forget gate 消除，通常会保持这个gate开放，偶尔关闭）。RNN 的每个时刻的 memory的咨询都会被重新覆盖，影响消失。</li><li>GRU 只有两个 gate，需要的参数少。所以 LSTM 过拟合时，可以考虑 GRU。</li></ul><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309281203595.webp" alt="image-20230928120347307" style="zoom:67%;" /><h1 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h1><p>在机器学习和深度学习领域，”ablation studies”（消融研究）是一种常见的实验方法，用于评估模型的性能和理解模型的组件对性能的贡献。具体来说，ablation studies通常涉及以下步骤：</p><ol><li>基线模型：首先，研究人员会训练一个基线模型，这是一个包含所有组件和特性的模型，用于解决特定任务或问题。</li><li>组件消融：接下来，研究人员会逐步移除或禁用模型的某些组件、特性或层，例如神经网络中的某些层、特征工程中的某些特征等。这是”ablation”的部分，意味着削减或切除模型的某些部分。</li><li>性能评估：在每次组件消融后，研究人员会重新评估模型的性能，通常是通过使用验证集或测试集来测量模型的性能指标，如准确率、精确度、召回率、F1分数等。</li><li>结果分析：通过比较不同组件消融条件下的性能，研究人员可以确定哪些组件对模型的性能贡献最大，哪些组件对性能影响不大，从而更好地理解模型的工作方式。</li></ol><p>Ablation studies的主要目的是帮助研究人员确定模型的关键组成部分，指导模型的改进和优化。通过逐步消除不必要的组件，研究人员可以更好地理解模型的复杂性，并提高模型的效率和性能。这种方法在深度学习和机器学习研究中非常常见，特别是在模型架构设计和特征工程方面。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Deeplearning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>决策树</title>
      <link href="/posts/29152/"/>
      <url>/posts/29152/</url>
      
        <content type="html"><![CDATA[<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a><p align="center">决策树</p></h1><p>猫分类作为示例：</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309141742921.webp" alt="image-20230914174201119" style="zoom: 67%;" /><p align="center">根节点  >>>  决策节点  >>>  叶节点 </p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309141749242.webp" alt="image-20230914174911889" style="zoom:50%;" /><ul><li>&#x3D;&#x3D;决策树的工作算法：从所有可能的决策树中，尝试选择一个在训练集上表先良好的树，然后理想的泛化到新数据。&#x3D;&#x3D;</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309141751202.webp" alt="image-20230914175149945"></p><h2 id="学习过程："><a href="#学习过程：" class="headerlink" title="学习过程："></a>学习过程：</h2><ul><li>决定根节点使用什么特征。    </li><li>只关注左侧部分，决定将哪些节点放在那，特别是要拆分的特征。</li><li>右侧部分重复上述操作。</li></ul><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309142029321.webp" alt="image-20230914202951995" style="zoom: 50%;" /><ol><li><p>如何选择每个节点上使用哪些特征进行拆分？</p><p>决策树将要选择拆分的特征以尝试<strong>最大化纯度</strong>。</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309142035225.webp" alt="image-20230914203540840" style="zoom:50%;" /></li><li><p>构建决策树的第二个关键是决定何时停止分裂。</p></li></ol><ul><li>当一个节点一定是一类时。</li><li>当分出的节点到达树的最大深度时。（限制决策树深度的一个原因时确保树不会太大和太笨重；通过保持树小，使其不太容易过拟合）</li><li>优先级分数的改进，该分数应该低于某个阈值。</li><li>一个节点的示例数量低于某个阈值，也可能决定停止分裂。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309142050213.webp" alt="image-20230914205023932"></p><h2 id="纯度"><a href="#纯度" class="headerlink" title="纯度"></a>纯度</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">在决策树中，熵（entropy）是一种用于衡量数据集的不纯度（impurity）的常用度量方式之一。 </span></span><br><span class="line"><span class="string">熵的概念来源于信息论，它用于衡量系统的混乱程度或不确定性。在决策树中，熵用于衡量一个数据集中不同类别的混合程度。如果一个数据集中的样本都属于同一类别，那么熵为0，表示数据集非常纯净。如果一个数据集中的样本均匀分布在不同的类别中，那么熵会较高，表示数据集不纯，即存在较大的不确定性。</span></span><br><span class="line"><span class="string">熵越高，数据集的不纯度越高，表示需要更多的决策来对数据进行分类。决策树算法会尝试使用不同的特征来分割数据，以降低数据集的熵，即增加数据集的纯度。通过选择使得熵降低最多的特征作为分割特征，决策树可以逐步构建出一个能够有效分类数据的树形结构。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309142134287.webp" alt="image-20230914213441134"></p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309142128263.webp" alt="image-20230914212832975" style="zoom:50%;" /><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309142133414.webp" alt="image-20230914213310196"></p><h2 id="选择拆分信息增益"><a href="#选择拆分信息增益" class="headerlink" title="选择拆分信息增益"></a>选择拆分信息增益</h2><ul><li><p>在构建决策树时，决定在节点上拆分哪个特征的方式将基于哪种特征选择能够减少熵。</p></li><li><p>计算出熵之后，鉴于要在根节点使用的功能的这三个选项，哪个最有效？</p></li><li><p><strong>如果一个节点有很多示例且具有高熵，相比只有几个示例的高熵要好一点。</strong></p></li><li><p>下图三种情况的根节点已经计算出了左右分支的熵，为了从中挑选，可以将两个数字组合成一个数字。要看每个分支下示例的数量，如果使得示例多的分支的熵低一些，才会是正确的选择。**<code>计算加权平均熵</code>**</p></li><li><p><strong>需要计算的不是加权平均熵，而是与根本没有分裂的熵减少</strong>：转到根节点，开始是10个示例，5猫5狗，p_1实际为0.5，而0.5对应的熵为1。然后减去计算出来的分裂后的加权平均熵，计算出<strong>熵减</strong>。这些被称为<strong>信息增益</strong>。</p></li><li><p>事实证明，决定何时不再进一步分裂的停止标准之一是熵减的大小 。<strong>熵减越大的越好</strong>。</p></li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309151425110.webp" alt="image-20230915142506755"></p><h3 id="信息增益的一般定义："><a href="#信息增益的一般定义：" class="headerlink" title="信息增益的一般定义："></a><strong>信息增益</strong>的一般定义：</h3><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309151429224.webp" alt="image-20230915142929927" style="zoom:50%;" /><blockquote><p>其中   <strong>p_1 ^ left</strong>   表示左分支中正标签样本所占示例分数；</p><p><strong>w ^ left</strong>  表示转到左分支的样本占根节点的样本分数；  </p><p> <strong>p_1 ^ root</strong>    表示根节点中正样本的分数。</p></blockquote><h2 id="给定训练集的情况下构建决策树的整体算法"><a href="#给定训练集的情况下构建决策树的整体算法" class="headerlink" title="给定训练集的情况下构建决策树的整体算法"></a>给定训练集的情况下构建决策树的整体算法</h2><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309151502324.webp" alt="image-20230915150159977" style="zoom:50%;" /><ol><li>从树的根节点处的所有训练样本开始。</li><li>计算所有可能特征的信息增益，并选择要拆分的特征以提供最高的信息增益。</li><li>将数据集划分为两个子集，创建树的左右分支，将训练样本发送到左右分支。</li><li>重复上述拆分过程直至：<ul><li>当一个节点100%为一个类别时，熵为0时；</li><li>达到树的最大深度时；</li><li>拆分的信息增益小于阈值时；</li><li>拆分出的节点的样本小于阈值时；</li></ul></li></ol><p>构建决策树的方式是构建较小的子决策树然后将它们放在一起来构建整体决策树。<strong>递归算法</strong>。</p><h2 id="决策树的改进："><a href="#决策树的改进：" class="headerlink" title="决策树的改进："></a>决策树的改进：</h2><h3 id="one-hot编码："><a href="#one-hot编码：" class="headerlink" title="one-hot编码："></a>one-hot编码：</h3><ul><li>解决两个以上的特征：换成k个二进制特征来替换。所有特征中恰有一个为1，剩下的都为0，所以称为：one-hot编码。<strong>该方法也适用于神经网络。</strong></li></ul><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309151615856.webp" alt="image-20230915161502495" style="zoom:67%;" /><h3 id="连续值数字特征的处理："><a href="#连续值数字特征的处理：" class="headerlink" title="连续值数字特征的处理："></a>连续值数字特征的处理：</h3><p>例如在小猫分类器中加入体重这个特征，它是离散的数值。</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309151720456.webp" alt="image-20230915172018220" style="zoom:67%;" /><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309151722745.webp" alt="image-20230915172224452"></p><ul><li>如上图所示，尝试一些值来拆分数据集，并计算信息增益，选择信息增益最高的一次作为拆分依据。一般会沿着x轴取多个值，一种惯例是根据此特征的值对所有示例进行排序，并取所有排序列表之间的中点的值。考虑此处作为阈值。（例如10个训练样本，就要测试9个不同的值，然后选择提供最高信息增益的值作为阈值）</li></ul><h2 id="回归树"><a href="#回归树" class="headerlink" title="回归树"></a>回归树</h2><ul><li>上述讨论了决策树分类算法，将决策树泛化，得到回归树，将可以预测数字等离散的值。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309151804527.webp" alt="image-20230915180453195"></p><ul><li>将输入的特征变为三个，而将体重变为输出。这就变成了一个回归问题。</li><li>拆分的方法变成了计算<strong>加权方差</strong>，然后计算方差的减少。选择最大的方差减少的特征作为拆分特征。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309171315779.webp" alt="image-20230917131506332"></p><h2 id="使用多个决策树"><a href="#使用多个决策树" class="headerlink" title="使用多个决策树"></a>使用多个决策树</h2><ul><li>使用单个决策树的缺点之一是该决策树可能对数据中的微笑变化高度敏感。解决方法是构建多个决策树。</li><li>修改一个训练样本就导致算法再根部产生了不同的根部分裂。使用决策树时，通常会得到一个更好的结果，因为可以训练一大堆决策树而不是仅训练一个，这样得到的预测更加准确。</li><li>如果有一个想要分类的新预测样本，可以在新样本上运行所有的这三棵树，并选取票数最多结果的作为最终预测。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309171351850.webp" alt="image-20230917135121683"></p><h3 id="有放回抽样"><a href="#有放回抽样" class="headerlink" title="有放回抽样"></a>有放回抽样</h3><ul><li>这么多种不同的决策树是如何生成的？<strong>进行有放回的抽样来替换训练集。</strong></li></ul><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309171405685.webp" alt="image-20230917140521502" style="zoom:33%;" /><h2 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h2><ul><li>进行有放回的抽样来生成与原始训练集大小一样的新训练集，训练决策树。然后尝试预测时，依旧采用投票的形式确定最终预测。</li><li>事实证明，如果将抽样产生新训练集的次数调的很大，实际没有什么太大改进。</li><li>关键思想是：有些抽样产生的新训练集所产生的决策树在进行拆分时与之前的决策树相似。</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309171423104.webp" alt="image-20230917142329649"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309171440713.webp" alt="image-20230917144048529"></p><h2 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h2><ul><li><p>总结为<strong>刻意练习</strong>四个字，主要训练表现差的那部分。在抽样时，多多选择预测错误的训练集进行产生新的决策树。</p></li><li><p>梯度提升：XGBoost是梯度提升框架的一种实现，这是一种集成学习方法。梯度提升按顺序构建一组决策树，每棵树都纠正了前一棵树的错误，从而产生了一个高度准确的模型。</p></li><li><p>正则化：XGBoost在其目标函数中包括了内置的L1（Lasso回归）和L2（Ridge回归）正则化项。这有助于防止过拟合，使模型更加稳健。</p></li><li><p>处理缺失值：XGBoost具有处理缺失数据的强大方法。它可以在训练过程中自动学习如何最好地填补缺失值，减少了预处理的需求。</p></li><li><p>树剪枝：XGBoost采用一种称为“剪枝”的技术来控制集成中各个树的生长，防止它们变得过于深并过拟合数据。</p></li><li><p>并行处理：XGBoost被设计为高效处理，可以利用并行处理，适用于大型数据集和分布式计算环境。</p></li><li><p>交叉验证：该算法提供了内置的交叉验证功能，使超参数调整和模型性能评估更加容易。</p></li><li><p>特征重要性：XGBoost提供特征重要性分数，有助于识别数据集中最重要的特征，帮助特征选择和模型解释。</p></li><li><p>各种损失函数支持：XGBoost支持不同类型任务的各种损失函数，包括回归、二元分类和多类分类。</p></li><li><p>GPU加速支持：XGBoost可以使用GPU进行加速，进一步提高训练速度。</p></li><li><p>多功能性：XGBoost可用于广泛的机器学习任务，包括结构化数据、自然语言处理和推荐系统。</p></li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309171456145.webp" alt="image-20230917145605950"></p><h2 id="何时选择使用决策树？"><a href="#何时选择使用决策树？" class="headerlink" title="何时选择使用决策树？"></a>何时选择使用决策树？</h2><ul><li>决策树和树通常适用于表格数据，也称为结构化数据。</li><li>不太适用于非结构化数据，例如图像、视频、音频、文本等</li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309171512326.webp" alt="image-20230917151232045"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309171515722.webp" alt="image-20230917151522517"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>机器学习开发的迭代过程</title>
      <link href="/posts/29151/"/>
      <url>/posts/29151/</url>
      
        <content type="html"><![CDATA[<h1 id="机器学习开发的迭代过程"><a href="#机器学习开发的迭代过程" class="headerlink" title="机器学习开发的迭代过程"></a><p align="center">机器学习开发的迭代过程</p></h1><ol><li>选择系统的框架：模型、数据、超参数等等。</li><li>训练模型。</li><li>诊断模型。</li><li>做出决定：是否扩大神经网络、更改正则化参数、添加数据、增加或者减少功能。</li><li>持续上述过程。</li></ol><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309131410115.webp" alt="image-20230913141043879" style="zoom: 50%;" /><h2 id="错误分析"><a href="#错误分析" class="headerlink" title="错误分析"></a>错误分析</h2><p>手动检查算法的错误分类或错误标记的示例，尝试找出错误原因并解决。（根据误差收集更多数据）</p><h2 id="添加更多数据"><a href="#添加更多数据" class="headerlink" title="添加更多数据"></a>添加更多数据</h2><p>根据问题，添加对解决问题最有用的数据。</p><h3 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h3><p>机器学习数据增强是一种用于改善训练数据集的技术，旨在提高机器学习模型的性能和鲁棒性。数据增强的主要思想是通过对原始数据进行一系列变换或处理，生成新的训练样本，从而扩充训练数据集。这有助于模型更好地泛化到未见过的数据，并减少过拟合的风险。以下是一些常见的机器学习数据增强技术：</p><ol><li>图像数据增强：<ul><li>随机旋转：对图像进行随机旋转，以增加视角的多样性。</li><li>镜像翻转：水平或垂直翻转图像，以生成镜像样本。</li><li>随机裁剪：随机裁剪图像的一部分，以改变图像的大小和内容。</li><li>调整亮度和对比度：随机调整图像的亮度和对比度，以模拟不同的光照条件。</li><li>增加噪声：向图像中添加随机噪声，以提高模型对噪声的鲁棒性。</li></ul></li><li>文本数据增强：<ul><li>同义词替换：替换文本中的一些词汇为其同义词，以生成新的句子。</li><li>随机删除和插入：随机删除文本中的词语或随机插入新的词语，以改变句子结构。</li><li>扰动：对文本进行随机扰动，如字符级别的替换或重排。</li><li>生成对抗样本：使用生成对抗网络（GANs）生成对抗样本，以使模型更加鲁棒。</li></ul></li><li>音频数据增强：<ul><li>变速和变调：改变音频的播放速度和音调，以增加多样性。</li><li>加噪声：向音频中添加随机噪声，以提高模型对噪声的鲁棒性。</li><li>时间剪辑：随机剪辑音频的一部分，以改变音频的长度和内容。</li></ul></li></ol><p>数据增强技术的选择取决于任务和数据类型。在训练机器学习模型之前，通常需要仔细考虑数据增强策略，以确保生成的样本仍然保持与实际数据的一致性。数据增强可以帮助提高模型的性能，特别是在数据有限的情况下，但也需要小心以避免引入不良影响。</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309131449503.webp" alt="image-20230913144953300" style="zoom:50%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309131506848.webp" alt="image-20230913150623575" style="zoom:50%;" /><h2 id="迁移学习-使用其他任务中的数据"><a href="#迁移学习-使用其他任务中的数据" class="headerlink" title="迁移学习_使用其他任务中的数据"></a>迁移学习_使用其他任务中的数据</h2><p>针对神经网络模型的参数训练：</p><ol><li><strong>仅训练输出层的参数</strong>：<ul><li>这种方式被称为特征提取或冻结底层特征表示。在这种策略中，模型的底层（通常是卷积神经网络或预训练的特征提取器）的权重通常被冻结，不再进行训练，而<strong>只有输出层的参数</strong>（通常是分类器）被训练以适应新任务。</li><li>这种方法适用于源任务和目标任务之间的特征表示相似，但分类或预测的任务不同。冻结底层特征表示可以防止在目标任务上过拟合，并且通常需要较少的训练数据。</li></ul></li><li><strong>训练所有层的参数</strong>：<ul><li>这种方式被称为微调。在微调中，除了输出层之外，模型的底层参数也会被训练，（以之前的参数值为初始值）但训练速度通常比较慢，因为这些底层参数已经包含了预训练任务的知识。</li><li>这种方法适用于源任务和目标任务之间的特征表示相似性较高，或者需要在目标任务上进行更多的模型调整以适应新任务。</li></ul></li></ol><p> 选择哪种策略取决于迁移学习任务的特性。通常情况下，如果源任务和目标任务之间有很大的相似性，微调整个模型的参数可能会更有效，因为模型可以从源任务中受益。然而，如果源任务和目标任务之间差异很大，只训练输出层的参数可能会更合适，因为这可以减少过拟合的风险。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309131538345.webp" alt="image-20230913153802116"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309131559030.webp" alt="image-20230913155954813"></p><p>迁移学习是一项重要的机器学习技术，允许将从一个任务中学到的知识迁移到另一个相关任务中，以改善模型性能和加速训练过程。以下是迁移学习的主要要点和总结：</p><ol><li><strong>核心思想</strong>：迁移学习的核心思想是利用已有知识来帮助解决新任务，即使新任务的数据分布或特性与原任务不完全相同。</li><li><strong>两种主要策略</strong>：迁移学习通常包括两种主要策略：<ul><li><strong>基于特征的迁移学习</strong>：重用底层特征表示，通常冻结底层，只训练输出层的参数。</li><li><strong>基于模型的迁移学习</strong>：重用整个或部分预训练模型，包括底层特征表示，可能微调整个模型的参数。</li></ul></li><li><strong>适用场景</strong>：选择迁移学习策略取决于源任务和目标任务之间的相似性和差异性。<ul><li>如果源任务和目标任务之间相似，微调整个模型可能更有效。</li><li>如果源任务和目标任务之间差异大，只训练输出层的参数可能更合适。</li></ul></li><li><strong>应用领域</strong>：迁移学习广泛应用于计算机视觉、自然语言处理、语音识别等领域，用于提高模型性能和泛化能力。</li><li><strong>数据有限性</strong>：迁移学习特别有用，当目标任务的数据量有限或难以获得大规模标记数据时，可以借助已有知识来加速模型的学习过程。</li><li><strong>实验和调整</strong>：在应用迁移学习时，通常需要进行实验和调整，以确定哪种策略对特定任务最有效。有时可以结合不同策略以获得最佳性能。</li></ol><h2 id="机器学习项目的完整周期"><a href="#机器学习项目的完整周期" class="headerlink" title="机器学习项目的完整周期"></a>机器学习项目的完整周期</h2><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309131626841.webp" alt="image-20230913162659552" style="zoom:50%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309131635991.webp" alt="image-20230913163549719" style="zoom:50%;" /><h2 id="倾斜数据集的误差指标"><a href="#倾斜数据集的误差指标" class="headerlink" title="倾斜数据集的误差指标"></a>倾斜数据集的误差指标</h2><p>误差最小的预测可能不是特别有用的预测。在处理倾斜数据集的问题时，我们通常使用不同的误差度量，而不仅仅是分类误差。</p><p> 一对常见的错误指标是<strong>精确率</strong>和<strong>召回率</strong>，</p><p>引入<strong>混淆矩阵</strong>：</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309131906587.webp" alt="image-20230913190612369" style="zoom:50%;" /><ul><li><p><strong>精确率定义为：预测结果中真阳性的数量与分类为阳性数量的比值。</strong></p></li><li><p><strong>召回率定义为：预测结果中真阳性的数量与实际为阳性数量的比值。</strong></p></li><li><p>一般来说，零准确率和零召回率的算法是无用算法。</p></li><li><p><strong>精确率很高：说话靠谱。</strong></p></li><li><p><strong>召回率很高：遗漏率很低。</strong></p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&quot;准确率&quot;（Accuracy）和&quot;精确率&quot;（Precision）是两个不同的性能评估指标，通常用于衡量分类模型的性能，特别是在二分类问题中。它们有不同的计算方法和重要性。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">1. 准确率（Accuracy）： 准确率是一个分类模型的总体性能度量，它衡量了模型正确分类样本的比例。准确率的计算方法如下： </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">准确率 = 正确分类的样本数/总样本数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">准确率的优点是简单易懂，但它有一个问题，就是对于不平衡的数据集来说，可能会给出误导性的结果。如果数据集中某个类别的样本比其他类别多得多，模型只需预测多数类别，也能获得高准确率。因此，在不平衡数据集中，准确率可能不是一个很好的性能指标。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">2. 精确率（Precision）： 精确率衡量了模型在预测为正类别的样本中，实际为正类别的比例。精确率的计算方法如下： </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">精确率 = 真正例/(真正例+假正例)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">其中，真正例是模型正确预测为正类别的样本数，假正例是模型错误预测为正类别的样本数。精确率强调了模型对正类别的预测准确性，对于那些需要高度准确性的应用，精确率是一个重要的指标。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="精确率与召回率的权衡"><a href="#精确率与召回率的权衡" class="headerlink" title="精确率与召回率的权衡"></a>精确率与召回率的权衡</h2><ul><li><p>提高分类阈值会提高精确度，但是会导致较低的召回率。另一种相反的情况例如做核酸，就是为了提高召回率，“宁可错杀一千，也不会放过一个“，这样召回率高，但精确率变低。<img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309132013257.webp" alt="image-20230913201349928">     </p></li><li><p>当   <em><strong>f</strong></em>   高于某个阈值时，我们通过设置这个阈值，可以很好的在精确度和召回率之间做出不同的权衡。</p></li><li><p>notice：选择与阈值并不是要通过交叉验证做的事情，手动选择阈值权衡是我们要做的。</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># F1分数</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">F1分数是一个综合考虑精确率（Precision）和召回率（Recall）的性能评估指标，通常用于评估二分类模型的性能。它衡量了模型在同时考虑精确性和完整性的情况下的性能。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">F1分数的计算方法如下：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">F1=2⋅(精确率⋅召回率)/(精确率+召回率)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">F1分数通过精确率和召回率的调和平均来综合考虑两者，这有助于平衡模型的精确性和完整性。F1分数的取值范围在0和1之间，值越高表示模型性能越好。当模型的精确率和召回率都很高时，F1分数也会很高，反之亦然。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">F1分数特别适用于处理不平衡数据集，其中一个类别的样本数量远远多于另一个类别。在这种情况下，如果只使用精确率或召回率来评估模型，可能会导致误导，因为模型可能会倾向于预测为占主导地位的类别。F1分数帮助平衡了这两个指标，使其更公平地考虑了正类别和负类别的性能。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p align="center">`**P和R的调和平均数**`</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309132048000.webp" alt="image-20230913204842787"></p><h2 id="ROC-曲线"><a href="#ROC-曲线" class="headerlink" title="ROC 曲线"></a>ROC 曲线</h2><p>AUC：随机挑选一个正样本以及一个负样本，模型预测 <strong>正样本为正的概率的值（Score值）</strong>大于 <strong>模型预测 负样本为正的概率的值</strong> 的概率 就是AUC的值。</p><p>所以根据定义：我们最直观的有两种计算AUC的方法</p><p>1：绘制ROC曲线，ROC曲线下面的面积就是AUC的值</p><p>2：假设总共有（m+n）个样本，其中正样本m个，负样本n个，一个正样本和一个负样本的组合有 m * n个样本对，我们对 <strong>正样本预测为正样本的概率值</strong> 大于 <strong>负样本预测为正样本的概率值</strong> 计数，也就是累加计数，然后用累加计数的和除以（m * n）就是AUC的值。</p><p>roc曲线：接收者操作特征(receiver operating characteristic),roc曲线上每个点反映着对同一信号刺激的感受性。</p><p><strong>纵轴</strong>：真正类率(true postive rate <strong>TPR</strong>)，也叫<strong>真阳性率</strong></p><p><strong>横轴</strong>：假正类率(false postive rate <strong>FPR</strong>)，也叫<strong>伪阳性率</strong></p><p>由上表可得出横，纵轴的计算公式：</p><p>(1)**真正类率(**True Postive Rate)TPR: <strong>TP&#x2F;(TP+FN)</strong>, 代表分类器</p><p>​<strong>预测为正类，实际为正实例 占 所有正实例 的比例。</strong></p><p>(2)<strong>假正类率</strong>(False Postive Rate)FPR: **FP&#x2F;(FP+TN)**，代表分类器</p><p>​<strong>预测为正类，实际为负实例 占 所有负实例 的比例。</strong></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Image Classification</title>
      <link href="/posts/29150/"/>
      <url>/posts/29150/</url>
      
        <content type="html"><![CDATA[<h1 id="Image-Classification"><a href="#Image-Classification" class="headerlink" title="Image Classification"></a><p align="center">Image Classification</p></h1><ul><li><p>本次主要实践内容是在图像分类任务中训练和评估不同的神经网络模型，目前尝试<strong>MobileNetV2、MobileNetV3_small、ResNet18、ResNet34、ShuffleNetV1、ShuffleNetV2、VGG11、VGG11_bn</strong>，并对模型进行了评估。</p></li><li><p>通过实践，发现在不同模型上的性能达到了一定的高度，但还有许多提升空间，后续会继续<strong>使用不同模型、修改超参数、数据预处理、学习率更新策略、优化器等方面进行优化。添加类别激活图可视化、学习策略可视化、数据增强策略可视化。</strong></p></li><li><p>本次实践具体内容为对花卉图像进行分类，以下内容为不同模型的性能指标和混淆矩阵。</p></li></ul><hr><p>涉及模型的内容，在 <strong>model_cfg</strong> 中，一个完整的模型由 <strong>backbone</strong>、<strong>neck</strong> 、<strong>head</strong>；损失的计算集成在<strong>head</strong>中。</p><p><code>eval()</code> 是Python内置函数之一，用于计算传递给它的表达式并返回结果。它将接受的字符串作为一个有效的Python表达式进行解析和计算。<code>eval()</code> 函数的使用案例包括：</p><ul><li><strong>计算数学表达式：</strong> 可以用于执行数学表达式，例如计算数学运算。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result = <span class="built_in">eval</span>(<span class="string">&quot;2 + 3 * 4&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(result)  <span class="comment"># 输出：14</span></span><br></pre></td></tr></table></figure><ul><li><strong>动态执行代码：</strong> 可以用于执行动态生成的代码。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x = <span class="number">5</span></span><br><span class="line">y = <span class="number">10</span></span><br><span class="line">expression = <span class="string">&quot;x + y&quot;</span></span><br><span class="line">result = <span class="built_in">eval</span>(expression)</span><br><span class="line"><span class="built_in">print</span>(result)  <span class="comment"># 输出：15</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><strong>创建自定义函数： 可以用于动态创建函数。</strong></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">dynamic_function</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">eval</span>(<span class="string">&quot;x * 2 + 1&quot;</span>)</span><br><span class="line"></span><br><span class="line">result = dynamic_function(<span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(result)  <span class="comment"># 输出：7</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/train.py models/  /</span><br></pre></td></tr></table></figure><p>评估：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/evaluation.py models/  /</span><br></pre></td></tr></table></figure><h3 id="数据预处理-数据增强"><a href="#数据预处理-数据增强" class="headerlink" title="数据预处理|数据增强"></a>数据预处理|数据增强</h3><p>五种花卉图片，共计3670张图片。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309121723220.webp" alt="image-20230912172315065"></p><ul><li><p>标签文件制作</p></li><li><p>数据集划分</p></li><li><p>数据集信息文件制作</p></li><li><p>转换与编辑图像标注文件</p></li></ul><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><ul><li><strong><a href="https://ieeexplore.ieee.org/document/6795724">LeNet5</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124461111">AlexNet</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124477080">VGG</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124630832">DenseNet</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124477575">ResNet</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124754437">Wide-ResNet</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124477919">ResNeXt</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124478157">SEResNet</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124478347">SEResNeXt</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124478426">RegNet</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124478681">MobileNetV2</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124478770">MobileNetV3</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124479156">ShuffleNetV1</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124479336">ShuffleNetV2</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124754493">EfficientNet</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124479644">RepVGG</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124479467">Res2Net</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124481466">ConvNeXt</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124481590">HRNet</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124481766">ConvMixer</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124481930">CSPNet</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124538198">Swin-Transformer</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124567953">Vision-Transformer</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124596023">Transformer-in-Transformer</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124596093">MLP-Mixer</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124591888">DeiT</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124596343">Conformer</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124596425">T2T-ViT</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124596619">Twins</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124596740">PoolFormer</a></strong></li><li><strong><a href="https://blog.csdn.net/zzh516451964zzh/article/details/124630541">VAN</a></strong></li><li><strong><a href="https://arxiv.org/pdf/2207.14284v2.pdf">HorNet</a></strong></li><li><strong><a href="https://arxiv.org/abs/2206.01191">EfficientFormer</a></strong></li><li><strong><a href="https://arxiv.org/abs/2111.09883.pdf">Swin Transformer V2</a></strong></li><li><strong><a href="http://openaccess.thecvf.com//content/CVPR2022/papers/Li_MViTv2_Improved_Multiscale_Vision_Transformers_for_Classification_and_Detection_CVPR_2022_paper.pdf">MViT V2</a></strong></li><li><strong><a href="https://arxiv.org/abs/2110.02178">MobileViT</a></strong></li><li><strong><a href="https://arxiv.org/abs/2204.03645v1">DaViT</a></strong></li><li><strong><a href="https://arxiv.org/abs/2203.06717">replknet</a></strong></li><li><strong><a href="https://arxiv.org/abs/2106.08254">BEiT</a></strong></li><li><strong><a href="https://arxiv.org/abs/2211.07636">EVA</a></strong></li><li><strong><a href="https://arxiv.org/abs/2205.13137">MixMIM</a></strong></li><li><strong><a href="https://arxiv.org/abs/2104.00298">EfficientNetV2</a></strong></li></ul><h3 id="预训练权重"><a href="#预训练权重" class="headerlink" title="预训练权重"></a>预训练权重</h3><h3 id="学习率更新策略-优化器"><a href="#学习率更新策略-优化器" class="headerlink" title="学习率更新策略|优化器"></a>学习率更新策略|优化器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@repo&#123;2020mmclassification,</span></span><br><span class="line">    title=&#123;OpenMMLa<span class="string">b&#x27;s Image Classification Toolbox and Benchmark&#125;,</span></span><br><span class="line"><span class="string">    author=&#123;MMClassification Contributors&#125;,</span></span><br><span class="line"><span class="string">    howpublished = &#123;\url&#123;https://github.com/open-mmlab/mmclassification&#125;&#125;,</span></span><br><span class="line"><span class="string">    year=&#123;2020&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure><h2 id="1、mobilenet-v3-small"><a href="#1、mobilenet-v3-small" class="headerlink" title="1、mobilenet_v3_small"></a>1、mobilenet_v3_small</h2><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/image-20230816230759363.webp" alt="image-20230816230759363"></p><ul><li><strong>Backbone（骨干网络）：</strong> 骨干网络是模型的基础部分，用于从输入数据中提取特征。在这里，使用了MobileNetV3 作为骨干网络。MobileNetV3 是一种轻量级的卷积神经网络架构，适用于移动设备和计算资源受限的场景。</li><li><strong>Neck（特征提取部分）：</strong> 特征提取部分是在骨干网络之后添加的层，用于进一步提取抽象特征。在这里，您使用了 Global Average Pooling，这是一种用于减少特征图尺寸的操作，将每个特征通道的平均值作为全局特征表示。</li><li><strong>Head（分类头部）：</strong> 分类头部是模型的最后一层，用于将从特征提取部分得到的特征映射到不同类别的预测。使用了 Stacked Linear Classification Head，这是一个堆叠的线性分类层，用于生成类别预测。</li><li><strong>Loss（损失函数）：</strong> 损失函数用于衡量模型的预测与真实标签之间的差距。使用了 Cross Entropy Loss（交叉熵损失），这是分类任务中常用的损失函数，用于优化模型参数，使预测结果更接近真实标签。</li></ul><p><strong>三种情况下保存权重：</strong></p><ul><li>最近一次周期</li><li>损失最小的周期</li><li>验证准确率最高的周期</li></ul><p><strong>模型评估：</strong></p><p><strong>batch_size &#x3D; 16；loss_weight&#x3D;1.0；lr&#x3D;0.001；loss&#x3D;0.059</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308162319981.webp" alt="image-20230816231903794"></p><p>​<img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308171228867.webp" alt="image-20230817122804701"></p><blockquote><p>以第一行为例介绍混淆矩阵：</p><ul><li><strong>daisy 类别被正确预测（True Positive）：</strong> 在第一行的第一个格子中，数字 117 表示实际为 “daisy” 的样本中，被正确预测为 “daisy” 的数量。这些样本被成功地分类到了正确的类别。</li><li><strong>daisy 类别被错误预测为其他类别（False Positives）：</strong> 在第一行的其他列中的数字，例如 2、3、1、3，表示实际为 “daisy” 的样本被错误地预测为其他类别。例如，有 2 个样本被错误地预测为 “dandelion”，有 3 个样本被错误地预测为 “roses”，等等。</li><li><strong>daisy 类别的召回率（Recall）：</strong> 召回率表示实际属于某个类别的样本中，被模型预测为该类别的比例。在这里，召回率可以计算为 (117 &#x2F; (117 + 2 + 3 + 1 + 3)) &#x3D; 0.9286，即约 92.86%。这表示模型对于实际为 “daisy” 的样本中，有约 92.86% 被成功预测为 “daisy”。</li><li><strong>daisy 类别的精确率（Precision）：</strong> 精确率表示模型预测为某个类别的样本中，实际属于该类别的比例。在这里，精确率可以计算为 (117 &#x2F; (117 + 2 + 3 + 1 + 3)) &#x3D; 0.8931，即约 89.31%。这表示在模型预测为 “daisy” 的样本中，有约 89.31% 真正属于 “daisy” 类别。</li><li><strong>daisy 类别的 F1 分数：</strong> F1 分数是精确率和召回率的调和平均值，可以综合考虑模型的准确性和覆盖率。在这里，您的数据没有提供 “daisy” 类别的精确率和召回率，因此无法计算 F1 分数。</li></ul></blockquote><hr><p><strong>batch_size &#x3D; 16；loss_weight&#x3D;0.9；lr&#x3D;0.001；loss&#x3D;0.053</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308171226672.webp" alt="image-20230817122643492"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308171227745.webp" alt="image-20230817122731555"></p><hr><p><strong>batch_size &#x3D; 16；loss_weight&#x3D;0.9；lr&#x3D;0.0003；loss&#x3D;0.0040</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308171310185.webp" alt="image-20230817131038989"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308171312541.webp" alt="image-20230817131200362"></p><hr><ol><li><strong>数据增强策略的添加：</strong> 代码引入了一个名为 <code>policies</code> 的列表，其中包含了多种不同的数据增强策略。这些策略是一系列数据增强操作的组合，将按顺序应用于训练图像。第一段代码没有明确包含这种策略，可能需要在代码中添加数据增强操作。</li><li><strong>数据预处理策略的不同：</strong> 第二段代码中的数据预处理策略与第一段代码不同。第一段代码中，训练数据的预处理包括随机裁剪、随机翻转、标准化等。而第二段代码中，使用了一系列复杂的数据增强操作，例如 Posterize、Rotate、Solarize 等。这些操作的目的是提高模型的鲁棒性和泛化能力。</li></ol><p>更改后的优点：</p><ol><li><strong>增强数据多样性：</strong>数据增强策略更加丰富多样，涵盖了多种增强操作。这可以帮助模型在训练过程中更好地适应不同的变化和场景，从而提高模型的泛化能力。</li><li><strong>提高模型鲁棒性：</strong> 复杂的数据增强操作，如 Solarize、AutoContrast 等，可以在一定程度上模拟现实世界中的异常情况，从而使模型更具鲁棒性，能够更好地处理异常数据。</li><li><strong>减少过拟合风险：</strong> 数据增强可以有效减少过拟合风险，因为它引入了更多的变化和噪声，使得模型不仅仅学习训练集中的特定样本。</li><li><strong>减少数据不平衡影响：</strong> 一些增强操作可以平衡不同类别之间的样本数量，从而减少因类别不平衡导致的模型偏见。</li></ol><p>​        总体而言，通过引入更丰富的数据增强操作，可以提高模型的性能和泛化能力，使其在不同情况下表现得更好。然而，增强操作的选择和配置需要谨慎考虑，因为过多或不恰当的增强操作可能会影响训练稳定性和效果。</p><p><strong>batch_size &#x3D; 16；loss_weight&#x3D;1.0；lr&#x3D;0.001；loss&#x3D;0.133</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308171357536.webp" alt="image-20230817135723285"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308171359328.webp" alt="image-20230817135908146"></p><hr><p><strong>batch_size &#x3D; 32；loss_weight&#x3D;1.0；lr&#x3D;0.001；loss&#x3D;0.080</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308171817878.webp" alt="image-20230817181654647"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308171819853.webp" alt="image-20230817181920681"></p><h2 id="2、mobilenet-v2"><a href="#2、mobilenet-v2" class="headerlink" title="2、mobilenet_v2"></a>2、mobilenet_v2</h2><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308171906213.webp" alt="image-20230817190617893"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308171909695.webp" alt="image-20230817190901400"></p><p>批量图片检测</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308181029513.webp" alt="image-20230818102906307"></p><h2 id="3、VGG11"><a href="#3、VGG11" class="headerlink" title="3、VGG11"></a>3、VGG11</h2><p>​</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">主要不同在于 `norm_cfg` 参数。在第一个示例中，使用了批归一化（BN）作为规范化层，而在第二个示例中没有使用任何规范化层。批归一化可以帮助网络更快地训练，提高模型的稳定性和收敛性。没有使用规范化层可能会导致训练过程较慢，收敛较慢。</span></span><br><span class="line"><span class="string">两个示例都构建了一个具有11层深度的VGG主干网络，用于分类任务，并指定了相同的类别数量。不同之处在于是否使用批归一化作为规范化层。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><strong>epoches&#x3D;100</strong></p><p><strong>batch_size &#x3D; 16；num_workers &#x3D; 2；loss_weight&#x3D;1.0；lr&#x3D;0.1*16&#x2F;256 ；loss&#x3D;0.051</strong></p><p>预训练权重：<strong>vgg11_batch256_imagenet_20210208-4271cd6c</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308181055345.webp" alt="image-20230818105554203"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308181154012.webp" alt="image-20230818115440746"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308181156758.webp" alt="image-20230818115602491"></p><hr><p><code>norm_cfg=dict(type=&#39;BN&#39;)</code>：指定了使用批归一化（Batch Normalization）作为规范化层。</p><p><strong>batch_size &#x3D; 16；num_workers &#x3D; 2；loss_weight&#x3D;1.0；lr&#x3D;0.1*16&#x2F;256 ；loss&#x3D;0.046</strong></p><p>预训练权重：<strong>vgg11_bn_batch256_imagenet_20210207-f244902c.pth</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308181312688.webp" alt="image-20230818131242421"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308181314878.webp" alt="image-20230818131404573"></p><h2 id="4、Resnet"><a href="#4、Resnet" class="headerlink" title="4、Resnet"></a>4、Resnet</h2><h3 id="Resnet18"><a href="#Resnet18" class="headerlink" title="Resnet18"></a>Resnet18</h3><p><strong>epoches&#x3D;100</strong></p><p><strong>batch_size &#x3D; 16；num_workers &#x3D; 2；loss_weight&#x3D;1.0；lr&#x3D;0.1*16&#x2F;256 ；loss&#x3D;0.133</strong></p><p>预训练权重：<strong>resnet18_8xb32_in1k_20210831-fbbb1da6.pth</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308181705618.webp" alt="image-20230818170518446"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308181757520.webp" alt="image-20230818175735297"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308181759064.webp" alt="image-20230818175913802"></p><hr><p><strong>batch_size &#x3D; 8；num_workers &#x3D; 2；loss_weight&#x3D;1.0；lr&#x3D;0.1*8&#x2F;256 ；loss&#x3D;0.163</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308191107220.webp" alt="image-20230819110657946"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308191108065.webp" alt="image-20230819110828762"></p><h3 id="Renet34"><a href="#Renet34" class="headerlink" title="Renet34"></a>Renet34</h3><p>预训练权重：<strong>resnet34_8xb32_in1k_20210831-f257d4e6.pth</strong></p><p><strong>batch_size &#x3D; 16；num_workers &#x3D; 2；loss_weight&#x3D;1.0；lr&#x3D;0.1*16&#x2F;256 ；loss&#x3D;0.122</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308191124185.webp" alt="image-20230819112428988"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308191222114.webp" alt="image-20230819122207852"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308191223392.webp" alt="image-20230819122314098"></p><h2 id="5、ShuffleNet"><a href="#5、ShuffleNet" class="headerlink" title="5、ShuffleNet"></a>5、ShuffleNet</h2><h3 id="ShuffleNetV1"><a href="#ShuffleNetV1" class="headerlink" title="ShuffleNetV1"></a>ShuffleNetV1</h3><p>预训练权重：<strong>shufflenet_v1_batch1024_imagenet_20200804-5d6cec73 .pth</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308191335390.webp" alt="image-20230819133512216"></p><p><strong>batch_size &#x3D; 16；num_workers &#x3D; 2；loss_weight&#x3D;1.0；lr&#x3D;0.5*16&#x2F;256 ；loss&#x3D;0.044</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308191429702.webp" alt="image-20230819142944418"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308191430293.webp" alt="image-20230819143054972"></p><hr><h3 id="ShuffleNetV2"><a href="#ShuffleNetV2" class="headerlink" title="ShuffleNetV2"></a>ShuffleNetV2</h3><p>预训练权重：<strong>shufflenet_v2_batch1024_imagenet_20200812-5bf4721e.pth</strong></p><p><strong>batch_size &#x3D; 32；num_workers &#x3D; 4；loss_weight&#x3D;1.0；lr&#x3D;0.5*32&#x2F;256 ；loss&#x3D;0.0</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308191647044.webp" alt="image-20230819164730799"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308191648317.webp" alt="image-20230819164840103"></p>]]></content>
      
      
      <categories>
          
          <category> Image Classification </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Image Classification </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>模型的评估</title>
      <link href="/posts/29149/"/>
      <url>/posts/29149/</url>
      
        <content type="html"><![CDATA[<h1 id="下一步"><a href="#下一步" class="headerlink" title="下一步"></a><p align="center">下一步</p></h1><h2 id="模型诊断"><a href="#模型诊断" class="headerlink" title="模型诊断"></a>模型诊断</h2><p>在机器学习中，模型诊断是指通过分析模型的性能、预测结果以及其他相关指标来评估模型的质量和表现。这有助于发现模型中的问题、改进模型并了解其如何作出预测。以下是一些常见的机器学习诊断方法和技术：</p><ol><li><strong>性能指标分析</strong>：分析模型的性能指标，如准确率、精确率、召回率、F1分数等，以了解模型在不同类别上的表现如何。</li><li><strong>学习曲线分析</strong>：绘制模型在训练集和验证集上的学习曲线，以检查模型是否过拟合或欠拟合。</li><li><strong>特征重要性分析</strong>：通过分析模型所学习的特征权重，可以了解哪些特征对模型的预测贡献较大。</li><li><strong>错误分析</strong>：分析模型在预测中犯错的情况，了解模型常见的错误类型和原因。</li><li><strong>可视化分析</strong>：利用可视化工具展示模型的预测结果、决策边界等，帮助理解模型的工作原理。</li><li><strong>交叉验证</strong>：通过交叉验证方法来估计模型在未见数据上的性能，以避免过度拟合。</li><li><strong>模型比较</strong>：将不同模型的性能进行比较，以确定哪个模型在特定任务上表现最佳。</li><li><strong>超参数调整</strong>：调整模型的超参数，例如学习率、正则化参数等，以优化模型的性能。</li><li><strong>集成方法分析</strong>：分析集成方法（如随机森林、梯度提升等）的预测结果，了解它们如何结合多个基模型。</li><li><strong>时间序列分析</strong>：对于时间序列数据，可以分析模型在不同时间点上的预测表现，探索模型对趋势和季节性的捕捉能力。</li></ol><p>总之，机器学习诊断是一个多方面的过程，涉及对模型、数据和结果的深入分析，以便更好地理解模型的行为并做出必要的改进。</p><h2 id="模型评估"><a href="#模型评估" class="headerlink" title="模型评估"></a>模型评估</h2><ul><li><p>获取一个数据集并将其分为<strong>训练集</strong>和<strong>测试集</strong>，可以系统的评估学习成果如何。</p></li><li><p>测试集和训练集的均方误差。（不包括正则化项）通常对计算机有用的是训练误差，它是衡量学习算法在训练集上的表现。</p></li></ul><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309072026399.webp" alt="image-20230907202650328" style="zoom: 50%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309072035534.webp" alt="image-20230907203521249" style="zoom: 50%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309072104582.webp" alt="image-20230907210404387" style="zoom:67%;" /><pre><code>    ``可以在测试集中计算**y_hat**不等于测试集中实际标签的示例分数。``</code></pre><h2 id="模型选择，交叉评估验证"><a href="#模型选择，交叉评估验证" class="headerlink" title="模型选择，交叉评估验证"></a>模型选择，交叉评估验证</h2><p>测试不同的阶数，比较   <em><strong>J_test</strong></em>   大小，得到性能好坏。但<code>**有缺陷。**</code>可能是乐观估计。</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309102109004.webp" alt="image-20230910210906708" style="zoom: 50%;" /><p>可以将数据分为三个不同的子集：训练集、<strong>交叉验证集</strong>、测试集、</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309102115905.webp" alt="image-20230910211506635" style="zoom: 50%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309102119998.webp" alt="image-20230910211953702" style="zoom:50%;" /><ul><li><p>通常，不包括正则化项。中间这项除了被称为<strong>交叉验证错误</strong>外，通常也简称为<strong>验证错误</strong>。有了这些标准，就可以进行模型选择。</p></li><li><p>在<strong>交叉验证集上</strong>评估这些参数，选择   <em><strong>J_cv</strong></em>  最小的模型。</p></li><li><p>最后，如果想要获取<strong>泛化误差</strong>，再使用测试集计算   <em><strong>J_test</strong></em>   进行操作。</p></li><li><p>相当于两个测试集，cv用来判断项数，测试集用来判断误差。</p><p>​        <code>可以把训练集，验证集合，测试集合想成平时作业，月考，期末考，当你做了作业之后，通过月考成绩去调整平时作业的参数，最后通过期末考测试你这个学习成绩怎么样/</code></p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309102211376.webp" alt="image-20230910221121073" style="zoom:50%;" /></li></ul><p>它可以自动做出决定，例如为线性回归模型选择什么阶多项式。也可为其他类型的模型进行选择。例如下面的神经网络结构：手写数字模型。</p><p>如下为一些不同大小的神经网络，可以使用   <em><strong>J_cv</strong></em>  评估神经网络性能，这是分类问题，最常见的选择是将其计算为<strong>算法错误分类的交叉验证示例的分数。</strong></p><p>使用三个模型进行计算，然后取交叉验证误差最低的模型。<strong>如果想要计算泛化误差，</strong>则使用测试集来评估选择的神经网络的性能。</p><p><code>只有在选出一个模型作为最终模型之后。才可以在测试集上进行评估。选择模型或学习算法的过程并不需要查看测试集。</code></p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309102232182.webp" alt="image-20230910223223741" style="zoom:50%;" /><p>交叉验证（Cross-Validation）是一种用于评估机器学习模型性能和确定模型泛化能力的统计技术。它的主要目的是对模型进行客观的评估，以避免过拟合或欠拟合。在交叉验证过程中，数据集被分为训练集和测试集，模型多次训练和测试，以获得对模型性能的更稳健估计。</p><p>常见的交叉验证方法包括：</p><ol><li><strong>K折交叉验证（K-Fold Cross-Validation）</strong>：<ul><li>将数据集分为K个子集，其中K-1个子集用于训练模型，剩下的一个用于测试模型。这个过程重复K次，以确保每个子集都曾被用作测试集。</li><li>平均K次测试的结果，以获得模型的最终性能评估。</li></ul></li><li><strong>留一法交叉验证（Leave-One-Out Cross-Validation，LOOCV）</strong>：<ul><li>对于每个样本，使用除了该样本之外的所有其他样本来训练模型，然后用该样本来测试模型。</li><li>这个过程重复N次，其中N是数据集的样本数量。</li><li>LOOCV通常提供了更准确的性能评估，但计算成本较高，因为需要训练和测试多次。</li></ul></li><li><strong>留P法交叉验证（Leave-P-Out Cross-Validation）</strong>：<ul><li>类似于LOOCV，但是每次留下P个样本作为测试集，而不是一个。</li></ul></li><li><strong>随机划分交叉验证（Random Split Cross-Validation）</strong>：<ul><li>随机将数据集分为训练集和测试集的多个子集，然后多次训练和测试模型。</li><li>这种方法适用于大型数据集。</li></ul></li></ol><p>交叉验证有助于评估模型的性能，检测模型是否过度拟合或欠拟合，并提供关于模型的性能稳健性的信息。在模型选择、参数调整和特征选择过程中，交叉验证是一种重要的工具，可以帮助选择最适合数据的模型和参数。</p><h2 id="通过偏差的方法进行诊断"><a href="#通过偏差的方法进行诊断" class="headerlink" title="通过偏差的方法进行诊断"></a>通过偏差的方法进行诊断</h2><ul><li>高偏差（欠拟合）</li><li>高方差（过拟合）</li><li>诊断算法是否具有高偏差或者高方差的方法是查看算法在训练集和交叉验证集上的性能。看   <em><strong>J_cv</strong></em> 和   <em><strong>J_train</strong></em>   的大小。</li></ul><blockquote><p>中间这个图，   <em><strong>J_train</strong></em>  不太高表明它没有高偏差问题，而   <em><strong>J_cv</strong></em>  并不比   <em><strong>J_train</strong></em>  差很多，这表明它也没有高方差问题。</p></blockquote><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309111540688.webp" alt="image-20230911154042487" style="zoom: 50%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309111643897.webp" alt="image-20230911164308628" style="zoom: 50%;" /><blockquote><ul><li>学习算法有高偏差或者欠拟合，关键是  <em><strong>J_train</strong></em>  是否高，如图的左部分，此时  <em><strong>J_cv</strong></em>  与   <em><strong>J_train</strong></em>  很接近。</li><li>高方差或者过拟合，  <em><strong>J_cv</strong></em>  远大于   <em><strong>J_train</strong></em>  ，同时   <em><strong>J_train</strong></em>  可能很低。</li></ul><p>训练神经网络时，<strong>有时</strong>也会看到高偏差和高方差。   <em><strong>J_train</strong></em>  高且   <em><strong>J_cv</strong></em>  远大于   <em><strong>J_train</strong></em>  。可能如小图部分所示，部分数据过拟合，部分欠拟合。</p></blockquote><p>​        <strong><code>高阶多项式在训练次数不够的时候就会既有高偏差和高方差</code></strong></p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309111650909.webp" alt="image-20230911165022631" style="zoom: 50%;" /><p>正则化如何影响学习算法的偏差和方差？更好的理解何时应该使用正则化。</p><h2 id="正则化参数如何影响偏差、方差？"><a href="#正则化参数如何影响偏差、方差？" class="headerlink" title="正则化参数如何影响偏差、方差？"></a>正则化参数如何影响偏差、方差？</h2><p><code>目的：使用交叉验证来为选择一个适合的正则化参数   ***λ***   </code> </p><p>首先回顾一下正则化参数对模型的影响，以及此时对应的  <em><strong>J_train</strong></em>  和  <em><strong>J_cv</strong></em>  的情况。</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309121552461.webp" alt="image-20230912155219136" style="zoom:50%;" /><p>​        按照之前的方法进行尝试   <em><strong>λ</strong></em>   取不同值时，模型参数以及  <em><strong>J_cv</strong></em>  的大小。</p><blockquote><p>左侧过拟合，右侧欠拟合。与上个图像刚好对称。</p></blockquote> <img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309121611475.webp" alt="image-20230912161149154" style="zoom:50%;" /><h2 id="制定一个用于性能评估的基准"><a href="#制定一个用于性能评估的基准" class="headerlink" title="制定一个用于性能评估的基准"></a>制定一个用于性能评估的基准</h2><ul><li><p>目的：为了判断  <em><strong>J_train</strong></em>  和  <em><strong>J_cv</strong></em>  何谓之高，何谓之低。</p></li><li><p>语音识别运行示例：查看训练误差是否远高于人的表现水平更有用。</p></li><li><p>基准性能水平指的是合理希望学习算法最终达到的误差水平。常见的方法就是衡量人类在这项任务上的表现。也可以根据 <em><strong>baseline</strong></em> 建立基准。</p></li></ul><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309121634778.webp" alt="image-20230912163424534"></p><blockquote><p>比较 <em><strong>baseline performance</strong></em> 与  <em><strong>J_train</strong></em>  之间的差距，如果效果差，可能是高偏差。继续比较  <em><strong>J_train</strong></em>   与  <em><strong>J_cv</strong></em>  之间的差距，如果差距很大，可能遇到了高方差问题。</p></blockquote><h2 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h2><p>在机器学习中，学习曲线（Learning Curve）是一种可视化工具，用于帮助我们理解模型的性能如何随着训练数据量的增加而变化。学习曲线通常显示了训练数据大小与模型的性能之间的关系。</p><p>学习曲线一般包括两个主要方面的信息：</p><ol><li><strong>训练集性能</strong>：这是指模型在用于训练的数据上的性能表现。通常，随着训练数据量的增加，模型在训练集上的性能会逐渐提高。这是因为更多的数据有助于模型更好地学习数据的模式和特征。训练集性能通常以训练误差（训练集上的损失）来衡量。</li><li><strong>验证集性能</strong>：这是指模型在用于验证的独立数据集上的性能表现。验证集通常用于评估模型的泛化能力，即模型对新数据的适应能力。随着训练数据量的增加，验证集性能可能会出现以下情况：<ul><li>随着数据量的增加，验证集性能逐渐提高，这表明模型的泛化能力在改善。</li><li>随着数据量的增加，验证集性能趋于稳定，这可能表示模型已经充分学习了可用数据的模式。</li><li>验证集性能在训练数据量增加后开始下降，这可能是由于过拟合（Overfitting）导致的，即模型在训练集上表现很好，但在验证集上表现较差。</li></ul></li></ol><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309121757190.webp" alt="image-20230912175728901" style="zoom: 50%;" /><p>​        <code>如果算法具有高偏差，如果仅仅添加更多的训练数据，不会降低错误率。</code>首先得拟合好，其次增加数据集数量才有用。</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309121807204.webp" alt="image-20230912180725889" style="zoom: 50%;" /><p>​        高方差和高偏差不同，增加数据集大小可以有助于改善模型性能。</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309121817233.webp" alt="image-20230912181714954" style="zoom: 50%;" /><h2 id="偏差和方差如何帮助决定下一步要做什么？"><a href="#偏差和方差如何帮助决定下一步要做什么？" class="headerlink" title="偏差和方差如何帮助决定下一步要做什么？"></a>偏差和方差如何帮助决定下一步要做什么？</h2><p>​        以下描述的很清楚了：</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309121949024.webp" alt="image-20230912194907612" style="zoom: 50%;" /><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309121955743.webp" alt="image-20230912195521360" style="zoom:50%;" /><h2 id="神经网络中的方差和偏差"><a href="#神经网络中的方差和偏差" class="headerlink" title="神经网络中的方差和偏差"></a>神经网络中的方差和偏差</h2><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309122006372.webp" alt="image-20230912200611174" style="zoom:50%;" /><p>平衡，存在于万物之间。神经网络是我们摆脱了必须权衡偏差和方差的困境。如果神经网络足够大，几乎可以很好地适应训练集。<strong>如下图是神经网络处理偏差的具体方法，也是神经网络如此强大的原因。</strong></p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309122015567.webp" alt="image-20230912201550334" style="zoom:50%;" /><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">精心涉及的正则化大型网络通常与较小的神经网络一样好甚至更好（这里指的是正则化后的大型神经网络可能没有高方差的问题）。大的神经网络使得过拟合的风险增加，适当的正则化使得神经网络变得卓越，但会使计算量增加。</span><br></pre></td></tr></table></figure><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202309122032797.webp" alt="image-20230912203210570" style="zoom:50%;" /><h2 id="Kappa"><a href="#Kappa" class="headerlink" title="Kappa"></a>Kappa</h2><p>“Kappa”（κ，也称为 Cohen’s Kappa）是一种用于评估分类器性能和度量分类一致性的统计指标。它通常用于评估分类问题中的分类准确性，并考虑了分类器的性能与随机分类之间的差异。</p><p>Kappa 给出了分类器的性能与随机分类之间的一致性程度，其值范围在 -1 到 1 之间，其中：</p><ul><li>Kappa &#x3D; 1 表示完美一致，分类器的性能与随机分类没有差异。</li><li>Kappa &#x3D; 0 表示分类器的性能等同于随机分类。</li><li>Kappa &lt; 0 表示分类器性能比随机分类差。</li></ul><p>Kappa 的计算基于分类器的混淆矩阵，该矩阵显示了分类器的真阳性、真阴性、假阳性和假阴性。Kappa 考虑了观察到的一致性与预期的一致性之间的差异，同时考虑了随机误差。这使得 Kappa 成为一种在分类不平衡或随机误差较大的情况下，用于评估分类器性能的有用工具。</p><p>Kappa 常常用于医学诊断、自然语言处理、机器学习分类问题和其他领域，以度量分类器的性能。然而，它并不适用于回归问题，因为它是一种分类性能的度量标准。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Adam高级优化算法、反向传播</title>
      <link href="/posts/29148/"/>
      <url>/posts/29148/</url>
      
        <content type="html"><![CDATA[<h1 id="优化方法"><a href="#优化方法" class="headerlink" title="优化方法"></a><p align="center">优化方法</p></h1><h2 id="高级优化方法"><a href="#高级优化方法" class="headerlink" title="高级优化方法"></a>高级优化方法</h2><p>​<code>比梯度下降更快的训练神经网络</code></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308131725457.webp" alt="image-20230813172540182"></p><p>​Adam（Adaptive Moment Estimation）是一种用于优化神经网络和深度学习模型训练的优化算法。它结合了随机梯度下降（SGD）的优点和<strong>自适应学习率</strong>方法，旨在提供更快的收敛速度和更稳定的训练过程。</p><p>​Adam算法的工作原理如下：</p><ol><li><strong>梯度计算</strong>：在每个训练批次中，计算模型参数关于损失函数的梯度，以了解参数如何影响损失。</li><li><strong>一阶矩估计（均值）</strong>：Adam维护了每个模型参数的指数移动平均梯度，称为一阶矩估计或梯度的均值。这有助于捕捉梯度的整体趋势。</li><li><strong>二阶矩估计（方差）</strong>：类似地，Adam还维护了每个参数的指数移动平均平方梯度，称为二阶矩估计或梯度的方差。这有助于估计参数更新的变化幅度。</li><li><strong>学习率调整</strong>：Adam根据一阶矩估计和二阶矩估计对每个参数的更新幅度进行调整。学习率被自适应地缩放，从而在不同参数和时间步骤上提供更好的平衡。</li><li><strong>参数更新</strong>：使用调整后的学习率，Adam更新模型参数，以减少损失函数。</li></ol><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308131732346.webp" alt="image-20230813173225176"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308131733345.webp" alt="image-20230813173310075"></p><p>​<strong>选择Adam优化器：</strong> 在实例化神经网络模型时，选择Adam作为优化器。这可以在许多深度学习框架中通过一行代码来完成。</p><h3 id="其他的网络层类型"><a href="#其他的网络层类型" class="headerlink" title="其他的网络层类型"></a>其他的网络层类型</h3><h3 id="密集层"><a href="#密集层" class="headerlink" title="密集层"></a>密集层</h3><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308132000365.webp" alt="image-20230813200009101" style="zoom:67%;" /><p>密集层（Dense Layer），也被称为全连接层（Fully Connected Layer），是神经网络中的一个基本构建模块，尤其在前馈神经网络和人工神经网络中常见。它是一种层，其中该层中的每个神经元（或节点）与前一层和后一层中的每个神经元都相连接。</p><p>在密集层中，每个神经元从前一层的所有神经元接收输入，并产生一个输出，该输出传递给下一层中的所有神经元。密集层中每个神经元的输出是通过对其输入进行加权求和，然后应用激活函数来计算的。</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">输出 = 激活函数(加权求和(输入) + 偏置)</span><br></pre></td></tr></table></figure><p>密集层中神经元的数量和激活函数的选择通常由神经网络的架构和特定问题的要求决定。通过训练过程中调整权重和偏置，密集层用于学习数据中的复杂模式和关系。密集层的参数（权重和偏置）通过梯度下降等优化技术来学习。</p><p>在神经网络架构中，密集层通常与其他类型的层一起堆叠，例如卷积层（用于处理像素排列的数据，如图像）或循环层（用于处理序列数据）。这种层类型在将输入数据转换为用于进行预测或分类的高级表示方面起着关键作用。</p><h3 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h3><p>卷积层（Convolutional Layer）是神经网络中的一种重要层，主要用于处理具有<strong>网格状结构（如图像）</strong>的数据。卷积层通过使用卷积操作来从输入数据中提取特征，并且在图像处理和计算机视觉任务中取得了巨大的成功。</p><p>卷积操作是一种数学运算，通过在输入数据上滑动一个称为<strong>卷积核（或滤波器）</strong>的小窗口，将窗口中的数据与<strong>卷积核的权重</strong>进行逐元素相乘，然后将结果相加，最终生成输出的一个值。通过在输入数据的不同位置应用卷积操作，卷积层可以捕获输入数据的局部特征，如边缘、纹理等。</p><blockquote><p>卷积层的主要特点包括：</p><ol><li><strong>权值共享</strong>：卷积层中的卷积核在整个输入数据上共享相同的权重。这导致卷积层具有对平移不变性，即模型可以识别相同特征的不同位置。</li><li><strong>局部连接</strong>：每个卷积核仅与输入数据的一小部分区域连接，从而减少了参数数量，降低了计算成本。</li><li><strong>池化层</strong>：卷积层之后通常会加入池化层，用于减少特征图的尺寸，并增强模型对平移和尺度变化的鲁棒性。</li><li><strong>多通道输入与输出</strong>：卷积层可以处理多通道的输入数据（例如彩色图像的RGB通道），并且可以产生多个输出通道的特征图。</li></ol><p>卷积神经网络（CNNs）是使用卷积层作为主要组件的深度学习模型，在图像识别、物体检测、语义分割等计算机视觉任务中表现出色。通过层层堆叠卷积层、池化层和全连接层，CNNs能够学习到数据的多层次抽象特征，从而实现高效的特征提取和模式识别。</p></blockquote><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308132007771.webp" alt="image-20230813200725547"></p><p>​每个神经元只查看部分像素，在卷积神经网络（CNN）中，让神经元只查看部分像素而不是全部像素有几个重要的原因：</p><ol><li><strong>减少参数数量，加快计算速度：</strong> 图像通常非常大，如果每个神经元都连接到整个图像的每个像素，网络的参数数量会变得极其庞大，导致计算和内存开销巨大。通过让神经元只查看部分像素，可以大大减少参数数量，从而使网络更轻量化且更容易训练，也不太容易过拟合。</li><li><strong>局部特征提取：</strong> 图像中的信息通常是局部相关的，即相邻区域的像素之间存在相关性。通过让神经元只查看部分像素，卷积神经网络可以更有效地捕获图像的局部特征，如边缘、纹理等。这有助于提取更有意义的特征并降低不相关信息的影响。</li><li><strong>平移不变性：</strong> 图像中的特征通常在不同位置都有出现，但位置可能不同。通过使用卷积操作，卷积神经网络可以实现平移不变性，即学习到的特征在图像中的不同位置都能够被识别，而不需要重新训练。</li><li><strong>稀疏连接：</strong> 让神经元只连接到局部区域的像素可以视为一种稀疏连接。稀疏连接有助于减少计算复杂性，使神经网络能够更高效地处理大规模输入数据。</li></ol><p>​<strong>总之，让神经元只查看部分像素而不是全部像素是为了降低计算和内存开销、捕获局部特征、实现平移不变性以及提高网络的有效性。这些策略在卷积神经网络的设计中起到了至关重要的作用，使其能够更好地处理图像数据并在计算机视觉任务中取得优异的性能。</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/image-20230813201436920.webp" alt="image-20230813201436920"></p><p>​使用卷积神经网络（CNN）进行心电图（EKG信号）的分类是一个常见的任务，可以用于自动识别不同心脏疾病、心律失常等。</p><p>​第一个卷积层的神经元都是只查看部分EKG信号，隐藏层第二层也可以是卷积层，同理只查看部分激活，最后是一个sigmoid单元的输出层，以便对是否有心脏病进行二分类。</p><h3 id="反向传播如何计算导数？（optional）"><a href="#反向传播如何计算导数？（optional）" class="headerlink" title="反向传播如何计算导数？（optional）"></a>反向传播如何计算导数？（optional）</h3><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308141635967.webp" alt="image-20230814163544710"></p><p>​我们得出导数的<strong>非正式定义</strong>，即每当 <em><strong>w</strong></em> 上升一个微小的<em><strong>Epsilon</strong></em>时，就会导致 <em><strong>w</strong></em> 的 <em><strong>」</strong></em>上升 <em><strong>k</strong></em> 倍 <em><strong>Epsilon</strong></em>。</p><p><em><strong>k</strong></em>  即为在此处的导数。</p><h4 id="计算图"><a href="#计算图" class="headerlink" title="计算图"></a>计算图</h4><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308141710696.webp" alt="image-20230814171013485"></p><p>前向传播是从左到右计算，但导数的计算是从右到左，这就是 <em><strong>BP</strong></em> 反向传播。反向传播（Backpropagation）是训练神经网络的核心算法之一，用于计算损失函数关于网络权重的梯度，反向传播的关键是<strong>链式法则</strong>，它允许将网络的输出误差分解成每个权重的贡献。这允许网络根据损失的梯度调整每个权重，以便在训练数据上获得更好的预测结果。</p><blockquote><p><strong>如何理解：</strong> 当神经网络进行前向传播时，输入通过多个层传递并产生预测输出。但是，我们的目标是通过调整网络权重，使得预测输出更接近实际目标值，从而减小损失。为了做到这一点，我们需要知道每个权重对输出误差的影响有多大，以便适当地调整它们。</p><p>链式法则在这里的作用是，它允许我们将输出误差从输出层回传到每一层的权重。具体而言，对于每个权重，<strong>我们可以计算输出误差关于该权重的偏导数，即该权重对误差的影响有多大。通过乘以这个偏导数，我们可以知道如何微调每个权重以减小输出误差。</strong>(****)</p><p>这个过程可以被看作是将整个损失函数中的变化传递回到每个神经元的激活值和权重，从而使得网络能够逐步调整自己以最小化误差。这就是反向传播的核心思想：<code>通过链式法则，将误差从输出层传播回到网络的各个层，以便计算梯度并进行权重更新，最终使得网络能够更好地拟合训练数据，提高预测能力。</code></p></blockquote><p>​反向传播计算导数的原理是：如上图   <em><strong>d</strong></em>   变化微小，如  <em><strong>Epsilon</strong></em>  ， <em><strong>」</strong></em>如何变化？</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308141732319.webp" alt="image-20230814173256090"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308141735670.webp" alt="image-20230814173525449"></p><blockquote><p>以下是为什么反向传播适合计算导数的几个关键原因：</p><ol><li><strong>链式法则的应用：</strong> 反向传播基于链式法则，这是一种将复合函数的导数分解为各个组成部分导数的方法。在神经网络中，每一层的输出都是由前一层的输出和权重相乘得到的，通过逐层应用链式法则，我们可以将整个网络的导数分解为各层之间的局部导数。</li><li><strong>计算效率：</strong> 反向传播通过有效地传播误差信号和局部梯度，从输出层向输入层逐层计算梯度。这种计算的顺序与前向传播的顺序相反，因此称为“反向”传播。这种逐层计算梯度的方式使得计算效率更高，尤其在深层网络中。</li><li><strong>复用中间结果：</strong> 在前向传播过程中，神经元的激活值和权重相乘的中间结果被保留下来，以便在反向传播时使用。这样，可以避免重复计算，提高计算效率。</li><li><strong>自动计算：</strong> 反向传播允许计算机自动地计算网络中各个层的导数，而无需手动计算。这对于深层网络和复杂的函数非常有用，因为手动计算导数可能会非常繁琐和容易出错。</li></ol><p>总之，反向传播利用了链式法则，将导数的计算分解为网络的不同部分，从而实现高效的梯度计算。这使得神经网络能够在训练过程中自动调整权重以最小化损失函数，从而提高模型的性能。</p></blockquote><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308141742473.webp" alt="image-20230814174208256"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多分类问题</title>
      <link href="/posts/29147/"/>
      <url>/posts/29147/</url>
      
        <content type="html"><![CDATA[<h1 id="多分类"><a href="#多分类" class="headerlink" title="多分类"></a><p align="center">多分类</p></h1><h2 id="多分类-1"><a href="#多分类-1" class="headerlink" title="多分类"></a>多分类</h2><h3 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a><strong>Softmax</strong></h3><p>​（软最大值）是一种在机器学习和神经网络中经常使用的数学函数，特别是在分类任务的上下文中。<strong>它用于将一组实数向量转换为概率分布</strong>，其中向量中的每个元素都被转换为介于 0 和 1 之间的值，表示该元素是最可能的选择的概率。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308152122898.webp" alt="image-20230815212231672"></p><p>​Softmax 函数以任意实数向量作为输入，并计算向量中每个元素 <em>x</em><sub> <em>i</em> </sub> 的如下值：<br>$$<br>softmax(x_i)&#x3D;\frac {e^{x_i}}  {∑_{j&#x3D;1}^N e^{x_j}}<br>$$<br>​<img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308152133569.webp" alt="image-20230815213340440"></p><p>这里：</p><ul><li><em>N</em> 是输入向量中的元素总数。</li><li><em>e</em> 是自然对数的底数，即欧拉数。</li><li><em>x</em><sub> <em>i</em> </sub> 是输入向量的第 <em>i</em> 个元素。</li></ul><p>​Softmax 函数对输入向量的每个元素进行指数化，然后通过将每个指数化值除以向量中所有指数化值的和来进行归一化。这种归一化确保输出值在 [0, 1] 范围内，并且它们的总和为 1，形成一个有效的概率分布。</p><p>​Softmax 经常用于神经网络的输出层，用于多类分类任务。给定网络产生的原始分数（logits），Softmax 函数将这些分数转换为不同类别上的概率分布，从而更容易解释和比较模型的预测结果。</p><p>​从数学上讲，Softmax 函数放大了输入向量中元素之间的差异，给予较大值更多的权重，抑制较小值。因此，输入向量中的最大值将主导结果概率，成为最可能的类别选择。</p><p>​Softmax 具有一些特性：</p><ol><li>由于指数化步骤，它对异常值比较敏感。</li><li>它是单调递增函数，因此较高的输入值将对应于较高的概率。</li><li>它是可微分的，适用于使用基于梯度的优化方法来训练神经网络。</li></ol><h3 id="Cost"><a href="#Cost" class="headerlink" title="Cost"></a>Cost</h3><p>​<img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308122234613.webp" alt="image-20230812223452347"></p><p>​在机器学习和神经网络中，Softmax 通常与交叉熵损失（Cross-Entropy Loss）一起使用作为代价函数，特别是在多类别分类问题中。Softmax 用于将模型的原始分数转换为概率分布，而交叉熵损失用于衡量模型的预测与真实标签之间的差异。</p><p>​假设有一个具有 <em>C</em> 个类别的分类问题，每个类别用一个指标 <em><strong>y<sub> i </sub></strong></em> 表示，其中 <em><strong>i</strong></em> 是类别的索引。此外，假设模型的输出经过 Softmax 函数处理后得到的概率分布为 ***p<sub> i </sub>***，表示模型预测属于类别 <em><strong>p<sub> i </sub></strong></em> 的概率。</p><p>​交叉熵损失（Cross-Entropy Loss）用于衡量模型的预测与真实标签之间的差异，计算方式如下：<br>$$<br>L &#x3D; -∑_{i&#x3D;1}^{C} y_i * log(p_i)<br>$$<br><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308152135219.webp" alt="image-20230815213502096"></p><p>​这里：</p><ul><li><em><strong>y<sub> i </sub></strong></em> 是真实标签中类别 <em><strong>i</strong></em> 的指标，通常是一个 0 或 1。</li><li><em><strong>p<sub> i </sub></strong></em> 是模型预测属于类别 <em><strong>i</strong></em> 的概率，由 Softmax 函数计算得出。</li></ul><p>​交叉熵损失可以看作是模型预测分布与真实分布之间的差异的度量。在分类问题中，真实分布中只有一个类别的指标为 1，其他为 0，因此损失函数只关注模型对正确类别的预测。</p><p>​通过最小化交叉熵损失，模型将被鼓励更准确地预测样本的类别。训练过程中，优化算法（如梯度下降）会调整模型的参数，使损失逐渐减小，从而提升模型的分类性能。</p><h2 id="神经网络的Softmax输出"><a href="#神经网络的Softmax输出" class="headerlink" title="神经网络的Softmax输出"></a>神经网络的Softmax输出</h2><p>​<img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308131019403.webp" alt="image-20230813101904158"></p><p>当你在 TensorFlow 中使用 <code>softmax</code> 激活函数和 <code>SparseCategoricalCrossentropy</code> 损失函数时，你通常会按照以下步骤进行：</p><ol><li>定义模型的输出层，并在输出层使用 <code>softmax</code> 激活函数，以将原始分数转换为概率分布。</li><li>定义损失函数为 <code>SparseCategoricalCrossentropy</code>，并将 logits（原始分数）作为参数传递给它，而不需要显式地进行 softmax 转换。</li></ol><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308131023257.webp" alt="image-20230813102316988"></p><h2 id="Softmax的改进实现"><a href="#Softmax的改进实现" class="headerlink" title="Softmax的改进实现"></a>Softmax的改进实现</h2><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308152123813.webp" alt="image-20230815212344571"></p><p>​如果您将输出层的激活函数更改为线性（linear)，那么您应该在使用 <code>SparseCategoricalCrossentropy</code> 损失函数时，将参数 <code>from_logits=True</code> 设置为确保正确的损失计算。</p><p>​在神经网络中，将输出层的激活函数设置为线性意味着网络输出不再是经过 softmax 转换的概率分布，而是原始分数（logits）。这时，为了计算交叉熵损失，您需要在损失函数中执行 softmax 转换，以将 logits 转换为概率分布。</p><p>​<strong>这样做会确保在计算损失函数时，将 logits 转换为概率分布，从而使损失计算更稳定，避免数值不稳定性问题，并且可以更好地优化模型以逼近真实标签分布。</strong></p><p>​<code>**从概念上讲，两种代码做的是同一件事，但后者数字更为准确。**</code></p><hr><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308131104759.webp" alt="image-20230813110435532"></p><p>​现在只有一个细节，那就是我们现在已经将神经网络更改为使用<strong>线性激活函数</strong>而不是softmax激活函数。神经网络的最后一层不再输出 a<sub> 1</sub><del>a<sub> 10</sub>，而是 z<sub> 1</sub></del>z<sub> 10</sub> </p><h3 id="逻辑回归的改进"><a href="#逻辑回归的改进" class="headerlink" title="逻辑回归的改进:"></a>逻辑回归的改进:</h3><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308131110775.webp" alt="image-20230813111053537"></p><h2 id="多标签分类问题"><a href="#多标签分类问题" class="headerlink" title="多标签分类问题"></a>多标签分类问题</h2><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308131619390.webp" alt="image-20230813161953110"></p><p>​多标签分类是一种机器学习任务，其中算法为输入实例分配多个标签。在传统的二元分类中，一个实例被分配到两个类别中的一个（例如，垃圾邮件或非垃圾邮件）。在多标签分类中，一个实例可以与多个类别同时关联。</p><p>​<img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308131630467.webp" alt="image-20230813163012256"></p><p>​</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>神经网络的训练、激活函数的选择</title>
      <link href="/posts/29146/"/>
      <url>/posts/29146/</url>
      
        <content type="html"><![CDATA[<h1 id="训练、激活函数的选择"><a href="#训练、激活函数的选择" class="headerlink" title="训练、激活函数的选择"></a><p align="center">训练、激活函数的选择</p></h1><h2 id="1、Tensorflow实现"><a href="#1、Tensorflow实现" class="headerlink" title="1、Tensorflow实现"></a>1、Tensorflow实现</h2><ul><li><h3 id="回忆：回到识别手写数字0和1的例子："><a href="#回忆：回到识别手写数字0和1的例子：" class="headerlink" title="回忆：回到识别手写数字0和1的例子："></a>回忆：回到识别手写数字0和1的例子：</h3></li></ul><ol><li><strong>指定模型</strong>，设置隐藏层，神经网络单元，激活函数，如何计算推理；</li><li><strong>编译模型</strong>，指定损失函数（图为分类交叉熵）；</li><li><strong>训练模型</strong>，调用<code>fit</code>函数，使用指定代价函数的损失来拟合指定数据集；</li></ol><p>​<code>epochs</code>表示学习梯度下降等算法设置的<strong>步数</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308102214269.webp" alt="image-20230810221419946"></p><ul><li><h3 id="模型训练细节："><a href="#模型训练细节：" class="headerlink" title="模型训练细节："></a>模型训练细节：</h3></li></ul><ol><li>给定输入，给定参数，计算输出；</li><li>指定损失和代价；</li><li>梯度下降，最小化逻辑回归的代价函数。</li></ol><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308111050156.webp" alt="image-20230811105040880"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308111055621.webp" alt="image-20230811105550350"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308111058327.webp" alt="image-20230811105832078"></p><p>​keras中有很多损失函数，但是恐怕只有chatgpt能记得它有哪些。</p><p>​回归：MSE，均方误差</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308111104515.webp" alt="image-20230811110447328"></p><p>​TensorFlow所做的，实际上也是神经网络训练的标准，是使用一种称为反向传播（BP）的算法来计算这些偏导数项，调用<code>fit</code>函数。</p><h2 id="2、激活函数的替代方案"><a href="#2、激活函数的替代方案" class="headerlink" title="2、激活函数的替代方案"></a>2、激活函数的替代方案</h2><ul><li><h3 id="Sigmoid激活函数的替代方案"><a href="#Sigmoid激活函数的替代方案" class="headerlink" title="Sigmoid激活函数的替代方案"></a>Sigmoid激活函数的替代方案<img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308111517810.webp" alt="image-20230811151730550"></h3></li></ul><blockquote><p>线性整流函数（Rectified Linear Unit，简称<strong>ReLU</strong>）是一种常用的人工神经网络激活函数，通常用于神经网络的隐藏层。ReLU 函数定义如下：</p><p>​<strong><em>f</em>(<em>x</em>)&#x3D;max(0,<em>x</em>)</strong></p><p>其中，<em><strong>x</strong></em> 是输入值，而 <em><strong>f(x)</strong></em> 则是输出值。换句话说，当 <em><strong>x</strong></em> 大于等于零时，ReLU 函数返回 <em><strong>x</strong></em>；当 <em><strong>x</strong></em>小于零时，返回零。这就是为什么它被称为线性整流函数，因为它将负数的部分截断为零，而保留正数部分不变。</p></blockquote><ul><li><h3 id="如何选择激活函数？"><a href="#如何选择激活函数？" class="headerlink" title="如何选择激活函数？"></a>如何选择激活函数？</h3></li></ul><p>​<code>针对目标 y 选择:</code></p><ol><li>对于二分类问题，<em><strong>y</strong></em>   分为两种，可以选择   <em><strong>sigmiod</strong></em>   函数。</li><li>对于预测股票价格如何变化的问题，<em><strong>y</strong></em>   可正可负，可以选择线性激活函数。</li><li>对于预测房屋价格，<em><strong>y</strong></em>   为非负，选择   <em><strong>ReLU</strong></em>   函数。</li></ol><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308111533834.webp" alt="image-20230811153329560"></p><p>​现如今，隐藏层几乎都是用  <em><strong>ReLU</strong></em>  。</p><blockquote><p>  <em><strong>ReLU</strong></em> 在大多数情况下都是更优的选择，因为它具有更好的计算效率、训练速度和收敛性能，而且通常不容易遇到梯度消失问题。然而，  <em><strong>ReLU</strong></em> 也有一些问题，比如神经元死亡问题，可能需要通过使用其他激活函数的变体来解决。在特定情况下，如循环神经网络中，   <em><strong>sigmiod</strong></em>   仍然可能有一定的用途。最终的选择应该考虑到具体问题和网络结构的需求。</p></blockquote><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308111554152.webp" alt="image-20230811155359937"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308111603587.webp" alt="image-20230811160307343"></p><blockquote><p>将隐藏层使用 ReLU 激活函数，而输出层使用 Sigmoid 激活函数是一种常见的组合，适用于许多机器学习和深度学习任务，尤其是二元分类问题。这种组合在实际应用中很常见，有一些优点和适用场景：</p><ol><li><strong>隐藏层使用 ReLU</strong>：<ul><li>ReLU 激活函数在正值部分保持线性关系，对梯度消失问题有一定的缓解作用，因此通常用于隐藏层。</li><li>ReLU 是计算高效的激活函数，对于深层神经网络具有加速训练的效果。</li></ul></li><li><strong>输出层使用 Sigmoid</strong>：<ul><li>Sigmoid 激活函数将输出映射到 (0, 1) 的范围内，非常适用于表示概率值，尤其是二元分类问题的概率预测。</li><li>对于输出层使用 Sigmoid，可以将网络的输出解释为样本属于某一类的概率。</li></ul></li></ol></blockquote><ul><li><h3 id="为什么模型需要激活函数？"><a href="#为什么模型需要激活函数？" class="headerlink" title="为什么模型需要激活函数？"></a>为什么模型需要激活函数？</h3></li></ul><p>​需求检测示例：</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308112111767.webp" alt="image-20230811211151453"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308112112628.webp" alt="image-20230811211215382"></p><p>​线性函数的线性函数，还是线性函数</p><blockquote><p>激活函数在神经网络中扮演着重要的角色，它们引入非线性变换，使得网络能够捕捉复杂的模式和关系，从而提高网络的表达能力和性能。以下是一些关键原因，解释了为什么要使用激活函数：</p><ol><li><strong>引入非线性性</strong>： 神经网络的堆叠层本质上是一系列线性变换，如果没有激活函数，多个线性层的组合仍然只能表示线性关系。激活函数引入非线性性，使得网络可以对输入数据进行非线性变换，从而更好地捕捉数据中的复杂模式和特征。</li><li><strong>增强网络的表达能力</strong>： 激活函数允许神经网络模型更好地拟合各种不同的函数，包括非线性函数。这使得神经网络能够处理各种复杂的任务，如图像识别、自然语言处理等，从而提高网络的表达能力。</li><li><strong>解决线性组合的问题</strong>： 激活函数将输入的线性组合转化为非线性输出。这在处理数据时非常关键，因为现实世界中的数据通常是非线性的。激活函数能够让网络学习更加复杂的数据变换和模式。</li><li><strong>实现决策边界</strong>： 在分类问题中，激活函数可以帮助网络学习到适当的决策边界，从而正确地分类不同类别的样本。这对于图像分类、情感分析等任务非常重要。</li><li><strong>引入稀疏激活性</strong>： 一些激活函数（如 ReLU）可以在激活值为零时产生稀疏激活性，即部分神经元保持非激活状态。这有助于网络进行特征选择，减少冗余信息，提高模型的泛化能力。</li><li><strong>缓解梯度消失问题</strong>： 激活函数的非线性性质有助于缓解梯度消失问题。某些激活函数（如 ReLU）在正值部分具有常数梯度，有助于梯度在反向传播时保持一定的大小，避免梯度逐渐减小。</li></ol><p>综上所述，激活函数是神经网络中不可或缺的部分，它们赋予网络非线性能力，使得网络能够处理复杂的问题和数据。通过适当选择和组合激活函数，可以提高神经网络的性能、泛化能力和训练效果。</p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>前向传播、向量化神经网络</title>
      <link href="/posts/29145/"/>
      <url>/posts/29145/</url>
      
        <content type="html"><![CDATA[<h1 id="前向传播、向量化神经网络"><a href="#前向传播、向量化神经网络" class="headerlink" title="前向传播、向量化神经网络"></a><p align="center">前向传播、向量化神经网络</p></h1><h2 id="1、单个网络层上的前向传播"><a href="#1、单个网络层上的前向传播" class="headerlink" title="1、单个网络层上的前向传播"></a>1、单个网络层上的前向传播</h2><p>​阅读代码，理解内容，继续使用咖啡烘培模型</p><p>​<strong>前向传播参数随机初始化，后面进行反向传播调参修正。</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308061730483.webp" alt="image-20230806173016220"></p><blockquote><p>​w2_1 &#x3D; np.array ( [-7，8，<strong>1</strong>] )        #应该为3个元素的 1D</p><p>​               –</p><p>​a2_1 &#x3D; sigmod ( z2_1 )   # z2_1</p></blockquote><p>​这就是如何使用<code>python</code>和<code>numpy</code>实现前向传播。</p><h2 id="2、前向传播的一般实现"><a href="#2、前向传播的一般实现" class="headerlink" title="2、前向传播的一般实现"></a>2、前向传播的一般实现</h2><p>​<img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308062044889.webp" alt="image-20230806204441625"></p><blockquote><ol><li><p><code>units = W.shape[1]</code>: 获取权重矩阵 <code>W</code> 的输出维度（神经元数量），保存在变量 <code>units</code> 中。</p><p>通过将 <code>w.shape[1]</code> 赋值给 <code>units</code>，你可以根据权重矩阵 <code>w</code> 的形状自动设置神经网络层的输出维度，使其与权重矩阵的列数相匹配。这样在构建神经网络时就不需要手动指定输出维度，更加方便和灵活。</p></li><li><p><code>a_out = np.zeros(units)</code>: 创建一个一维数组 <code>a_out</code>，用于保存输出结果，初始值全部设为 0。</p></li><li><p><code>for j in range(units):</code>: 遍历每个输出神经元的索引 <code>j</code>。</p></li><li><p><code>w = W[:, j]</code>: 从权重矩阵 <code>W</code> 中获取第 <code>j</code> 列，即与第 <code>j</code> 个神经元连接的权重向量。</p></li><li><p><code>z = np.dot(w, a_in) + b[j]</code>: 计算加权输入 <code>z</code>，使用权重向量 <code>w</code> 与输入向量 <code>a_in</code> 的点积，并加上对应的偏置 <code>b[j]</code>。</p></li><li><p><code>a_out[j] = g(z)</code>: 将加权输入 <code>z</code> 经过激活函数 <code>g</code> 进行非线性变换，得到第 <code>j</code> 个输出神经元的输出值，并保存在 <code>a_out[j]</code> 中。</p></li><li><p>循环结束后，<code>a_out</code> 中存储了整个层的输出结果，即一个由 <code>units</code> 个元素组成的一维数组，表示该层所有神经元的输出。</p></li></ol><p></p></blockquote><p>​后面的代码时将几个隐藏层串在一起，以便在神经网络中实现前向传播。</p><p>​<strong>这里使用   W  ,因为根据线性代数，矩阵使用大写字母，小写字母代表向量和标量。</strong></p><p>​       这就是底层工作原理， <code>在实验室中练习。</code></p><hr><p>​神经网络与AI、AGI、通用人工智能之间是什么关系？</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308062119965.webp" alt="image-20230806211930637"></p><p>​实验表明人类的大脑具有惊人的适应性，具有惊人的可塑性，它意味着能够适应令人眼花缭乱的传感器输入范围，问题是，如果同一块脑组织可以学会看、摸，甚至其他东西，我们可以复制这个算法并在计算机上实现吗？</p><p>​在短期内，我认为即使不追求AGI，机器学习和神经网络也是非常强大的工具，即使不尝试去构建人类水平的智能，我认为你会发现神经网络非常强大，以及您可能构建的应用程序的有用工具集。</p><h2 id="3、神经网络的高效"><a href="#3、神经网络的高效" class="headerlink" title="3、神经网络的高效"></a>3、神经网络的高效</h2><p>​神经网络可以<code>矢量化</code>，下面第一段代码缺少对units的定义。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308101720807.webp" alt="image-20230810172006544"></p><blockquote><p>在NumPy库中，<code>dot</code>和<code>matmul</code>都用于矩阵乘法操作，但在某些情况下它们有一些细微的差异。下面我会详细解释它们的不同之处。</p><ol><li><strong><code>dot</code>函数：</strong> <code>numpy.dot(a, b)</code>函数用于计算两个数组的点积（内积）。对于二维数组（矩阵）来说，它执行矩阵乘法操作。对于一维数组，它计算两个数组的内积。对于高维数组，它会将最后两个维度视为矩阵，然后进行矩阵乘法。</li><li><strong><code>matmul</code>函数：</strong> <code>numpy.matmul(a, b)</code>函数也用于计算两个数组的矩阵乘法。与<code>dot</code>不同的是，<code>matmul</code>在处理高维数组时会更加严格。它只能用于两个至少是2维的数组，并且在进行矩阵乘法时会忽略其他维度。</li></ol><p>总结：</p><ul><li>当处理一维或多维数组时，<code>dot</code>和<code>matmul</code>在执行矩阵乘法时的行为可能会略有不同。</li><li>对于二维数组，<code>dot</code>和<code>matmul</code>执行相同的矩阵乘法操作。</li><li>对于高维数组，<code>dot</code>会在最后两个维度上执行矩阵乘法，而<code>matmul</code>只会在两个至少为2维的数组上执行矩阵乘法。</li></ul><p>在绝大多数情况下，对于二维数组，<code>dot</code>和<code>matmul</code>的行为是相同的，但在处理高维数组时，需要注意它们之间的差异。</p></blockquote><h2 id="4、矩阵乘法的学习与代码实现"><a href="#4、矩阵乘法的学习与代码实现" class="headerlink" title="4、矩阵乘法的学习与代码实现"></a>4、矩阵乘法的学习与代码实现</h2><p>​点乘，对应相乘相加   &#x3D;    矩阵转置相乘，实现点积。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308101720192.webp" alt="image-20230810172043022"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308101721579.webp" alt="image-20230810172102414"></p><p>​<strong>向量矩阵相乘推广矩阵矩阵相乘</strong></p><hr><p>​下面实现矩阵乘代码：</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308101721410.webp" alt="image-20230810172130165"></p><p>​注图中少 “[ ]”。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308101721089.webp" alt="image-20230810172146907"></p><p>​<strong>A-T我们将其称为A-in</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308101723420.webp" alt="image-20230810172325110"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>搭建神经网络（Tensorflow）</title>
      <link href="/posts/29144/"/>
      <url>/posts/29144/</url>
      
        <content type="html"><![CDATA[<h1 id="搭建神经网络"><a href="#搭建神经网络" class="headerlink" title="搭建神经网络"></a><p align="center">搭建神经网络</p></h1><h2 id="1、如何用代码实现推理"><a href="#1、如何用代码实现推理" class="headerlink" title="1、如何用代码实现推理"></a>1、如何用代码实现推理</h2><p>​神经网络的一个显着特点是可以将相同的算法应用于许多不同的应用程序。下面使用一个例子来说明推理。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308051709246.webp" alt="image-20230805170902992"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308051717349.webp" alt="image-20230805171740094"></p><p>​这行代码是使用 Keras API 创建一个神经网络的一层。在这个例子中，它创建了一个具有 3 个神经元的全连接层（也称为稠密层），并且使用 sigmoid 激活函数。</p><ul><li><p><code>Dense</code>：这是 Keras 中创建全连接层的类。</p></li><li><p><code>units=3</code>：指定这一层有 3 个神经元。这意味着该层的输出将是一个包含 3 个值的向量。</p></li><li><p><code>activation=&#39;sigmoid&#39;</code>：这是设置该层的激活函数，这里使用的是 sigmoid 函数。Sigmoid 函数将输入的值映射到 0 到 1 之间的范围，通常用于处理二分类问题。</p><p>以下是一个简单的示例，演示如何使用这个层来构建一个简单的 Keras 模型：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个 Sequential 模型</span></span><br><span class="line">model = Sequential()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加第一层</span></span><br><span class="line">model.add(Dense(units=<span class="number">3</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>, input_shape=(input_dim,)))  <span class="comment"># 替换 input_dim 为你的输入数据维度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加其他层（这里省略）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译模型并进行训练</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(X_train, y_train, epochs=<span class="number">10</span>, batch_size=<span class="number">32</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>以上代码只是一个简单示例，实际构建的模型可能更复杂，并且在编译和训练模型时需要使用适当的优化器、损失函数和评估指标。</p><p>这就是使用TensorFlow在神经网络中进行推理的方式。</p></li></ul><hr><p>​例子：手写数字分类问题</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308051728039.webp" alt="image-20230805172849814"></p><h2 id="2、Tensorflow-中的数据形式"><a href="#2、Tensorflow-中的数据形式" class="headerlink" title="2、Tensorflow 中的数据形式"></a>2、Tensorflow 中的数据形式</h2><p>​在  <strong>Numpy</strong>  和  <strong>TensorFlow</strong>  中表示数据，  <strong>Numpy</strong>  和<strong>TensorFlow</strong>  中的数据表示方式存在一些不一致。</p><p>​先看在  <strong>TensorFlow</strong>  中表示数据：利用上次的  <strong>coffee</strong>  数据，<strong>为什么是双方括号？</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308051749685.webp" alt="image-20230805174906489"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308051932344.webp" alt="image-20230805193231104"></p><p>​矩阵维数为行数<em>列数，每行数据一个</em>*[ ]<strong>，整个矩阵表示完后加</strong>（[ ]）**。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308051933971.webp" alt="image-20230805193326774"></p><p>​搞清楚生成的矩阵为什么样的形式。行向量，列向量，单个方括号则表示一维向量，没有行或者列的一维数组。一维向量可以用于表示一组单一维度的数据，例如：</p><ul><li><p>温度的时间序列数据：[25.5, 26.3, 24.8, 26.0, …]</p></li><li><p>学生的成绩：[90, 85, 78, 92, …]</p></li><li><p>产品的价格：[10.5, 15.2, 12.0, 9.8, …]</p><blockquote><p>在编程语言中，一维数组通常是一种简单的线性数据结构，可以通过列表（list）来表示。二维数组通常是嵌套的一维数组，可以通过列表的列表（list of lists）来表示。例如，Python中的列表可以用于表示一维数组和二维数组。</p><ol><li>一维数组（一维向量）：<ul><li>定义：一维数组是一组按顺序排列的数据元素，每个元素都有唯一的索引。</li><li>表示：一维数组是一个线性结构，数据按照单一维度组织，并且可以用一个索引来访问其中的每个元素。</li><li>示例：[1, 2, 3, 4, 5] 或者 [‘apple’, ‘banana’, ‘orange’]</li></ul></li><li>二维数组（二维矩阵）：<ul><li>定义：二维数组是一组按行和列排列的数据元素，每个元素由两个索引（行索引和列索引）来确定。</li><li>表示：二维数组是一个矩形结构，数据按照行和列的方式组织，每个元素需要两个索引来定位。</li><li>示例：[[1, 2, 3], [4, 5, 6], [7, 8, 9]] 或者 [[‘a’, ‘b’, ‘c’], [‘d’, ‘e’, ‘f’]]</li></ul></li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一维数组（列表）</span></span><br><span class="line">one_dimensional_array = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 二维数组（列表的列表）</span></span><br><span class="line">two_dimensional_array = [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, <span class="number">9</span>]]</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在数据分析、机器学习和深度学习中，二维数组常用于表示数据集、图像、矩阵等数据结构。一维数组通常用于表示单一维度的特征向量或标签。</p></blockquote></li></ul><p>​</p><p>​<strong>处理线性回归和逻辑回归的课程中，使用一维向量来表示输入特征  <em>x。</em></strong></p><p>​<strong>TensorFlow</strong>  中表示数据的惯例是使用矩阵来表示数据， 事实证明，<strong>TensorFlow</strong>  旨在处理非常大的数据集，并且通过在矩阵而不是一维数组中表示数据，它让<strong>TensorFlow</strong>  在内部的计算效率更高一些。</p><p>​所以：</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308051954453.webp" alt="image-20230805195427271"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308051959072.webp" alt="image-20230805195912840"></p><p>​</p><blockquote><ol><li><code>x = np.array([[200.0, 17.0]])</code>：这行代码创建了一个包含两个元素的二维 NumPy 数组，并将其赋值给变量 <code>x</code>。这个数组实际上是一个包含两个浮点数的一维向量（或一维数组）。注意，这里的代码应该是没有问题的，我之前提到的问题已经修复了。</li><li><code>layer_1 = Dense(units=3, activation=&#39;sigmoid&#39;)</code>：这行代码定义了一个全连接层（Dense Layer），该层有 3 个神经元，并使用 Sigmoid 激活函数。这里的 <code>units</code> 参数表示该层的输出维度，即输出具有 3 个值的向量。</li><li><code>a1 = layer_1(x)</code>：这行代码将输入向量 <code>x</code> 通过 <code>layer_1</code> 这个定义好的神经网络层进行前向传播。这就是将输入数据通过神经网络进行处理得到输出的过程。<code>a1</code> 将保存经过 <code>layer_1</code> 处理后的输出结果。</li><li><code>tf.Tensor([[0.2 0.7 0.3]], shape=(1, 3), dtype=float32)</code>：这是代码的输出结果。这表示经过前向传播后，<code>layer_1</code> 处理输入向量 <code>x</code> 后得到的输出向量 <code>a1</code>。这里的输出向量 <code>a1</code> 是一个包含三个浮点数的一维向量，具体数值是 <code>[0.2, 0.7, 0.3]</code>。</li></ol></blockquote><p>​</p><p><strong>Tensor</strong>：张量，这里的张量是TensorFlow团队为了有效地存储和执行矩阵计算而创建的一种数据类型。</p><blockquote><p><code>tf.Tensor</code> 是 TensorFlow 中表示张量（tensor）的数据类型。张量是多维数组，可以看作是标量（0 维）、向量（1 维）、矩阵（2 维）等的扩展。</p><p>在 TensorFlow 中，所有的数据都以张量的形式进行处理。张量可以包含任意维度的数据，并且可以存储数值、字符串等类型的数据。它是 TensorFlow 的核心数据结构之一，用于表示计算图中的数据流动。</p><p><code>tf.Tensor</code> 是不可变的，意味着创建后无法直接修改其值。在 TensorFlow 中，所有的操作（例如张量运算）都会返回新的 <code>tf.Tensor</code> 对象，而不会修改原始张量。</p></blockquote><p>​事实上，如果你想获取张量a1并将其转换回NumPy数组，你可以使用函数  <strong>a1.numpy</strong>  来实现。它将获取相同的数据并以NumPy数组的形式返回，而不是以TensorFlow数组或TensorFlow矩阵的形式返回。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308052013348.webp" alt="image-20230805201312150"></p><h2 id="3、搭建一个神经网络"><a href="#3、搭建一个神经网络" class="headerlink" title="3、搭建一个神经网络"></a>3、搭建一个神经网络</h2><ol><li>顺序框架张量流（Sequential Model in TensorFlow）是 TensorFlow 中一种简单且常用的神经网络模型构建方式。它是 TensorFlow 的高级 API，旨在帮助用户快速构建神经网络模型，特别适用于那些层按顺序堆叠的简单模型。</li><li>顺序框架张量流的主要特点是它按照顺序一层一层地添加神经网络层，形成一个线性的模型结构。每一层都连接到上一层，并且数据从第一层流动到最后一层。这种顺序的层叠结构使得模型的构建和理解更加直观和简单。</li></ol><p>​以下是一个简单的例子，展示了如何使用顺序框架张量流构建一个简单的全连接神经网络：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建顺序框架</span></span><br><span class="line">model = tf.keras.Sequential()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加第一层（输入层）</span></span><br><span class="line">model.add(Dense(units=<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(input_dim,)))  <span class="comment"># 替换 input_dim 为输入数据的维度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加第二层</span></span><br><span class="line">model.add(Dense(units=<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加输出层</span></span><br><span class="line">model.add(Dense(units=num_classes, activation=<span class="string">&#x27;softmax&#x27;</span>))  <span class="comment"># 替换 num_classes 为分类类别的数量</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译模型</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>​上述代码中，我们创建了一个顺序框架 <code>model</code>，并按照顺序添加了三个全连接层（输入层、隐藏层和输出层）。最后，<strong>我们通过 <code>compile</code> 方法对模型进行编译，指定优化器、损失函数和评估指标，以便在训练时进行模型优化和评估。</strong></p><p>​通过顺序框架张量流，我们可以快速构建和训练神经网络模型，适用于很多简单的深度学习任务。对于更复杂的模型结构或需要非顺序连接的情况，可以使用函数式 API 或子类化 API 来构建定制化的模型。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308052049104.webp" alt="image-20230805204953874"></p><ul><li>如果你想训练这个神经网络，你需要做的就是调用你需要用一些参数调用模型点编译的函数   <em><strong>compile</strong></em>   。</li><li><strong>fit</strong>  告诉张量流采用这个神经网络在数据  <strong>x</strong>  上对  <strong>y</strong>  进行训练。</li><li><strong>predict</strong>  进行预测。</li></ul><p>​模型预测使用顺序函数编译的神经网络进行前向传播并为您进行推理。</p><hr><p>​为数字分类示例重做此操作：</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308052102013.webp" alt="image-20230805210237748"></p><p>​<strong>通常可以将隐藏层直接放入顺序函数中</strong>：</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308052103009.webp" alt="image-20230805210336777"></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202308052106426.webp" alt="image-20230805210654045"></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>过拟合、正则化</title>
      <link href="/posts/29142/"/>
      <url>/posts/29142/</url>
      
        <content type="html"><![CDATA[<h1 id="过拟合、正则化"><a href="#过拟合、正则化" class="headerlink" title="过拟合、正则化"></a><p align="center">过拟合、正则化</p></h1><h2 id="1、过拟合问题"><a href="#1、过拟合问题" class="headerlink" title="1、过拟合问题"></a>1、过拟合问题</h2><ul><li>模型对训练数据 <strong>欠拟合</strong> (  <em><strong>underfit</strong></em>  ) or 算法具有 <strong>高偏差</strong>（ <em><strong>high bias</strong></em> ）</li><li>希望  <em><strong>generalization</strong></em> :  <strong>泛化</strong></li><li><strong>过拟合</strong>（ <em><strong>overfitting</strong></em> ） or  <strong>高方差</strong>（ <em><strong>high variance</strong></em> ）</li></ul><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307291641912.webp" alt="image-20230729164112592" style="zoom:50%;" /><hr><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307291650553.webp" alt="image-20230729165008193" style="zoom:50%;" /><h2 id="2、解决过拟合问题"><a href="#2、解决过拟合问题" class="headerlink" title="2、解决过拟合问题"></a>2、解决过拟合问题</h2><ol><li>收集更多的训练集数据。</li><li>不要使用太多特征，使用特征的子集即选择一部分最合适的特征。</li><li><em><strong>Regularization</strong></em>  : 正则化</li></ol><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307291657447.webp" alt="image-20230729165758247"></p><hr><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307291658119.webp" alt="image-20230729165852938"></p><h2 id="3、正则化"><a href="#3、正则化" class="headerlink" title="3、正则化"></a>3、正则化</h2><ul><li><p>正则化是一种更<strong>温和地减少某些特征影响</strong>的方法，而不像彻底消除它那样严厉。</p></li><li><p>正则化的作用是<strong>鼓励学习算法缩小参数值</strong>，而不是把参数变为0。</p></li></ul><p>​基于正则化为学习算法设计的代价函数，通过调整代价函数来调整参数。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307291711733.webp" alt="image-20230729171147458"></p><p>​<strong>正则化的典型实现方式是惩罚所有的特征，惩罚所有的 <em>w</em> 参数</strong>。最后一项可以忽略。</p><ul><li><em><strong>λ</strong></em> 设置为0，则根本没有使用正则化项。</li><li><em><strong>λ</strong></em> 设置非常大，参数非常接近0，例如对于线性回归模型则   <em><strong>f&#x3D;b</strong></em>   ，拟合水平直线，欠拟合。</li></ul><h2 id="4、用于线性回归的正则方法"><a href="#4、用于线性回归的正则方法" class="headerlink" title="4、用于线性回归的正则方法"></a>4、用于线性回归的正则方法</h2><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307292206887.webp" alt="image-20230729220649628"></p><blockquote><p><strong>注意：正则化项求偏导后无求和符号。</strong></p><p>求导是对某一项的参数求导，此时其他参数为常数。</p></blockquote><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307292212627.webp" alt="image-20230729221220333"></p><h3 id="高数"><a href="#高数" class="headerlink" title="高数"></a><p align="center">高数</p></h3><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307292217945.webp" alt="image-20230729221710700"></p><h2 id="5、用于逻辑回归的正则化方法"><a href="#5、用于逻辑回归的正则化方法" class="headerlink" title="5、用于逻辑回归的正则化方法"></a>5、用于逻辑回归的正则化方法</h2><p><strong><p align="center">正则化逻辑与线性回归相似</p></strong></p><p>​修改代价函数实现正则化：<img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307292222803.webp" alt="image-20230729222206533"></p><hr><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307292224550.webp" alt="image-20230729222403346"></p><p>​<strong>完全相同的方程，除了   <em>f</em>   的定义不再是线性函数，而是应用于   <em>z</em>   的逻辑函数。</strong></p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307292229255.webp" alt="image-20230729222925905" style="zoom:50%;" /><h1 id="knn"><a href="#knn" class="headerlink" title="knn"></a>knn</h1><p>K-最近邻算法（K-Nearest Neighbors，KNN）是一种监督学习算法，用于分类和回归任务。KNN是一种非参数和基于实例的学习算法，它的工作原理基于数据点之间的相似性度量。以下是KNN的原理：</p><ol><li><strong>训练阶段</strong>：在训练阶段，KNN算法仅仅存储整个数据集，不创建模型或学习特征与目标变量之间的显式关系。</li><li><strong>预测阶段</strong>：<ul><li>对于分类任务：当要对一个新数据点进行分类时，KNN计算该数据点与训练集中所有其他数据点之间的距离。常用的距离度量包括欧氏距离、曼哈顿距离等。</li><li>“K”代表KNN中要考虑的最近邻居的数量。在应用算法时，您需要指定这个超参数。算法然后根据距离度量选择K个最近的数据点（邻居）作为新数据点的邻居。</li><li>对于回归任务，与选择K个最近邻居不同，算法计算这些邻居的目标值的平均值或加权平均值作为新数据点的预测目标值。</li></ul></li><li><strong>分类或回归</strong>：对于分类任务，KNN通过在K个最近邻居中进行多数投票来预测新数据点的类别。对于回归任务，它通过计算K个最近邻居的目标值的平均值或加权平均值来预测新数据点的目标值。</li></ol><p>使用KNN时的关键考虑因素包括：</p><ul><li>选择K的值至关重要。较小的K值可能导致更灵活但嘈杂的预测，而较大的K值可能导致更平滑但可能不够准确的预测。</li><li>距离度量的选择可能影响算法的性能，您应选择对特定数据集有意义的度量方法。</li><li>对于大型数据集，KNN可能计算开销较高，因为它需要计算测试数据点与所有训练数据点之间的距离。</li></ul><p>KNN易于理解和实现，但不一定适用于所有情况。它在决策边界相对简单或有足够的数据以准确表示潜在模式时效果良好。此外，KNN对特征的尺度和分布敏感，因此在使用KNN时，需要进行特征缩放和适当的数据预处理。</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>逻辑回归</title>
      <link href="/posts/29141/"/>
      <url>/posts/29141/</url>
      
        <content type="html"><![CDATA[<h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a><p align="center">逻辑回归</p></h1><p>​分类：输出变量为少数可能值中的一个，而不是无限范围内的任何数字。</p><h3 id="1-2逻辑回归（用于二元分类）"><a href="#1-2逻辑回归（用于二元分类）" class="headerlink" title="1.2逻辑回归（用于二元分类）"></a>1.2逻辑回归（用于二元分类）</h3><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307061024791.webp" alt="image-20230706102408627" style="zoom:50%;" /><p>Sigmoid函数是一个在生物学中常见的<a href="https://baike.baidu.com/item/S%E5%9E%8B%E5%87%BD%E6%95%B0/19178062?fromModule=lemma_inlink">S型函数</a>，也称为<a href="https://baike.baidu.com/item/S%E5%9E%8B%E7%94%9F%E9%95%BF%E6%9B%B2%E7%BA%BF/5581189?fromModule=lemma_inlink">S型生长曲线</a>。 在信息科学中，由于其单增以及反函数单增等性质，Sigmoid函数常被用作神经网络的<a href="https://baike.baidu.com/item/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/2520792?fromModule=lemma_inlink">激活函数</a>，将变量映射到0,1之间。</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307061059720.webp" alt="image-20230706105911494" style="zoom:50%;" /><p>​<strong>多变量整合为单变量，再用sigmoid分类</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307061104571.webp" alt="image-20230706110452346"></p><h3 id="1-3逻辑回归、决策边界"><a href="#1-3逻辑回归、决策边界" class="headerlink" title="1.3逻辑回归、决策边界"></a>1.3逻辑回归、决策边界</h3><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307081441602.webp" alt="image-20230708144100042"></p><h3 id="2-1逻辑回归中的代价函数"><a href="#2-1逻辑回归中的代价函数" class="headerlink" title="2.1逻辑回归中的代价函数"></a>2.1逻辑回归中的代价函数</h3><p>​<strong>代价函数提供了一种衡量特定参数与训练数据拟合程度的方法</strong></p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307081448958.webp" alt="image-20230708144831744" style="zoom: 50%;" /><hr><p>​<strong>单个训练示例的损失函数</strong></p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307101450133.webp" alt="image-20230710145008957" style="zoom:50%;" /><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307081510170.webp" alt="image-20230708151030003"></p><p>​<em>f</em>  的值总是在0-1之间，越接近于1，损失越小。<strong>上图损失函数漏掉了一个负号</strong></p><hr><p>​<strong>代价函数是整个训练集的函数，因此是单个训练示例的损失函数之和的平均值</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307081519147.webp" alt="image-20230708151933785"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_cost_logistic</span>(<span class="params">X, y, w, b</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Computes cost</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      X (ndarray (m,n)): Data, m examples with n features</span></span><br><span class="line"><span class="string">      y (ndarray (m,)) : target values</span></span><br><span class="line"><span class="string">      w (ndarray (n,)) : model parameters  </span></span><br><span class="line"><span class="string">      b (scalar)       : model parameter</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">      cost (scalar): cost</span></span><br><span class="line"><span class="string">     &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">m = X.shape[<span class="number">0</span>]</span><br><span class="line">cost = <span class="number">0.0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">    z_i = np.dot(X[i],w) + b</span><br><span class="line">    f_wb_i = sigmoid(z_i)</span><br><span class="line">    cost +=  -y[i]*np.log(f_wb_i) - (<span class="number">1</span>-y[i])*np.log(<span class="number">1</span>-f_wb_i)</span><br><span class="line">         </span><br><span class="line">cost = cost / m</span><br><span class="line"><span class="keyword">return</span> cost</span><br></pre></td></tr></table></figure><h3 id="2-2简化逻辑回归代价函数"><a href="#2-2简化逻辑回归代价函数" class="headerlink" title="2.2简化逻辑回归代价函数"></a>2.2简化逻辑回归代价函数</h3><p>​目的：使用梯度下降来拟合逻辑回归模型的参数时，实现简单。</p><p>​二元<strong>交叉熵损失函数</strong>，多分类只需要多乘几个多项式即可</p><p> <img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307101459266.webp" alt="image-20230710145927025"></p><hr><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307101504651.webp" alt="image-20230710150413331"></p><p>这个特定的成本函数是使用最大似然估计的统计原理推导出来的，这是统计学中关于如何有效的找到不同模型的参数的想法。<strong>它有一个很好的特性，它是凸的。</strong></p><h3 id="3-1实现梯度下降"><a href="#3-1实现梯度下降" class="headerlink" title="3.1实现梯度下降"></a>3.1实现梯度下降</h3><p>​为了拟合逻辑回归模型的参数，将尝试找到使 <em>w</em> 和 <em>b</em> 的成本  <em>J</em>  最小的参数值，使用梯度下降来实现。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307121410281.webp" alt="image-20230712141007965"></p><p>​<strong>与线性回归模型类似，注意同时更新。</strong></p><p>推导过程：</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307121500696.webp" alt="image-20230712150021478" style="zoom: 67%;" /><hr><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307121519309.webp" alt="image-20230712151912073" style="zoom:67%;" /><p>​<strong>尽管线性回归和逻辑回归所写的算法看起来相同，但实际上它们是两种截然不同的算法，因为 <em>f</em> 的定义不同。</strong></p><p>​<strong>ps：上述逻辑回归的 <em>f</em> 的负号位置错了</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202307121526385.webp" alt="image-20230712152606243"></p><hr><p>​<strong>梯度函数实现代码：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">compute_gradient_logistic</span>(<span class="params">X, y, w, b</span>): </span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Computes the gradient for linear regression </span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      X (ndarray (m,n): Data, m examples with n features</span></span><br><span class="line"><span class="string">      y (ndarray (m,)): target values</span></span><br><span class="line"><span class="string">      w (ndarray (n,)): model parameters  </span></span><br><span class="line"><span class="string">      b (scalar)      : model parameter</span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">      dj_dw (ndarray (n,)): The gradient of the cost w.r.t. the parameters w. </span></span><br><span class="line"><span class="string">      dj_db (scalar)      : The gradient of the cost w.r.t. the parameter b. </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    m,n = X.shape</span><br><span class="line">    dj_dw = np.zeros((n,))                           <span class="comment">#(n,)</span></span><br><span class="line">    dj_db = <span class="number">0.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        f_wb_i = sigmoid(np.dot(X[i],w) + b)          <span class="comment">#(n,)(n,)=scalar</span></span><br><span class="line">        err_i  = f_wb_i  - y[i]                       <span class="comment">#scalar</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">            dj_dw[j] = dj_dw[j] + err_i * X[i,j]      <span class="comment">#scalar</span></span><br><span class="line">        dj_db = dj_db + err_i</span><br><span class="line">    dj_dw = dj_dw/m                                   <span class="comment">#(n,)</span></span><br><span class="line">    dj_db = dj_db/m                                   <span class="comment">#scalar</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> dj_db, dj_dw  </span><br></pre></td></tr></table></figure><p>​<strong>检查梯度函数的实现：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">X_tmp = np.array([[<span class="number">0.5</span>, <span class="number">1.5</span>], [<span class="number">1</span>,<span class="number">1</span>], [<span class="number">1.5</span>, <span class="number">0.5</span>], [<span class="number">3</span>, <span class="number">0.5</span>], [<span class="number">2</span>, <span class="number">2</span>], [<span class="number">1</span>, <span class="number">2.5</span>]])</span><br><span class="line">y_tmp = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">w_tmp = np.array([<span class="number">2.</span>,<span class="number">3.</span>])</span><br><span class="line">b_tmp = <span class="number">1.</span></span><br><span class="line">dj_db_tmp, dj_dw_tmp = compute_gradient_logistic(X_tmp, y_tmp, w_tmp, b_tmp)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;dj_db: <span class="subst">&#123;dj_db_tmp&#125;</span>&quot;</span> )</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;dj_dw: <span class="subst">&#123;dj_dw_tmp.tolist()&#125;</span>&quot;</span> )</span><br></pre></td></tr></table></figure><p>​<strong>结果为：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dj_db: <span class="number">0.49861806546328574</span></span><br><span class="line">dj_dw: [<span class="number">0.498333393278696</span>, <span class="number">0.49883942983996693</span>]</span><br></pre></td></tr></table></figure><hr><p>​<strong>梯度下降代码:</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">gradient_descent</span>(<span class="params">X, y, w_in, b_in, alpha, num_iters</span>): </span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Performs batch gradient descent</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">      X (ndarray (m,n)   : Data, m examples with n features</span></span><br><span class="line"><span class="string">      y (ndarray (m,))   : target values</span></span><br><span class="line"><span class="string">      w_in (ndarray (n,)): Initial values of model parameters  </span></span><br><span class="line"><span class="string">      b_in (scalar)      : Initial values of model parameter</span></span><br><span class="line"><span class="string">      alpha (float)      : Learning rate</span></span><br><span class="line"><span class="string">      num_iters (scalar) : number of iterations to run gradient descent</span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">      w (ndarray (n,))   : Updated values of parameters</span></span><br><span class="line"><span class="string">      b (scalar)         : Updated value of parameter </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># An array to store cost J and w&#x27;s at each iteration primarily for graphing later</span></span><br><span class="line">    J_history = []</span><br><span class="line">    w = copy.deepcopy(w_in)  <span class="comment">#avoid modifying global w within function</span></span><br><span class="line">    b = b_in</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_iters):</span><br><span class="line">        <span class="comment"># Calculate the gradient and update the parameters</span></span><br><span class="line">        dj_db, dj_dw = compute_gradient_logistic(X, y, w, b)   </span><br><span class="line"></span><br><span class="line">        <span class="comment"># Update Parameters using w, b, alpha and gradient</span></span><br><span class="line">        w = w - alpha * dj_dw               </span><br><span class="line">        b = b - alpha * dj_db               </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># Save cost J at each iteration</span></span><br><span class="line">        <span class="keyword">if</span> i&lt;<span class="number">100000</span>:      <span class="comment"># prevent resource exhaustion </span></span><br><span class="line">            J_history.append( compute_cost_logistic(X, y, w, b) )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Print cost every at intervals 10 times or as many iterations if &lt; 10</span></span><br><span class="line">        <span class="keyword">if</span> i% math.ceil(num_iters / <span class="number">10</span>) == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Iteration <span class="subst">&#123;i:4d&#125;</span>: Cost <span class="subst">&#123;J_history[-<span class="number">1</span>]&#125;</span>   &quot;</span>)</span><br><span class="line">    </span><br><span class="line">     <span class="keyword">return</span> w, b, J_history         <span class="comment">#return final w,b and J history for graphing</span></span><br></pre></td></tr></table></figure><p>​<strong>在数据集上运行：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">w_tmp  = np.zeros_like(X_train[<span class="number">0</span>])</span><br><span class="line">b_tmp  = <span class="number">0.</span></span><br><span class="line">alph = <span class="number">0.1</span></span><br><span class="line">iters = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line">w_out, b_out, _ = gradient_descent(X_train, y_train, w_tmp, b_tmp, alph, iters) </span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\nupdated parameters: w:<span class="subst">&#123;w_out&#125;</span>, b:<span class="subst">&#123;b_out&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>​<strong>结果：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Iteration    <span class="number">0</span>: Cost <span class="number">0.684610468560574</span>   </span><br><span class="line">Iteration <span class="number">1000</span>: Cost <span class="number">0.1590977666870457</span>   </span><br><span class="line">Iteration <span class="number">2000</span>: Cost <span class="number">0.08460064176930078</span>   </span><br><span class="line">Iteration <span class="number">3000</span>: Cost <span class="number">0.05705327279402531</span>   </span><br><span class="line">Iteration <span class="number">4000</span>: Cost <span class="number">0.04290759421682</span>   </span><br><span class="line">Iteration <span class="number">5000</span>: Cost <span class="number">0.03433847729884557</span>   </span><br><span class="line">Iteration <span class="number">6000</span>: Cost <span class="number">0.02860379802212006</span>   </span><br><span class="line">Iteration <span class="number">7000</span>: Cost <span class="number">0.02450156960879306</span>   </span><br><span class="line">Iteration <span class="number">8000</span>: Cost <span class="number">0.02142370332569295</span>   </span><br><span class="line">Iteration <span class="number">9000</span>: Cost <span class="number">0.019030137124109114</span>   </span><br><span class="line"></span><br><span class="line">updated parameters: w:[<span class="number">5.28</span> <span class="number">5.08</span>], b:-<span class="number">14.222409982019837</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>多元线性回归，矢量化</title>
      <link href="/posts/29140/"/>
      <url>/posts/29140/</url>
      
        <content type="html"><![CDATA[<h1 id="多元线性回归，矢量化"><a href="#多元线性回归，矢量化" class="headerlink" title="多元线性回归，矢量化"></a><p align="center">多元线性回归，矢量化</p></h1><h2 id="1-多维特征"><a href="#1-多维特征" class="headerlink" title="1.多维特征"></a>1.多维特征</h2><p><strong>多元线性回归模型</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306100942878.webp" alt="image-20230610094203639"></p><hr><hr><h2 id="2-矢量化"><a href="#2-矢量化" class="headerlink" title="2.矢量化"></a>2.矢量化</h2><p><strong>缩短代码，提高运行效率</strong></p><p><strong>NumPy</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306100951696.webp" alt="image-20230610095105404"></p><p><strong>用空间换时间，用连续的结构可以省去查找数据的时间</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306101002307.webp" alt="image-20230610100241038"></p><hr><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306101002970.webp" alt="image-20230610100256599"></p><hr><hr><h2 id="3-用于多元线性回归的梯度下降算法"><a href="#3-用于多元线性回归的梯度下降算法" class="headerlink" title="3.用于多元线性回归的梯度下降算法"></a>3.用于多元线性回归的梯度下降算法</h2><p><strong>带有矢量化的多元线性回归实现梯度下降</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306101013171.webp" alt="image-20230610101334864"></p><p><strong>核心</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306101018363.webp" alt="image-20230610101851161"></p><hr><hr><h2 id="4-特征缩放-数据预处理"><a href="#4-特征缩放-数据预处理" class="headerlink" title="4.特征缩放(数据预处理)"></a>4.特征缩放(数据预处理)</h2><p><strong>归一化</strong> ：拥有不同特征时，它们得取值范围非常不同时，可能会导致梯度下降运行缓慢，重新缩放不同得特征，使它们都具有可比较的取值范围，效果更显著。</p><ol><li><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306110919219.webp" alt="image-20230611091955007"></li><li>均值归一化：特征值减平均值（样本平均值）再除以方差<img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306110925805.webp" alt="image-20230611092559538"></li><li>Z-score 归一化：需要计算每个特征的标准差。<strong>概率论</strong></li></ol><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306110938294.webp" alt="image-20230611093829964"></p><p><strong>按需缩放</strong>：在一个数量级上的特征可以不考虑缩放</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306110941080.webp" alt="image-20230611094136864"></p><h2 id="5-判断梯度下降是否收敛"><a href="#5-判断梯度下降是否收敛" class="headerlink" title="5.判断梯度下降是否收敛"></a>5.判断梯度下降是否收敛</h2><p>如果有 <em>J</em> 在一次迭代后增加，意味着 Alpha选择不当，通常意味着Alpha太大，或者代码中可能存在错误。</p><ol><li><strong>迭代次数</strong>，创建学习曲线尝试找出。</li><li>自动收敛测试：假设 <em>epsilon</em> 是一个代表小数变量，例如 0.001 或 10^-3。如果成本 <em>J</em> 在一次迭代中减少的幅度小于这个数字 <em>epsilon</em> ，那么曲线可能趋于平坦。</li></ol><h2 id="6-选择合适的学习率"><a href="#6-选择合适的学习率" class="headerlink" title="6.选择合适的学习率"></a>6.选择合适的学习率</h2><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306120950291.webp" alt="image-20230612095038996"></p><hr><p>技巧：如果学习率足够小，成本函数应该在每次迭代中减少。通过将Alpha设置为一个非常小的数字，看看这是否会导致每次迭代时成本降低。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306120956944.webp" alt="image-20230612095616640"></p><p><strong>省流：凭感觉去试，调参。</strong></p><h2 id="7-特征工程"><a href="#7-特征工程" class="headerlink" title="7.特征工程"></a>7.特征工程</h2><p><strong>特征衍生</strong>：通常通过转换或组合原始特征来使学习算法更容易做出准确的预测。</p><p><strong>多项式回归</strong></p><p><strong>Scikit-learn</strong></p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306121042502.webp" alt="image-20230612104233179"></p><p>不仅可以拟合直线，还可以拟合曲线、非线性函数。</p><p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306121050229.webp" alt="image-20230612105041878" style="zoom:50%;" />、</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线性回归模型、梯度下降</title>
      <link href="/posts/29139/"/>
      <url>/posts/29139/</url>
      
        <content type="html"><![CDATA[<h1 id="线性回归模型、梯度下降"><a href="#线性回归模型、梯度下降" class="headerlink" title="线性回归模型、梯度下降"></a><p align="center">线性回归模型、梯度下降</p></h1><h2 id="两种主要类型"><a href="#两种主要类型" class="headerlink" title="两种主要类型"></a><p align="left">两种主要类型</p></h2><h3 id="1-监督学习-Supervised-Learning"><a href="#1-监督学习-Supervised-Learning" class="headerlink" title="1.监督学习(Supervised Learning)"></a><p align="left">1.监督学习(Supervised Learning)</p></h3><img src="https://api2.mubu.com/v3/document_image/3413a5cb-b522-42e8-ae40-3a988a00321d-12774614.jpg" alt="image" style="zoom:50%;" /><p>1、Regression-回归：从无限多种可能输出数字中预测数字。</p><p>2、Classfication-分类：预测类别，可能的输出都是一小组。</p><hr><h3 id="2-无监督学习-Unsupervised-Learning"><a href="#2-无监督学习-Unsupervised-Learning" class="headerlink" title="2.无监督学习(Unsupervised Learning)"></a><p align="left">2.无监督学习(Unsupervised Learning)</p></h3><p>没有试图监督算法而为了给每个输入提供一些正确的答案，相反，为了弄清数据中有什么模式或者结构。</p><img src="https://api2.mubu.com/v3/document_image/ab575484-7afb-4726-b350-0697e0a4cf12-12774614.jpg" alt="image" style="zoom:50%;" /><p>1、Clustering-聚类：获取没有标签的数据并尝试将他们自动分组到集群中。例如相似推荐，就是把相似的内容归类后处理。</p><p>2、Anomaly detection-异常检测：用于检测异常事件。</p><p>3、Dimensionality reduction-降维：压缩大数据集。</p><hr><h3 id="3-线性回归模型-linear-regression"><a href="#3-线性回归模型-linear-regression" class="headerlink" title="3.线性回归模型(linear regression)"></a><p align="left">3.线性回归模型(linear regression)</p></h3><p>Training set-训练集、features-输入变量 <em>x</em>（特征或输入特征）、targets-目标变量  <em>y</em></p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306021634673.webp" alt="image-20230602163455564" style="zoom: 67%;" /><p>Univariate linear regression-单变量线性回归</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306021647760.webp" alt="image-20230602164734648" style="zoom:67%;" /><p><strong>1.Cost function-代价函数</strong></p><p>平方误差代价函数</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306021702346.webp" alt="image-20230602170247191" style="zoom:67%;" /><p>如何使用代价函数为模型找到最佳参数？</p><p>使  <em>J</em>  越小越好。  </p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306021719541.webp" alt="image-20230602171953431" style="zoom:50%;" /><p>先找最优的权重 <em>w</em> ，令 <em>b</em> 为 0。做代价函数图—二维</p><p><strong>多元函数求极值的问题。</strong></p><p>可视化代价函数：</p><p>回到原始问题，<em>b</em> 不为 0 时：</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306021801888.webp" alt="image-20230602180127719" style="zoom:67%;" /><hr><h3 id="4-梯度下降（Gradient-descent）"><a href="#4-梯度下降（Gradient-descent）" class="headerlink" title="4.梯度下降（Gradient descent）"></a><p align="left">4.梯度下降（Gradient descent）</p></h3><p>高效算法：代码编写自动找到 <em>w</em> 和 <em>b</em>，实现最好的拟合。</p><p>梯度下降是一种尝试最小化任何函数的方法。而不局限于线性回归的成本函数。</p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306031154023.webp" alt="image-20230603115414788" style="zoom:50%;" /><p><strong>同时更新参数（代码顺序）</strong></p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306031745415.webp" alt="image-20230603174503106" style="zoom:50%;" /><p><strong>学习率</strong></p><p>太小：下降步幅小，速度慢。</p><p>太大：步幅大，但可能会使结果更糟，在最低点附近震荡，过充，甚至离最低点越来越远，发散。</p><hr><h3 id="5-线性回归算法"><a href="#5-线性回归算法" class="headerlink" title="5.线性回归算法"></a><p align="left">5.线性回归算法</p></h3><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306071640865.webp" alt="image-20230607164007657" style="zoom: 67%;" /><hr><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306081554888.webp" alt="image-20230608155457007" style="zoom:67%;" /><p><strong>使用线性回归的平方误差成本函数时，成本函数永远不会有多个局部最小值。凸函数</strong></p><hr><h3 id="6-运行梯度下降"><a href="#6-运行梯度下降" class="headerlink" title="6.运行梯度下降"></a><p align="left">6.运行梯度下降</p></h3><p><strong>C1_W2_Lab03_Gradient_Descent_Soln</strong></p><img src="https://blog-1318483047.cos.ap-nanjing.myqcloud.com/img%20/202306081609512.webp" alt="image-20230608160911171" style="zoom:50%;" />]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Machine learning </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
